{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src_vec = src;\n    int64_t *dst_vec = dst;\n    const bool *mask_vec = mask;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint64m1_t src_reg = vle64_v_i64m1(src_vec, vl);\n        vbool64_t mask_reg = vbmsel_v_i64m1(mask_vec, vl);\n        vint64m1_t dst_reg = vmerge_vx_i64m1(src_reg, mask_reg);\n        vse64_v_i64m1(dst_vec, dst_reg, vl);\n        src_vec += vl;\n        dst_vec += vl;\n        mask_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src_vec = src;\n    int64_t *dst_vec = dst;\n    const bool *mask_vec = mask;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint64m1_t src_reg = vle64_v_i64m1(src_vec, vl);\n        vbool64_t mask_reg = vbmsel_v_i64m1(mask_vec, vl);\n        vint64m1_t dst_reg = vwmul_vx_i64m1(src_reg, 0, vl); // Zero-initialize\n        vint64m1_t result = vmseq_vx_i64m1(src_reg, 0, vl); // Create a mask for zero\n        result = vmv_x_b64(result); // Convert mask to scalar\n        vse64_v_i64m1(dst_vec, result ? dst_reg : src_reg, vl);\n        src_vec += vl;\n        dst_vec += vl;\n        mask_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src_vec = src;\n    int64_t *dst_vec = dst;\n    const bool *mask_vec = mask;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint64m1_t src_reg = vle64_v_i64m1(src_vec, vl);\n        vbool64_t mask_reg = vbmsel_v_i64m1(mask_vec, vl);\n        vint64m1_t dst_reg = vmerge_vx_i64m1(src_reg, mask_reg);\n        vse64_v_i64m1(dst_vec, dst_reg, vl);\n        src_vec += vl;\n        dst_vec += vl;\n        mask_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src_vec = src;\n    int64_t *dst_vec = dst;\n    const bool *mask_vec = mask;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint64m1_t src_reg = vle64_v_i64m1(src_vec, vl);\n        vbool64_t mask_reg = vbmsel_v_i64m1(mask_vec, vl);\n        vint64m1_t dst_reg = vfmacc_vx_i64m1(vint64m1_t(), src_reg, mask_reg);\n        vse64_v_i64m1(dst_vec, dst_reg, vl);\n        src_vec += vl;\n        dst_vec += vl;\n        mask_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_0_RVV", "completion": "```c\nvoid conditional_move_simd(const int64_t *src, int64_t *dst, const bool *mask, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src_vec = src;\n    int64_t *dst_vec = dst;\n    const bool *mask_vec = mask;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint64m1_t src_reg = vle64_v_i64m1(src_vec, vl);\n        vbool64_t mask_reg = vbmsel_v_i64m1(mask_vec, vl);\n        vint64m1_t dst_reg = vwmul_vx_i64m1(src_reg, 0, vl); // Zero-initialize\n        vint64m1_t result = vmseq_vx_i64m1(src_reg, 0, vl); // Create a mask for zero\n        result = vmv_x_b64(result); // Convert mask to scalar\n        vse64_v_i64m1(dst_vec, result ? dst_reg : src_reg, vl);\n        src_vec += vl;\n        dst_vec += vl;\n        mask_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int32m1_t scale_vec = vdup_n_i32(scale);\n\n    // Step 1: Calculate tmp1 as (element * scale) right-shifted by 3 bits\n    int32m1_t tmp1 = vmul_w_v_i32m1_i32m1(src_vec, scale_vec);\n    tmp1 = vssra_32m1(tmp1, 3);\n\n    // Step 2: Calculate tmp2 as (element * scale) left-shifted by 3 bits\n    int32m1_t tmp2 = vmul_w_v_i32m1_i32m1(src_vec, scale_vec);\n    tmp2 = vssll_32m1(tmp2, 3);\n\n    // Step 3: Compute the final result as: (element * scale + tmp1 * tmp2) / 7\n    int32m1_t mul_result = vmadd_vv_i32m1(src_vec, scale_vec, tmp1);\n    mul_result = vmadd_vv_i32m1(mul_result, scale_vec, tmp2);\n    int32m1_t final_result = vdiv_w_v_i32m1_i32m1(mul_result, vdup_n_i32(7));\n\n    // Step 4: Store the result in dst\n    vse32_v_i32m1(dst, final_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int32m1_t scale_vec = vdup_v_i32m1(scale, vl);\n\n    // Step 1: Calculate tmp1 as (element * scale) right-shifted by 3 bits\n    int32m1_t tmp1 = vmrg_vx_i32m1(vsmul_vx_i32m1(src_vec, scale_vec), 3);\n\n    // Step 2: Calculate tmp2 as (element * scale) left-shifted by 3 bits\n    int32m1_t tmp2 = vslidedown_vx_i32m1(vsmul_vx_i32m1(src_vec, scale_vec), 3);\n\n    // Step 3: Compute the final result as: (element * scale + tmp1 * tmp2) divided by 7\n    int32m1_t result = vssra_vx_i32m1(vsmuladd_vx_i32m1(src_vec, scale_vec, vmul_vx_i32m1(tmp1, tmp2)), 7);\n\n    // Step 4: Store the result in dst\n    vse32_v_i32m1(dst, result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int32m1_t scale_vec = vdup_n_i32(scale);\n\n    // Step 1: Calculate tmp1 as (element * scale) right-shifted by 3 bits\n    int32m1_t tmp1 = vmulh_w_i32m1(vmul_vv_i32m1(src_vec, scale_vec), 8);\n\n    // Step 2: Calculate tmp2 as (element * scale) left-shifted by 3 bits\n    int32m1_t tmp2 = vmul_vv_i32m1(src_vec, scale_vec);\n    tmp2 = vrgather_vx_i32m1(tmp2, vget_v_i32m1(tmp2, 0), vl);\n    tmp2 = vadd_vx_i32m1(tmp2, 8, vl);\n\n    // Step 3: Compute the final result as: (element * scale + tmp1 * tmp2) divided by 7\n    int32m1_t mul_result = vmul_vv_i32m1(src_vec, scale_vec);\n    int32m1_t mul_tmp1_tmp2 = vmul_vv_i32m1(tmp1, tmp2);\n    int32m1_t sum_result = vadd_vv_i32m1(mul_result, mul_tmp1_tmp2);\n    int32m1_t final_result = vdiv_w_v_i32m1(sum_result, 7);\n\n    // Step 4: Store the result in dst\n    vse32_v_i32m1(dst, final_result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int32m1_t scale_vec = vdup_n_i32(scale);\n\n    // Step 1: Calculate tmp1\n    int32m1_t tmp1 = vmul_w_v_i32m1(src_vec, scale_vec);\n    tmp1 = vssra_32m1(tmp1, 3);\n\n    // Step 2: Calculate tmp2\n    int32m1_t tmp2 = vmul_w_v_i32m1(src_vec, scale_vec);\n    tmp2 = vssll_32m1(tmp2, 3);\n\n    // Step 3: Compute the final result\n    int32m1_t product = vmul_w_v_i32m1(src_vec, scale_vec);\n    int32m1_t term1 = vmul_w_v_i32m1(tmp1, tmp2);\n    int32m1_t sum = vadd_vv_i32m1(product, term1);\n    int32m1_t result = vdiv_w_v_i32m1(sum, 7);\n\n    // Step 4: Store the result\n    vse32_v_i32m1(dst, result, vl);\n}\n```"}
{"task_id": "SimdBench_1_RVV", "completion": "```c\nvoid load_modify_store_simd(const int *src, int *dst, int scale, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int32m1_t scale_vec = vdup_v_i32m1(scale, vl);\n\n    // Step 1: Calculate tmp1 as (element * scale) right-shifted by 3 bits\n    int32m1_t tmp1 = vmul_w_v_i32m1_i32m1(src_vec, scale_vec, vl);\n    tmp1 = vrsra_v_i32m1(tmp1, 3, vl);\n\n    // Step 2: Calculate tmp2 as (element * scale) left-shifted by 3 bits\n    int32m1_t tmp2 = vmul_w_v_i32m1_i32m1(src_vec, scale_vec, vl);\n    tmp2 = vlsra_v_i32m1(tmp2, 3, vl);\n\n    // Step 3: Compute the final result as: (element * scale + tmp1 * tmp2) / 7\n    int32m1_t mul_result = vmadd_vv_i32m1(src_vec, scale_vec, vl);\n    int32m1_t mul_tmp1_tmp2 = vmul_vv_i32m1(tmp1, tmp2, vl);\n    int32m1_t final_result = vredsum_vs_i32m1_i32m1_i32m1(mul_result, mul_tmp1_tmp2, vl);\n    final_result = vdiv_v_i32m1(final_result, 7, vl);\n\n    // Step 4: Store the result in dst\n    vse32_v_i32m1(dst, final_result, vl);\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t r = 0; r < rows; r++) {\n        vfloat64m1_t vector = vle64_v_f64m1(src + r * cols + stride, vl);\n        vse64_v_f64m1(dst + r, vector, 1);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t r = 0; r < rows; r++) {\n        vfloat64m1_t vector = vle64_v_f64m1(src + r * cols + stride, vl);\n        vse64_v_f64m1(dst + r, vector, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t r = 0; r < rows; r++) {\n        vfloat64xm1_t vector = vle64_v_f64m1(src + r * cols + stride, vl);\n        vse64_v_f64m1(dst + r, vector, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t r = 0; r < rows; r++) {\n        vfloat64xm1_t vector = vle64_v_f64m1(src + r * cols + stride, vl);\n        vse64_v_f64m1(dst + r, vector, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_2_RVV", "completion": "```c\nvoid strided_load_store_simd(const double *src, double *dst, size_t rows, size_t cols, size_t stride) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t r = 0; r < rows; r++) {\n        vfloat64m1_t vec = vle64_v_f64m1(src + r * cols + stride, vl);\n        vse64_v_f64m1(dst + r, vec, 1);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t src_vec = vle32_v_f32m1(src + i, vl);\n        vint32m1_t indices_vec = vle32_v_i32m1(indices + i, vl);\n        vfloat32m1_t dst_vec = vgather_vx_f32m1(src_vec, indices_vec, vl);\n        vse32_v_f32m1(dst + i, dst_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t src_vec = vle32_v_f32m1(src + i, vl);\n        vint32m1_t indices_vec = vle32_v_i32m1(indices + i, vl);\n        \n        // Gather operation\n        vfloat32m1_t dst_gather = vgather_vx_f32m1(src_vec, indices_vec, vl);\n        \n        // Scatter operation\n        vse32_v_f32m1(dst + i, dst_gather, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t src_vec = vle32_v_f32m1(src + i, vl);\n        vint32m1_t indices_vec = vle32_v_i32m1(indices + i, vl);\n        \n        // Gather operation\n        vfloat32m1_t dst_gathered = vgather_vx_f32m1(src_vec, indices_vec, vl);\n        \n        // Scatter operation\n        vse32_v_f32m1(dst + i, dst_gathered, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t src_vec = vle32_v_f32m1(src + i, vl);\n        vint32m1_t indices_vec = vle32_v_i32m1(indices + i, vl);\n        \n        // Gather operation\n        vfloat32m1_t dst_gather = vgather_vx_f32m1(src_vec, indices_vec, vl);\n        \n        // Scatter operation\n        vse32_v_f32m1(dst + i, dst_gather, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_3_RVV", "completion": "```c\nvoid indexed_access_simd(const float *src, const int *indices, float *dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t src_vec = vle32_v_f32m1(src + i, vl);\n        vint32m1_t indices_vec = vle32_v_i32m1(indices + i, vl);\n        \n        // Gather operation\n        vfloat32m1_t dst_gather = vgather_vx_f32m1(src_vec, indices_vec, vl);\n        \n        // Scatter operation\n        vse32_v_f32m1(dst + i, dst_gather, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvl_e16m1(end - start + 1);\n    vint16m1_t vec_arr = vle16_v_i16m1(arr + start, vl);\n    vint16m1_t reversed_vec = vreversem1_v_i16m1(vec_arr);\n    vse16_v_i16m1(arr + start, reversed_vec, vl);\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvl_e16m1(end - start + 1);\n    vint16m1_t vec_arr = vle16_v_i16m1(arr + start, vl);\n    vint16m1_t reversed_vec = vreversem1_v_i16m1(vec_arr);\n    vse16_v_i16m1(arr + start, reversed_vec, vl);\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvl_e16m1(end - start + 1);\n    vint16m1_t vec_arr = vle16_v_i16(arr + start, vl);\n    vint16m1_t reversed_vec = vreversem1_vi16(vec_arr, vl);\n    vse16_v_i16(arr + start, reversed_vec, vl);\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvl_e16m1(end - start + 1);\n    vint16m1_t vec_arr = vle16_v_i16m1(arr + start, vl);\n    vint16m1_t reversed_vec = vreversem1_v_i16m1(vec_arr);\n    vse16_v_i16m1(arr + start, reversed_vec, vl);\n}\n```"}
{"task_id": "SimdBench_4_RVV", "completion": "```c\nvoid range_reverse_simd(int16_t *arr, uint64_t start, uint64_t end) {\n    size_t vl = vsetvl_e16m1(end - start + 1);\n    vint16m1_t vec_arr = vle16_v_i16m1(arr + start, vl);\n    vint16m1_t reversed_vec = vreversem1_v_i16m1(vec_arr, vl);\n    vse16_v_i16m1(arr + start, reversed_vec, vl);\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t total_elements = dim1 * dim2;\n    size_t vector_width = vsetvl_e8m1(total_elements);\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vuint8m1_t vec_tensor = vle8_v_u8m1(tensor + i, vector_width);\n        vse8_v_u8m1(slice + i, vec_tensor, vector_width);\n        i += vector_width;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t total_elements = dim1 * dim2;\n    size_t vector_width = vsetvl_e8m1(total_elements);\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vuint8m1_t vec_tensor = vle8_v_u8m1(tensor + i, vector_width);\n        vse8_v_u8m1(slice + i, vec_tensor, vector_width);\n        i += vector_width;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t total_elements = dim1 * dim2;\n    size_t vector_width = vsetvl_e8m1(total_elements);\n    size_t i = 0;\n\n    while (i < total_elements) {\n        vuint8m1_t vec_tensor = vle8_v_u8m1(tensor + i, vector_width);\n        vse8_v_u8m1(slice + i, vec_tensor, vector_width);\n        i += vector_width;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t total_elements = dim1 * dim2;\n    size_t vector_width = vsetvl_e8mf2(1); // Example vector width\n    size_t i = 0;\n\n    while (i < total_elements) {\n        size_t vl = vsetvl_e8mf2(total_elements - i);\n        const uint8_t *src_ptr = tensor + i + slice_idx * dim1 * dim2;\n        uint8_t *dst_ptr = slice + i;\n\n        vuint8m2_t vec_src = vle8_v_u8m2(src_ptr, vl);\n        vse8_v_u8m2(dst_ptr, vec_src, vl);\n\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_5_RVV", "completion": "```c\nvoid extract_tensor_slice_simd(const uint8_t *tensor, uint8_t *slice, size_t dim1, size_t dim2, size_t dim3, size_t slice_idx) {\n    size_t total_elements = dim1 * dim2;\n    size_t vector_width = vsetvl_e8m1(total_elements);\n    size_t i = 0;\n\n    while (i < total_elements) {\n        size_t vl = vsetvl_e8m1(total_elements - i);\n        vuint8m1_t vec_tensor = vle8_v_u8m1(tensor + i + slice_idx * dim1 * dim2, vl);\n        vse8_v_u8m1(slice + i, vec_tensor, vl);\n        i += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k;\n    size_t num_blocks_row = (rows + block_size - 1) / block_size;\n    size_t num_blocks_col = (cols + block_size - 1) / block_size;\n\n    for (i = 0; i < num_blocks_row; i++) {\n        for (j = 0; j < num_blocks_col; j++) {\n            size_t start_row = i * block_size;\n            size_t end_row = (start_row + block_size > rows) ? rows : start_row + block_size;\n            size_t row_count = end_row - start_row;\n\n            size_t start_col = j * block_size;\n            size_t end_col = (start_col + block_size > cols) ? cols : start_col + block_size;\n            size_t col_count = end_col - start_col;\n\n            for (k = 0; k < row_count; k++) {\n                vint16m1_t row_vec = vle16_v_i16m1(src + (start_row + k) * cols + start_col, col_count);\n                vse16_v_i16m1(dst + (start_col + k) * rows + start_row, row_vec, col_count);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k;\n    size_t num_blocks_row = (rows + block_size - 1) / block_size;\n    size_t num_blocks_col = (cols + block_size - 1) / block_size;\n\n    for (i = 0; i < num_blocks_row; i++) {\n        for (j = 0; j < num_blocks_col; j++) {\n            size_t row_start = i * block_size;\n            size_t col_start = j * block_size;\n            size_t block_rows = (row_start + block_size <= rows) ? block_size : rows - row_start;\n            size_t block_cols = (col_start + block_size <= cols) ? block_size : cols - col_start;\n\n            for (k = 0; k < block_rows; k++) {\n                vint16m1_t row_vec = vle16_v_i16(src + row_start * cols + col_start + k * cols, block_cols);\n                vse16_v_i16(dst + col_start * rows + row_start + k, row_vec, block_cols);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k;\n    size_t num_blocks_row = (rows + block_size - 1) / block_size;\n    size_t num_blocks_col = (cols + block_size - 1) / block_size;\n\n    for (i = 0; i < num_blocks_row; i++) {\n        for (j = 0; j < num_blocks_col; j++) {\n            size_t row_start = i * block_size;\n            size_t col_start = j * block_size;\n            size_t block_rows = (row_start + block_size <= rows) ? block_size : rows - row_start;\n            size_t block_cols = (col_start + block_size <= cols) ? block_size : cols - col_start;\n\n            for (k = 0; k < block_rows; k++) {\n                vint16m1_t src_vec = vle16_v_i16(src + row_start * cols + col_start + k * cols, block_cols);\n                vse16_v_i16(dst + col_start * rows + row_start + k, src_vec, block_cols);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t row_blocks = (rows + block_size - 1) / block_size;\n    size_t col_blocks = (cols + block_size - 1) / block_size;\n\n    for (size_t br = 0; br < row_blocks; br++) {\n        for (size_t bc = 0; bc < col_blocks; bc++) {\n            size_t r_start = br * block_size;\n            size_t c_start = bc * block_size;\n            size_t block_rows = (r_start + block_size <= rows) ? block_size : rows - r_start;\n            size_t block_cols = (c_start + block_size <= cols) ? block_size : cols - c_start;\n\n            for (size_t i = 0; i < block_rows; i++) {\n                for (size_t j = 0; j < block_cols; j++) {\n                    vint16m1_t row_vec = vle16_v_i16m1(src + (r_start + i) * cols + c_start, block_cols);\n                    vse16_v_i16m1(dst + (c_start + j) * rows + r_start + i, row_vec, block_cols);\n                }\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_6_RVV", "completion": "```c\nvoid blocked_matrix_transpose_simd(const int16_t *src, int16_t *dst, size_t rows, size_t cols, size_t block_size) {\n    size_t i, j, k;\n    size_t num_blocks_row = (rows + block_size - 1) / block_size;\n    size_t num_blocks_col = (cols + block_size - 1) / block_size;\n\n    for (i = 0; i < num_blocks_row; i++) {\n        for (j = 0; j < num_blocks_col; j++) {\n            size_t start_row = i * block_size;\n            size_t end_row = ((start_row + block_size) <= rows) ? (start_row + block_size) : rows;\n            size_t row_count = end_row - start_row;\n\n            size_t start_col = j * block_size;\n            size_t end_col = ((start_col + block_size) <= cols) ? (start_col + block_size) : cols;\n            size_t col_count = end_col - start_col;\n\n            size_t block_size_bytes = row_count * col_count * sizeof(int16_t);\n\n            for (k = 0; k < col_count; k += vlenb / sizeof(int16_t)) {\n                size_t vl = vsetvl_e16m1(col_count - k);\n                vint16m1_t src_block = vle16_v_i16m1(src + start_row * cols + start_col + k, vl);\n                vint16m1_t dst_block = vtranspose_v_i16m1(src_block, vl);\n                vse16_v_i16m1(dst + start_col * rows + start_row + k, dst_block, vl);\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t vl = vsetvl_e32m1(dim);\n    const float *ptr = array;\n    for (size_t i = 0; i < dim; i += vl) {\n        vfloat32m1_t vec = vle32_v_f32m1(ptr, vl);\n        ptr += vl;\n        sum += vfmacc_vf_f32m1(vec, 1.0f, sum);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t vl = vsetvl_e32m1(dim);\n    const float *ptr = array;\n    for (size_t i = 0; i < dim; i += vl) {\n        vfloat32m1_t vec = vle32_v_f32m1(ptr, vl);\n        ptr += vl;\n        sum += vfmacc_vf_f32m1(vec, 1.0f, sum);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    size_t vl = vsetvl_e32m1(dim);\n    float sum = 0.0f;\n    for (size_t i = 0; i < dim; i += vl) {\n        vfloat32m1_t vec = vle32_v_f32m1(array + i * dim * dim, vl);\n        sum += vfmacc_vf_f32m1(vec, 1.0f, vfmul_vf_f32m1(vec, i, vl));\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t vl = vsetvl_e32m1(dim);\n    const float *ptr = array;\n    for (size_t i = 0; i < dim; i += vl) {\n        vfloat32m1_t vec = vle32_v_f32m1(ptr, vl);\n        ptr += vl;\n        sum += vfmacc_vf_f32m1(vec, 1.0f, sum);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_7_RVV", "completion": "```c\nfloat diagonal_sum_3d_simd(const float *array, size_t dim) {\n    float sum = 0.0f;\n    size_t vl = vsetvl_e32m1(dim);\n    const float *ptr = array;\n    for (size_t i = 0; i < dim; i += vl) {\n        vfloat32m1_t vec = vle32_v_f32m1(ptr, vl);\n        ptr += vl;\n        sum += vfmacc_vf_f32m1(vec, 1.0f, sum);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t len = rows * cols;\n    size_t vl = vsetvl_e64m1(len);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vfloat64m1_t src_vec = vle64_v_f64m1(src + i, vl);\n        vbool64_t mask = vfredge_vs_f64m1_b64(vluxei64_v_i64m1(threshold, vl), src_vec, vl);\n        vfloat64m1_t scaled_vec = vfmsub_vf_f64m1(src_vec, scale, src_vec, vl);\n        vse64_v_f64m1(dst + i, vtern_vff_f64m1(scaled_vec, src_vec, mask, vl), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t i;\n    vfloat64m1_t v_threshold, v_scale;\n    vbool16_t v_mask;\n\n    v_threshold = vf64m1_from_float64(threshold);\n    v_scale = vf64m1_from_float64(scale);\n\n    for(i = 0; i < rows * cols; i += 16){\n        vfloat64m1_t vs = vle64_v_f64m1(src + i, 16);\n        vfloat64m1_t vd = vfredusum_vs_f64m1_f64m1(vs, vs, v_threshold, &v_mask);\n        vd = vmsle_f64m1_f64m1(vf64m1_gt(vs, v_threshold), vd, vf64m1_mul(vs, v_scale));\n        vse64_v_f64m1(dst + i, vd, 16);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t len = rows * cols;\n    size_t vl = vsetvl_e64m1(len);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vfloat64m1_t src_vec = vle64_v_f64m1(src + i, vl);\n        vbool64_t mask = vfredge_vs_f64m1_b64(vluxei64_v_i64m1(threshold, vl), src_vec, vl);\n        vfloat64m1_t scaled_vec = vfmsub_vf_f64m1(src_vec, scale, src_vec, mask);\n        vse64_v_f64m1(dst + i, scaled_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t len = rows * cols;\n    size_t vl = vsetvl_e64m1(len);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vfloat64m1_t src_vec = vle64_v_f64m1(src + i, vl);\n        vbool64_t mask = vfredge_vs_f64m1_b64(vluxei64_v_f64m1(src_vec, 0, vl), src_vec, vl);\n        vfloat64m1_t scaled_vec = vfmsub_vf_f64m1(src_vec, scale - 1.0, src_vec);\n        vse64_v_f64m1(dst + i, vmerge_vvm_f64m1(scaled_vec, src_vec, mask, vl), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_8_RVV", "completion": "```c\nvoid conditional_scale_simd(const double *src, double *dst, size_t rows, size_t cols, double threshold, double scale) {\n    size_t len = rows * cols;\n    size_t vl = vsetvl_e64m1(len);\n\n    for (size_t i = 0; i < len; i += vl) {\n        vfloat64m1_t src_vec = vle64_v_f64m1(src + i, vl);\n        vbool64_t mask = vfredge_vs_f64m1_b64(vluxei64_v_i64m1(threshold, vl), src_vec, vl);\n        vfloat64m1_t scaled_vec = vfmsub_vf_f64m1(src_vec, scale, src_vec);\n        vse64_v_f64m1(dst + i, vmerge_vvm_f64m1(src_vec, scaled_vec, mask), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row = indices[i];\n        const double *src_ptr = src + src_row * cols;\n        double *dst_ptr = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec_src = vle64_v_f64m1(src_ptr + j, vl);\n            vse64_v_f64m1(dst_ptr + j, vec_src, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row = indices[i];\n        const double *src_ptr = src + src_row * cols;\n        double *dst_ptr = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec_src = vle64_v_f64m1(src_ptr + j, vl);\n            vse64_v_f64m1(dst_ptr + j, vec_src, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row = indices[i];\n        const double *src_ptr = src + src_row * cols;\n        double *dst_ptr = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec_src = vle64_v_f64m1(src_ptr + j, vl);\n            vse64_v_f64m1(dst_ptr + j, vec_src, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row = indices[i];\n        const double *src_ptr = src + src_row * cols;\n        double *dst_ptr = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec_src = vle64_v_f64m1(src_ptr + j, vl);\n            vse64_v_f64m1(dst_ptr + j, vec_src, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_9_RVV", "completion": "```c\nvoid reorder_matrix_rows_simd(const double *src, double *dst, size_t rows, size_t cols, const size_t *indices) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        size_t src_row = indices[i];\n        const double *src_ptr = src + src_row * cols;\n        double *dst_ptr = dst + i * cols;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec_src = vle64_v_f64m1(src_ptr + j, vl);\n            vse64_v_f64m1(dst_ptr + j, vec_src, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src1_ptr = src1;\n    const int64_t *src2_ptr = src2;\n    int64_t *dst_ptr = dst;\n\n    while (length > 0) {\n        vint64m1_t vec_src1 = vle64_v_i64m1(src1_ptr, vl);\n        vint64m1_t vec_src2 = vle64_v_i64m1(src2_ptr, vl);\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl);\n        vint64m1_t vec_scalar = vmv_x_s_i64m1_m(vl, scalar);\n        vint64m1_t vec_result = vadd_vx_i64m1(vec_sum, vec_scalar, vl);\n        vec_result = vdiv_wx_i64m1(vec_result, 2, vl);\n        vse64_v_i64m1(dst_ptr, vec_result, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src1_ptr = src1;\n    const int64_t *src2_ptr = src2;\n    int64_t *dst_ptr = dst;\n\n    while (length > 0) {\n        vint64m1_t vec_src1 = vle64_v_i64m1(src1_ptr, vl);\n        vint64m1_t vec_src2 = vle64_v_i64m1(src2_ptr, vl);\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl);\n        vint64m1_t vec_scalar = vmsltu_i64m1_i64(vec_sum, 0); // Mask for negative values\n        vint64m1_t vec_result = vmadd_vx_i64m1(vec_sum, scalar, vec_scalar, vl);\n        vint64m1_t vec_divided = vdiv_vx_i64m1(vec_result, 2, vl);\n        vse64_v_i64m1(dst_ptr, vec_divided, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src1_ptr = src1;\n    const int64_t *src2_ptr = src2;\n    int64_t *dst_ptr = dst;\n\n    while (length > 0) {\n        vint64m1_t vec_src1 = vle64_v_i64m1(src1_ptr, vl);\n        vint64m1_t vec_src2 = vle64_v_i64m1(src2_ptr, vl);\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl);\n        vint64m1_t vec_scalar = vle64_v_i64m1(&scalar, 1);\n        vint64m1_t vec_result = vadd_vx_i64m1(vec_sum, vec_scalar, vl);\n        vint64m1_t vec_divided = vdiv_vx_i64m1(vec_result, 2, vl);\n        vse64_v_i64m1(dst_ptr, vec_divided, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src1_ptr = src1;\n    const int64_t *src2_ptr = src2;\n    int64_t *dst_ptr = dst;\n\n    while (length > 0) {\n        vint64m1_t vec_src1 = vle64_v_i64m1(src1_ptr, vl);\n        vint64m1_t vec_src2 = vle64_v_i64m1(src2_ptr, vl);\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl);\n        vint64m1_t vec_scalar = vle64_v_i64m1(&scalar, 1);\n        vint64m1_t vec_result = vadd_vx_i64m1(vec_sum, vec_scalar, vl);\n        vec_result = vdiv_wx_i64m1(vec_result, 2, vl);\n        vse64_v_i64m1(dst_ptr, vec_result, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_10_RVV", "completion": "```c\nvoid vector_vector_add_simd(const int64_t *src1, const int64_t *src2, int64_t *dst, int64_t scalar, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *src1_ptr = src1;\n    const int64_t *src2_ptr = src2;\n    int64_t *dst_ptr = dst;\n\n    while (length > 0) {\n        vint64m1_t vec_src1 = vle64_v_i64m1(src1_ptr, vl);\n        vint64m1_t vec_src2 = vle64_v_i64m1(src2_ptr, vl);\n        vint64m1_t vec_sum = vadd_vv_i64m1(vec_src1, vec_src2, vl);\n        vint64m1_t vec_scalar = vmv_x_s_i64m1_m(vl, scalar);\n        vint64m1_t vec_result = vadd_vx_i64m1(vec_sum, vec_scalar, vl);\n        vec_result = vdiv_wx_i64m1(vec_result, 2, vl);\n        vse64_v_i64m1(dst_ptr, vec_result, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if(length == 0) return -1;\n    \n    vint32m1_t vec_src;\n    vint32m1_t min_val = vint32m1_vint32m1_i32(-1);\n    size_t vl;\n    \n    for(size_t i=0; i<length; i+=vl){\n        vl = vsetvl_e32m1(vmin_vv_u32(length-i, length-i));\n        vec_src = vle32_v_i32m1(src + i, vl);\n        vec_src = vmsle_vx_i32m1(vec_src, 1, vl); // Mask out odd indices\n        vint32m1_t local_min = vmin_vx_i32m1(vec_src, -1, vl);\n        min_val = vmin_vv_i32m1(min_val, local_min, vl);\n    }\n    \n    return vget_v_i32(min_val);\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if(length == 0) return -1;\n    \n    vint32m1x4_t vec = {0};\n    vbool4_t mask;\n    int min_val = INT32_MAX;\n    \n    for(size_t i = 0; i < length; i += 4){\n        vint32m1x4_t vec = vle32_v_i32m1x4(&src[i], vlse32_li(4));\n        mask = vmsltu_vx_i32m1x4(vec, 0, lse32_li(4));\n        vint32m1x4_t filtered = vcompress_v_x_i32m1x4(vec, mask, vsetvl_e32m1(4));\n        \n        if(vmsum_vx_i32m1x4(filtered, 0, lse32_li(4)) > 0){\n            int temp_min = vmin_vx_i32m1x4(filtered, INT32_MAX, lse32_li(4));\n            min_val = (temp_min < min_val) ? temp_min : min_val;\n        }\n    }\n    \n    return (min_val == INT32_MAX) ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if(length == 0) return -1;\n    \n    vint32m1x4_t vec = {0};\n    vbool4_t mask;\n    int min_val = INT32_MAX;\n    \n    for(size_t i = 0; i < length; i += 4){\n        vint32m1x4_t vec = vle32_v_i32m1x4(src + i, vlse32(src + i, sizeof(int), length));\n        mask = vmsne_v_i32m1x4_i32m1(vec, 0, vlse32(src + i, sizeof(int), length));\n        vint32m1_t filtered = vcompress_v_i32m1(vec, mask);\n        int local_min = vmin_v_i32m1(filtered, vl);\n        if(local_min < min_val){\n            min_val = local_min;\n        }\n    }\n    \n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if(length == 0) return -1;\n    \n    vint32m1_t vec_src;\n    vint32m1_t min_val = vint32m1_vint32m1_i32(-1);\n    size_t vl;\n    \n    for(size_t i=0; i<length; i+=vl){\n        vl = vsetvl_e32m1(vmin_vv_u32(length-i, length-i));\n        vec_src = vle32_v_i32m1(src + i, vl);\n        vint32m1_t even_mask = vmslt_vx_u32(vec_src, 1);\n        vint32m1_t even_vals = vmseq_vx_u32(vec_src, 0);\n        vboolm1_t mask = vmseq_vx_u32(vec_src, 0);\n        vint32m1_t filtered = vcompress_vx_i32(vec_src, mask);\n        vl = vsetvl_e32m1(vmin_vv_u32(1, vl));\n        vint32m1_t current_min = vmin_vx_i32(filtered, -1);\n        min_val = vmin_vv_i32(min_val, current_min);\n    }\n    \n    return vget_v_i32_i32(min_val, 0);\n}\n```"}
{"task_id": "SimdBench_11_RVV", "completion": "```c\nint vector_even_min_simd(const int *src, size_t length){\n    if(length == 0) return -1;\n    \n    vint32m1x4_t vec = {0};\n    vbool4_t mask;\n    int min_val = INT32_MAX;\n    \n    for(size_t i = 0; i < length; i += 4){\n        vint32m1x4_t vec = vle32_v_i32m1x4(src + i, vlse32(src + i, sizeof(int), length));\n        mask = vmsne_v_i32m1_i32m1(vec, 0, vlse32(src + i, sizeof(int), length));\n        vint32m1_t filtered = vmseq_v_i32m1_i32m1(vec, vec, mask);\n        int local_min = vmin_v_i32m1_i32m1(filtered, filtered, mask);\n        if(local_min < min_val) min_val = local_min;\n    }\n    \n    return min_val == INT32_MAX ? -1 : min_val;\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int8m1_t arith_shift_vec = varrg_v_i32m1(src_vec, shift);\n    uint32m1_t uint_src_vec = vreinterpretu_i32m1_u32m1(vconv_u_i32m1(src_vec));\n    int8m1_t logic_shift_vec = vncsr_v_i32m1(uint_src_vec, shift);\n    int8m1_t result_vec = vadd_vv_i32m1(arith_shift_vec, logic_shift_vec);\n    vse32_v_i32m1(dst, result_vec, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int *src_vec = src;\n    int *dst_vec = dst;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vint32m1_t src_v = vle32_v_i32m1(src_vec, vl);\n        vint32m1_t arith_shift_v = varrg_v_i32m1(src_v, shift);\n        vuint32m1_t uint_src_v = vreinterpretu_i32m1_i32m1(src_v);\n        vuint32m1_t logic_shift_v = vlsr_v_u32m1(uint_src_v, shift);\n        vint32m1_t result_v = vadd_vv_i32m1(arith_shift_v, vreinterpret_i32m1_u32m1(logic_shift_v));\n        vse32_v_i32m1(dst_vec, result_v, vl);\n        src_vec += vl;\n        dst_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int8m1_t arith_shift_vec = varrg_v_i32m1(src_vec, shift);\n    uint32m1_t uint_src_vec = vreinterpret_u32m1_i32m1(src_vec);\n    int8m1_t logic_shift_vec = vncsr_v_i32m1(uint_src_vec, shift);\n    int8m1_t result_vec = vadd_vv_i32m1(arith_shift_vec, logic_shift_vec);\n    vse32_v_i32m1(dst, result_vec, vl);\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int *src_vec = src;\n    int *dst_vec = dst;\n\n    while (length > 0) {\n        vint32m1_t src_v = vle32_v_i32m1(src_vec, vl);\n        vint32m1_t arithmetic_shift_v = vsra_vx_i32m1(src_v, shift, vl);\n        vuint32m1_t uint_src_v = vreinterpretu_i32_u32m1(src_v);\n        vuint32m1_t logical_shift_v = vsrl.vx_u32m1(uint_src_v, shift, vl);\n        vint32m1_t sum_v = vadd_vx_i32m1(arithmetic_shift_v, logical_shift_v, vl);\n        vse32_v_i32m1(dst_vec, sum_v, vl);\n\n        length -= vl;\n        src_vec += vl;\n        dst_vec += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_12_RVV", "completion": "```c\nvoid mixed_right_shift_simd(const int *src, int *dst, uint8_t shift, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const int8m1_t src_vec = vle32_v_i32m1(src, vl);\n    int8m1_t arith_shift_vec = varrcl_i32m1(src_vec, shift, vl);\n    uint32m1_t uint_src_vec = vreinterpret_u32m1_i32m1(src_vec);\n    int8m1_t logic_shift_vec = vseal_v_u32m1(vlse32_v_u32m1(uint_src_vec, shift, vl), vl);\n    int8m1_t result_vec = vadd_vv_i32m1(arith_shift_vec, logic_shift_vec, vl);\n    vse32_v_i32m1(dst, result_vec, vl);\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    int64_t sum = 0;\n\n    vint32m1x4_t vec;\n    size_t i = 0;\n    for (; i + 4 <= total_elements; i += 4) {\n        vec = vle32_v_i32m1x4(matrix + i, 4);\n        sum += vsum_v_i32m1x4(vec);\n    }\n\n    for (; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    int64_t sum = 0;\n\n    vint32m1_t vec_sum = vint32m1_zero();\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        vint32m1_t vec = vle32_v_i32m1(matrix + i, 8);\n        vec_sum = vadd_vx_i32m1(vec_sum, vec);\n    }\n\n    for (; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    sum += vsum_v_i32m1(vec_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    int64_t sum = 0;\n\n    vint32m1x4_t vec_sum = vint32m1x4_zero();\n    size_t i = 0;\n\n    for (; i + 4 <= total_elements; i += 4) {\n        vint32m1_t vec = vle32_v_i32m1(matrix + i, 4);\n        vec_sum = vaddv_i32m1x4(vec_sum, vec);\n    }\n\n    for (; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    sum += vsum_v_i32m1x4_int64(vec_sum);\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    int64_t sum = 0;\n\n    vint32m1x4_t vec_sum;\n    vint32m1_t vec_temp;\n    const int *ptr = matrix;\n\n    while (total_elements >= 4) {\n        vec_sum = vle32_v_i32m1x4(ptr, vlmax());\n        ptr += 4;\n        total_elements -= 4;\n\n        vec_temp = vadd_vv_i32m1(vec_sum, vlmax());\n        sum += vgetsum_v_i32m1(vec_temp, vlmax());\n    }\n\n    // Handle remaining elements\n    while (total_elements > 0) {\n        sum += *ptr++;\n        total_elements--;\n    }\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_13_RVV", "completion": "```c\nint64_t matrix_sum_simd(const int *matrix, size_t rows, size_t cols) {\n    size_t total_elements = rows * cols;\n    int64_t sum = 0;\n\n    vint32m1_t vec_sum = vint32m1_zero();\n    size_t i = 0;\n\n    for (; i + 8 <= total_elements; i += 8) {\n        vint32m1_t vec = vle32_v_i32m1(matrix + i, 8);\n        vec_sum = vadd_vx_i32m1(vec_sum, 0); // Initialize reduction\n        vec_sum = vredsum_vs_i32m1_i32m1(vec_sum, vec, vint32m1_zero());\n    }\n\n    for (; i < total_elements; i++) {\n        sum += matrix[i];\n    }\n\n    return sum + (int64_t)vgetsum_v_i32m1(vec_sum);\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    vint8m1_t vec;\n    vbool16m2_t mask;\n    size_t max_idx = 0;\n    size_t i = 0;\n\n    while (i + 16 <= length) {\n        vec = vle8_v_i8m1(src + i, vlse8_v_i8m1(&length, src + i, vsetvl_e8m1(length)));\n        mask = vmseq_v_i8m1_i8(vec, vlsb8_v_i8m1(vec, vsetvl_e8m1(1)));\n        size_t idx = vfirst_b16m2(mask);\n        if (idx != -1 && (src[max_idx] < src[i + idx])) {\n            max_idx = i + idx;\n        }\n        i += 16;\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > src[max_idx]) {\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    vint8m1_t vec;\n    vint8m1_t max_vec = vle8_v_i8m1(src, 1);\n    vbool16m2_t mask;\n    size_t max_idx = 0;\n\n    for (size_t i = 1; i < length; i += 16) {\n        vec = vle8_v_i8m1(src + i, 1);\n        mask = vmgt_vv_b16m2(vec, max_vec, 16);\n        max_vec = vmerge_vx_i8m1(max_vec, vec, mask, 16);\n        max_idx = vfirst_b16m2(mask) + i;\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    vint8m1_t vec;\n    vint8m1_t max_vec = vle8_v_i8m1(src, 1);\n    vbool16m2_t mask;\n    size_t max_idx = 0;\n\n    for (size_t i = 1; i < length; i += 16) {\n        vec = vle8_v_i8m1(src + i, 1);\n        mask = vmgt_vv_b16m2(vec, max_vec, 16);\n        max_vec = vmerge_vx_i8m1(max_vec, vec, mask, 16);\n        max_idx = vfirst_b16m2(mask) + i;\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    vint8m1_t vec;\n    vbool16m2_t mask;\n    size_t max_idx = 0;\n    size_t idx = 0;\n    int8_t max_val = src[0];\n    const int8_t *src_end = src + length;\n\n    while ((intptr_t)src + vl <= (intptr_t)src_end) {\n        vec = vle8_v_i8m1(src, vl);\n        mask = vmslt_vx_i8m1(vec, max_val, vl);\n        if (vmall2_b16m2(mask)) {\n            // No update needed\n        } else {\n            max_val = vlsge_vx_i8m1(vec, max_val, vl, &idx);\n            if (max_val > src[max_idx]) {\n                max_idx = idx;\n            }\n        }\n        src += vl;\n        idx += vl;\n    }\n\n    while (src < src_end) {\n        if (*src > max_val) {\n            max_val = *src;\n            max_idx = idx;\n        }\n        src++;\n        idx++;\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_14_RVV", "completion": "```c\nsize_t argmax_simd(const int8_t *src, size_t length) {\n    if (length == 0) return 0;\n\n    vint8m1_t vec;\n    vbool16m2_t mask;\n    size_t max_idx = 0;\n    size_t i = 0;\n\n    while (i + 16 <= length) {\n        vec = vle8_v_i8m1(src + i, vlse8_v_i8m1(&length, src + i, vl));\n        mask = vmseq_v_i8m1_i8(vec, vlsb8_v_i8m1(vlse8_v_i8m1(&length, src + i, vl), vl), vl);\n        size_t local_max_idx = i + vlsb8_v_i8m1(vec, mask, vl);\n        if (local_max_idx > max_idx) {\n            max_idx = local_max_idx;\n        }\n        i += 16;\n    }\n\n    for (; i < length; i++) {\n        if (src[i] > src[max_idx]) {\n            max_idx = i;\n        }\n    }\n\n    return max_idx;\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint16m1_t src1_vec = vle16_v_u16m1(src1 + i, vl);\n        vuint16m1_t src2_vec = vle16_v_u16m1(src2 + i, vl);\n        vbool16_t mask_vec = vmsltu_vx_u32(i, mask);\n        vuint16m1_t res_vec = vmerge_vvm_u16m1(src1_vec, src2_vec, mask_vec);\n        vse16_v_u16m1(dst + i, res_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16_t* src1_ptr = src1;\n    const uint16_t* src2_ptr = src2;\n    uint16_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint16m1_t src1_vec = vle16_v_u16m1(src1_ptr, vl);\n        vuint16m1_t src2_vec = vle16_v_u16m1(src2_ptr, vl);\n        vbool16_t mask_vec = vmseq_vx_u32(vluxu_i32(0, vl), mask);\n\n        vse16_v_u16m1(dst_ptr, vmsltu_vx_u16(src1_vec, src2_vec, mask_vec), vl);\n\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n        length -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16_t* src1_ptr = src1;\n    const uint16_t* src2_ptr = src2;\n    uint16_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint16m1_t src1_vec = vle16_v_u16m1(src1_ptr, vl);\n        vuint16m1_t src2_vec = vle16_v_u16m1(src2_ptr, vl);\n        vbool16_t mask_vec = vmsne_vx_u32(vl, (uint32_t)(vilanei16(src1_vec, vl) & mask));\n\n        vse16_v_u16m1(dst_ptr, vternary_v_vx_u16m1(src1_vec, src2_vec, mask_vec, vl), vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint16m1_t src1_vec = vle16_v_u16m1(src1 + i, vl);\n        vuint16m1_t src2_vec = vle16_v_u16m1(src2 + i, vl);\n        vbool16_t mask_vec = vmsltu_vx_u32(i, mask);\n        vuint16m1_t res_vec = vmerge_vvm_u16(src1_vec, src2_vec, mask_vec);\n        vse16_v_u16m1(dst + i, res_vec, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_15_RVV", "completion": "```c\nvoid vector_blend_simd(const uint16_t* src1, const uint16_t* src2, uint32_t mask, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16_t* src1_ptr = src1;\n    const uint16_t* src2_ptr = src2;\n    uint16_t* dst_ptr = dst;\n\n    for (size_t i = 0; i < length; i += vl) {\n        vuint16m1_t src1_vec = vle16_v_u16m1(src1_ptr, vl);\n        vuint16m1_t src2_vec = vle16_v_u16m1(src2_ptr, vl);\n        vbool16_t mask_vec = vmsltu_vx_u32(vsub_vx_u32(vindex_v_u32(lmul=1), i), mask);\n\n        vse16_v_u16m1(dst_ptr, vmv_x_s_u16m1_m(mask_vec, src1_vec, src2_vec), vl);\n\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint32m1_t popcnt_vec = vpopc_v_u32m1(src_vec);\n        vse32_v_u32m1(dst_ptr, popcnt_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint32m1_t popcnt_vec = vpopc_v_u32m1(src_vec);\n        vse32_v_u32m1(dst_ptr, popcnt_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint32m1_t popcnt_vec = vpopc_v_u32m1(src_vec);\n        vse32_v_u32m1(dst_ptr, popcnt_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint32m1_t popcnt_vec = vpopc_v_u32m1(src_vec);\n        vse32_v_u32m1(dst_ptr, popcnt_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_16_RVV", "completion": "```c\nvoid population_count_simd(const uint32_t* src, uint32_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint32m1_t popcnt_vec = vpopc_v_u32m1(src_vec);\n        vse32_v_u32m1(dst_ptr, popcnt_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16xm1_t vsrc1 = vle16_v_u16m1(src1, vl);\n    const uint16xm1_t vsrc2 = vle16_v_u16m1(src2, vl);\n    uint16xm1_t vd = vaddu_sat_vv_u16m1(vsrc1, vsrc2, vl);\n    vse16_v_u16m1(dst, vd, vl);\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16xm1_t vsrc1 = vle16_v_u16m1(src1, vl);\n    const uint16xm1_t vsrc2 = vle16_v_u16m1(src2, vl);\n    uint16xm1_t vd = vaddu_sat_vv_u16m1(vsrc1, vsrc2, vl);\n    vse16_v_u16m1(dst, vd, vl);\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16xm1_t vsrc1 = vle16_v_u16m1(src1, vl);\n    const uint16xm1_t vsrc2 = vle16_v_u16m1(src2, vl);\n    uint16xm1_t vd = vaddu_sat_vv_u16m1(vsrc1, vsrc2, vl);\n    vse16_v_u16m1(dst, vd, vl);\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16xm1_t vsrc1 = vle16_v_u16m1(src1, vl);\n    const uint16xm1_t vsrc2 = vle16_v_u16m1(src2, vl);\n    uint16xm1_t vd = vaddu_sat_vv_u16m1(vsrc1, vsrc2, vl);\n    vse16_v_u16m1(dst, vd, vl);\n}\n```"}
{"task_id": "SimdBench_17_RVV", "completion": "```c\nvoid saturating_add_simd(const uint16_t* src1, const uint16_t* src2, uint16_t* dst, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const uint16xm1_t vsrc1 = vle16_v_u16m1(src1, vl);\n    const uint16xm1_t vsrc2 = vle16_v_u16m1(src2, vl);\n    uint16xm1_t vd = vaddu_sat_vv_u16m1(vsrc1, vsrc2, vl);\n    vse16_v_u16m1(dst, vd, vl);\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vbool64 mask = 0;\n            double acc = 0.0;\n            for (size_t k = 0; k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    mask = vmseq_vb_mask(vlede_vd(a, vl), vlede_vd(b, vl));\n                    acc += vfmacc_vd_vs(acc, vlede_vd(b, vl), mask, vl);\n                }\n            }\n            C[i * p + j] = acc;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vbool64 mask = 0;\n            double acc = 0.0;\n            for (size_t k = 0; k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    mask = vmseq_vb_mask(vlede_vd(a, vl), vlede_vd(b, vl));\n                    acc += vfmacc_vd_vs(acc, vlede_vd(b, vl), mask, vl);\n                }\n            }\n            C[i * p + j] = acc;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vbool64 mask = 0;\n            double acc = 0.0;\n            for (size_t k = 0; k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    mask = vmseq_vb_mask(vlede_vd(a, vl), vlede_vd(b, vl));\n                    acc += a * b;\n                }\n            }\n            C[i * p + j] = acc;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vbool64 mask = 0;\n            double sum = 0.0;\n            for (size_t k = 0; k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    mask = vmseq_vx_mask(mask, a, -100.0, vl);\n                    mask = vmseq_vx_mask(mask, a, 100.0, vl);\n                    mask = vmseq_vx_mask(mask, b, -100.0, vl);\n                    mask = vmseq_vx_mask(mask, b, 100.0, vl);\n                    sum += a * b;\n                }\n            }\n            C[i * p + j] = sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_18_RVV", "completion": "```c\nvoid range_matrix_mul_simd(const double* A, const double* B, double* C, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vbool64 mask = 0;\n            double acc = 0.0;\n            for (size_t k = 0; k < n; k++) {\n                double a = A[i * n + k];\n                double b = B[k * p + j];\n                if (a >= -100.0 && a <= 100.0 && b >= -100.0 && b <= 100.0) {\n                    mask = vmseq_vb_mask(vlede_vd(a, vl), vlede_vd(b, vl));\n                    acc += vfmacc_vd_vs(acc, vlede_vd(b, vl), mask, vl);\n                }\n            }\n            C[i * p + j] = acc;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vint64m1_t vec_A = vle64_v_i64m1(A + i, vl);\n        vint64m1_t vec_B = vle64_v_i64m1(B + i, vl);\n        vint64m1_t vec_C = vadd_vv_i64m1(vec_A, vec_B, vl);\n        vse64_v_i64m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vint64m1_t vec_A = vle64_v_i64m1(A + i, vl);\n        vint64m1_t vec_B = vle64_v_i64m1(B + i, vl);\n        vint64m1_t vec_C = vadd_vv_i64m1(vec_A, vec_B, vl);\n        vse64_v_i64m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vint64m1_t vec_A = vle64_v_i64m1(A + i, vl);\n        vint64m1_t vec_B = vle64_v_i64m1(B + i, vl);\n        vint64m1_t vec_C = vadd_vv_i64m1(vec_A, vec_B, vl);\n        vse64_v_i64m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vint64m1_t vec_A = vle64_v_i64m1(A + i, vl);\n        vint64m1_t vec_B = vle64_v_i64m1(B + i, vl);\n        vint64m1_t vec_C = vadd_vv_i64m1(vec_A, vec_B, vl);\n        vse64_v_i64m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_19_RVV", "completion": "```c\nvoid tensor_add_3d_simd(const int64_t* A, const int64_t* B, int64_t* C, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e64m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vint64m1_t vec_A = vle64_v_i64m1(A + i, vl);\n        vint64m1_t vec_B = vle64_v_i64m1(B + i, vl);\n        vint64m1_t vec_C = vadd_vv_i64m1(vec_A, vec_B, vl);\n        vse64_v_i64m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const float* src1_ptr = src1;\n    const float* src2_ptr = src2;\n    float* dst_ptr = dst;\n\n    while (length > 0) {\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1_ptr, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2_ptr, vl);\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl);\n        vint32m1_t vec_rounded = vrndint_v_f32m1_f32m1(vec_sum, vl);\n        vse32_v_f32m1(dst_ptr, vec_rounded, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const float* src1_ptr = src1;\n    const float* src2_ptr = src2;\n    float* dst_ptr = dst;\n\n    while (length > 0) {\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1_ptr, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2_ptr, vl);\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl);\n        vint32m1_t vec_rounded = vrndint_v_f32m1_f32m1(vec_sum, vl);\n        vse32_v_f32m1(dst_ptr, vec_rounded, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const float* src1_ptr = src1;\n    const float* src2_ptr = src2;\n    float* dst_ptr = dst;\n\n    while (length > 0) {\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1_ptr, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2_ptr, vl);\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl);\n        vint32m1_t vec_rounded = vrndint_v_f32m1_to_i32m1(vec_sum, vl);\n        vse32_v_f32m1(dst_ptr, vec_rounded, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const float* src1_ptr = src1;\n    const float* src2_ptr = src2;\n    float* dst_ptr = dst;\n\n    while (length > 0) {\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1_ptr, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2_ptr, vl);\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl);\n        vint32m1_t vec_rounded = vrndint_v_f32m1_to_i32m1(vec_sum, vl);\n        vse32_v_f32m1(dst_ptr, vec_rounded, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_20_RVV", "completion": "```c\nvoid vector_add_round_nearest_simd(const float* src1, const float* src2, float* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const float* src1_ptr = src1;\n    const float* src2_ptr = src2;\n    float* dst_ptr = dst;\n\n    while (length > 0) {\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1_ptr, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2_ptr, vl);\n        vfloat32m1_t vec_sum = vfadd_vv_f32m1(vec_src1, vec_src2, vl);\n        vint32m1_t vec_rounded = vrndint_v_f32m1_to_i32m1(vec_sum, vl);\n        vse32_v_f32m1(dst_ptr, vec_rounded, vl);\n\n        length -= vl;\n        src1_ptr += vl;\n        src2_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    for(size_t i=0; i<length; i+=vl){\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl);\n        vboolm1_t mask = vmseq_vf_f32m1(vfredusum_vs_f32m1_f32m1_mask(vec_src1, vec_src2, vl), 50.0f, vl);\n        vfloat32m1_t vec_diff = vsub_vv_f32m1(vec_src1, vec_src2, vl);\n        vboolm1_t index_mask = vmseq_vf_u32m1(vluxei32_v_i32m1(src1 + i, vl), 2, vl);\n        vboolm1_t final_mask = vbmsk_bm(mask & index_mask);\n        vfloat32m1_t vec_result = vfmul_vv_f32m1(vec_src1, vec_src2, vl);\n        vec_result = vfredusum_vs_f32m1_f32m1_mask(vec_result, 1.0f, final_mask);\n        vse32_v_f32m1(dst + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    for(size_t i=0; i<length; i+=vl){\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl);\n        vboolm1_t mask = vmsltu_vf_f32m1_f32m1(vec_src1, vec_src2, vl, 50.0f);\n        mask = vmseq_vf_f32m1_f32m1(mask, vec_src1, vec_src2, vl, 2);\n        vfloat32m1_t vec_result = vfadd_vf_f32m1(vec_src1, vec_src2, vl);\n        vec_result = vfwadd_w_v_f32m1(vec_result, vl);\n        vse32_v_f32m1(dst + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    for(size_t i=0; i<length; i+=vl){\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl);\n        vboolm1_t mask = vmsltu_vx_f32m1(vfredusum_vs_f32m1_f32m1(vec_sub_v_f32m1(vec_abs_v_f32m1(vec_sub_v_f32m1(vec_src1, vec_src2)), vfmul_vx_f32m1(vec_src1, 0.5f, vl), vl), vl), 50.0f, vl);\n        vfloat32m1_t vec_result = vmseq_vx_f32m1(vluxei32_v_f32m1(src1 + i, vlsse32_v_i32m1(vluxei32_v_i32m1(vlsegw_v_i32m1(i, vl), 0, vl), 2, vl), vl), 0.0f, vl) ? vfadd_vx_f32m1(vfrintu_v_f32m1(vfmul_v_f32m1(vec_src1, vec_src2, vl), vl), 0.5f, vl) : vfmv_s_f32m1(-1.0f, vl);\n        vse32_v_f32m1(dst + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    for(size_t i=0; i<length; i+=vl){\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl);\n        vboolm1_t mask = vmsge_vf_f32m1(vfabs_v_f32m1(vsub_vv_f32m1(vec_src1, vec_src2)), 50.0f);\n        vboolm1_t index_mask = vbextui_v_b8m1((uint64_t)i, 1, vl);\n        mask = vmseq_vx_b8m1(mask, index_mask);\n        vfloat32m1_t vec_result = vfredroundup_vs_f32m1_f32m1(vfmul_vv_f32m1(vec_src1, vec_src2, vl), vfsub_vx_f32m1(vec_src1, -1.0f, vl), mask);\n        vse32_v_f32m1(dst + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_21_RVV", "completion": "```c\nvoid vector_mul_round_up_simd(const float* src1, const float* src2, float* dst, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    for(size_t i=0; i<length; i+=vl){\n        vfloat32m1_t vec_src1 = vle32_v_f32m1(src1 + i, vl);\n        vfloat32m1_t vec_src2 = vle32_v_f32m1(src2 + i, vl);\n        vboolm1_t mask = vmsltu_vx_f32m1(vec_src1, vec_src2, 50.0f);\n        mask = vmseq_vx_u32m1(vmsub_vv_u32m1(vmseq_vx_u32m1(vilez_v_u32m1(), vl), vl), vl);\n        vfloat32m1_t vec_result = vfredusum_vs_f32m1_f32m1(mask, vfmul_vv_f32m1(vec_src1, vec_src2, vl), vfmul_vx_f32m1(vec_src1, -1.0f, vl));\n        vse32_v_f32m1(dst + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vdouble_t vec_mat = vle64_v_f64m1(mat + i * n, vl);\n        vdouble_t vec_res = vfmsub_vf_f64m1(vec_mat, scalar, vec_mat);\n        vse64_v_f64m1(dst + i * n, vec_res, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vdouble_t vec_mat = vle64_v_f64m1(mat + i * n, vl);\n        vdouble_t vec_res = vfmsub_vf_f64m1(vec_mat, scalar, vec_mat);\n        vse64_v_f64m1(dst + i * n, vec_res, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vdouble_t vec_mat = vle64_v_f64m1(mat + i * n, vl);\n        vdouble_t vec_res = vfmsub_vf_f64m1(vec_mat, scalar, vec_mat);\n        vse64_v_f64m1(dst + i * n, vec_res, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vdouble_t vec_mat = vle64_v_f64m1(mat + i * n, vl);\n        vdouble_t vec_res = vfmsub_vf_f64m1(vec_mat, scalar, vec_mat);\n        vse64_v_f64m1(dst + i * n, vec_res, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_22_RVV", "completion": "```c\nvoid matrix_scalar_mul_simd(const double* mat, double scalar, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vdouble_t vec_mat = vle64_v_f64m1(mat + i * n, vl);\n        vdouble_t vec_res = vfmsub_vf_f64m1(vec_mat, scalar, vec_mat);\n        vse64_v_f64m1(dst + i * n, vec_res, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        size_t offset = i * n;\n        vfloat32m1_t row = vle32_v_f32m1(mat + offset, vl);\n        vfloat32m1_t squared = vfmul_vf_f32m1(row, row, vl);\n        float sum = 0.0f;\n        for (size_t j = 0; j < n; j++) {\n            sum += squared[j];\n        }\n        float norm = sqrtf(sum);\n        if (norm > 0.0f) {\n            vfloat32m1_t normalized = vfdiv_vf_f32m1(row, norm, vl);\n            vse32_v_f32m1(mat + offset, normalized, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t row_vec = vle32_v_f32m1(mat + i * n, vl);\n        vfloat32m1_t squared = vfmul_vf_f32m1(row_vec, row_vec, vl);\n        float sum_squares = 0.0f;\n        for (size_t j = 0; j < n; j++) {\n            sum_squares += squared[j];\n        }\n        float norm = sqrtf(sum_squares);\n        if (norm > 0.0f) {\n            vfloat32m1_t norm_vec = vfmul_vf_f32m1(row_vec, 1.0f / norm, vl);\n            vse32_v_f32m1(mat + i * n, norm_vec, vl);\n        } else {\n            for (size_t j = 0; j < n; j++) {\n                mat[i * n + j] = 0.0f;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t row_vec;\n        vfloat32m1_t sum_squares = vle32_v_f32m1(mat + i * n, vl);\n        sum_squares = vfmsub_vv_f32m1(sum_squares, sum_squares, 0.0f, vl);\n        for (size_t j = 1; j < n; j++) {\n            row_vec = vle32_v_f32m1(mat + i * n + j, vl);\n            sum_squares = vfadd_vv_f32m1(sum_squares, row_vec, row_vec, vl);\n        }\n        float norm = sqrt(vfredosum_vs_f32m1_f32m1(sum_squares, sum_squares, 0.0f, vl));\n        if (norm > 0.0f) {\n            row_vec = vle32_v_f32m1(mat + i * n, vl);\n            row_vec = vfmul_vx_f32m1(row_vec, 1.0f / norm, vl);\n            vse32_v_f32m1(mat + i * n, row_vec, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t row_vec;\n        vfloat32m1_t sum_squares = vfmul_vf_f32m1(row_vec, 0.0f, vl);\n        for (size_t j = 0; j < n; j++) {\n            row_vec = vle32_v_f32m1(mat + i * n + j, vl);\n            vfloat32m1_t squared = vfmul_vf_f32m1(row_vec, row_vec, vl);\n            sum_squares = vfadd_vf_f32m1(sum_squares, squared, vl);\n        }\n        float norm = sqrt(vfsum_f32m1(sum_squares, vl));\n        if (norm > 0.0f) {\n            vfloat32m1_t norm_vec = vfmul_vf_f32m1(row_vec, 1.0f / norm, vl);\n            vse32_v_f32m1(mat + i * n, norm_vec, vl);\n        } else {\n            // Handle division by zero if necessary\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_23_RVV", "completion": "```c\nvoid matrix_normalize_rows_simd(float* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t row_vec = vle32_v_f32m1(mat + i * n, vl);\n        vfloat32m1_t squared = vfmul_vf_f32m1(row_vec, row_vec, vl);\n        float sum_squares = 0.0f;\n        for (size_t j = 0; j < vl; j++) {\n            sum_squares += squared[j];\n        }\n        float norm = sqrtf(sum_squares);\n        if (norm > 0.0f) {\n            vfloat32m1_t norm_vec = vfmul_vf_f32m1(row_vec, 1.0f / norm, vl);\n            vse32_v_f32m1(mat + i * n, norm_vec, vl);\n        } else {\n            for (size_t j = 0; j < n; j++) {\n                mat[i * n + j] = 0.0f;\n            }\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vint64m1_t sum = v\u52d20m1();\n            for (size_t k = 0; k < n; k++) {\n                vint64m1_t a = vle64_v_i64m1(mat1 + i * n + k);\n                vint64m1_t b = vle64_v_i64m1(mat2 + k * p + j);\n                vint64m1_t prod = vmul_vv_i64m1(a, b, vl);\n                sum = vadd_vv_i64m1(sum, prod, vl);\n            }\n            int64_t rounded_sum = vfredround_vs_i64m1_i64m1(sum, v\u52d20m1(), vl);\n            dst[i * p + j] = rounded_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vint64m1_t sum = vle64_v_i64m1(mat2 + j * n, vl);\n            for (size_t k = 0; k < n; k++) {\n                vint64m1_t temp = vfmul_vx_i64m1(vle64_v_f64m1(mat1 + i * n + k, vl), mat2[k * p + j], vl);\n                sum = vadd_vv_i64m1(sum, temp, vl);\n            }\n            vse64_v_i64m1(dst + i * p + j, vround_v_i64m1(sum, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vint64m1_t sum = v\u52d20m1();\n            for (size_t k = 0; k < n; k++) {\n                vint64m1_t a = vle64_v_i64m1(mat1 + i * n + k);\n                vint64m1_t b = vle64_v_i64m1(mat2 + k * p + j);\n                vint64m1_t prod = vmul_vv_i64m1(a, b, vl);\n                sum = vadd_vv_i64m1(sum, prod, vl);\n            }\n            int64_t rounded_sum = vround_to_int(sum);\n            dst[i * p + j] = rounded_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vint64m1_t sum = v\u52d20m1(0);\n            for (size_t k = 0; k < n; k++) {\n                vint64m1_t a = vle64_v_i64m1(mat1 + i * n + k);\n                vint64m1_t b = vle64_v_i64m1(mat2 + k * p + j);\n                vint64m1_t prod = vmul_vv_i64m1(a, b);\n                sum = vadd_vv_i64m1(sum, prod);\n            }\n            int64_t rounded_sum = vround_to_int(sum);\n            dst[i * p + j] = rounded_sum;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_24_RVV", "completion": "```c\nvoid matrix_mul_round_int_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n, size_t p) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        for (size_t j = 0; j < p; j++) {\n            vint64m1_t sum = v\u52d20m1(0);\n            for (size_t k = 0; k < n; k++) {\n                vint64m1_t a = vle64_v_i64m1(mat1 + i * n + k);\n                vint64m1_t b = vle64_v_i64m1(mat2 + k * p + j);\n                vint64m1_t prod = vmul_vv_i64m1(a, b);\n                sum = vadd_vv_i64m1(sum, prod);\n            }\n            dst[i * p + j] = vroundint_v_f64m1(sum);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat32m1_t vec_in = vle32_v_f32m1(src + i + j * rows, vl);\n            vfloat32m1_t vec_out = vroundq_f32m1(vec_in);\n            vse32_v_f32m1(dst + j + i * cols, vec_out, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat32m1_t vec_in = vle32_v_f32m1(src + j + i * cols, vl);\n            vfloat32m1_t vec_out = vfncvt_x_f_f_v_f32m1(vec_in, vl);\n            vfloat32m1_t vec_rounded = vroundeven_v_f32m1(vec_out, vl);\n            vse32_v_f32m1(dst + j * rows + i, vec_rounded, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat32m1_t vec_in = vle32_v_f32m1(src + j + i * cols, vl);\n            vfloat32m1_t vec_out = vfadd_vf_f32m1(vfdiv_vf_f32m1(vec_in, 4.0f), 0.5f, vl);\n            vse32_v_f32m1(dst + j * rows + i, vec_out, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat32m1_t vec_in = vle32_v_f32m1(src + i + j * rows, vl);\n            vfloat32m1_t vec_out = vroundq_f32m1(vec_in);\n            vse32_v_f32m1(dst + j + i * cols, vec_out, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_25_RVV", "completion": "```c\nvoid matrix_transpose_round_quarter_simd(const float* src, float* dst, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat32m1_t vec_in = vle32_v_f32m1(src + j + i * cols, vl);\n            vfloat32m1_t vec_out = vfadd_vf_f32m1(vec_in, 0.25f, vl);\n            vec_out = vfrint_r_v_f32m1(vec_out, vl); // Round to nearest integer\n            vec_out = vfsub_vf_f32m1(vec_out, 0.25f, vl); // Subtract 0.25 to round to nearest quarter\n            vse32_v_f32m1(dst + j * rows + i, vec_out, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m1_t vec_tensor1 = vle32_v_f32m1(tensor1 + i, vl);\n        vfloat32m1_t vec_tensor2 = vle32_v_f32m1(tensor2 + i, vl);\n        vfloat32m1_t vec_result = vfsub_vv_f32m1(vec_tensor1, vec_tensor2, vl);\n        vint32m1_t vec_rounded = vrndms_v_f32m1(vec_result, vl);\n        vse32_v_f32m1(dst + i, vec_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_tensor1 = vle32_v_f32m8(tensor1 + i, vl);\n        vfloat32m8_t vec_tensor2 = vle32_v_f32m8(tensor2 + i, vl);\n        vfloat32m8_t vec_diff = vfsub_vv_f32m8(vec_tensor1, vec_tensor2, vl);\n        vint32m8_t vec_rounded = vrndms_v_f32m8(vec_diff, vl);\n        vse32_v_f32m8(dst + i, vec_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_tensor1 = vle32_v_f32m8(tensor1 + i, vl);\n        vfloat32m8_t vec_tensor2 = vle32_v_f32m8(tensor2 + i, vl);\n        vfloat32m8_t vec_result = vfsub_vv_f32m8(vec_tensor1, vec_tensor2, vl);\n        vint32m8_t vec_rounded = vfrsub_round_to_zero_v_f32m8(vec_result, vl);\n        vse32_v_f32m8(dst + i, vec_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_tensor1 = vle32_v_f32m8(tensor1 + i, vl);\n        vfloat32m8_t vec_tensor2 = vle32_v_f32m8(tensor2 + i, vl);\n        vfloat32m8_t vec_diff = vfsub_vv_f32m8(vec_tensor1, vec_tensor2, vl);\n        vint32m8_t vec_rounded = vrndms_v_f32m8(vec_diff, vl);\n        vse32_v_f32m8(dst + i, vec_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_26_RVV", "completion": "```c\nvoid tensor3d_sub_round_zero_simd(const float* tensor1, const float* tensor2, float* dst, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m1_t vec_tensor1 = vle32_v_f32m1(tensor1 + i, vl);\n        vfloat32m1_t vec_tensor2 = vle32_v_f32m1(tensor2 + i, vl);\n        vfloat32m1_t vec_result = vfsub_vv_f32m1(vec_tensor1, vec_tensor2, vl);\n        vint32m1_t vec_rounded = vrndt_v_f32m1(vec_result, vl);\n        vse32_v_f32m1(dst + i, vec_rounded, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        const double* row1 = mat1 + i * n;\n        const double* row2 = mat2 + i * n;\n        double* row_dst = dst + i * n;\n        vfloat64xm1_t vec1, vec2;\n        for (size_t j = 0; j < n; j += vl) {\n            vec1 = vle64_v_f64m1(row1 + j, vl);\n            vec2 = vle64_v_f64m1(row2 + j, vl);\n            vse64_v_f64m1(row_dst + j, vmul_vv_f64m1(vec1, vec2, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        const double* row1 = mat1 + i * n;\n        const double* row2 = mat2 + i * n;\n        double* row_dst = dst + i * n;\n        vfloat64xm1_t vec1, vec2;\n        for (size_t j = 0; j < n; j += vl) {\n            vec1 = vle64_v_f64m1(row1 + j, vl);\n            vec2 = vle64_v_f64m1(row2 + j, vl);\n            vse64_v_f64m1(row_dst + j, vmul_vv_f64m1(vec1, vec2, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        const double* row1 = mat1 + i * n;\n        const double* row2 = mat2 + i * n;\n        double* row_dst = dst + i * n;\n        vdoublex1_t vec1, vec2, res;\n        for (size_t j = 0; j < n; j += vl) {\n            vec1 = vle64_v_f64m1(row1 + j, vl);\n            vec2 = vle64_v_f64m1(row2 + j, vl);\n            res = vfmsub_vv_f64m1(vec1, vec2, vec1); // Element-wise multiplication\n            vse64_v_f64m1(row_dst + j, res, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        const double* row1 = mat1 + i * n;\n        const double* row2 = mat2 + i * n;\n        double* row_dst = dst + i * n;\n        vdoublex1_t vec1, vec2, res;\n        for (size_t j = 0; j < n; j += vl) {\n            vec1 = vle64_v_f64m1(row1 + j, vl);\n            vec2 = vle64_v_f64m1(row2 + j, vl);\n            res = vfmsub_vv_f64m1(vec1, vec2, vec1); // Element-wise multiplication\n            vse64_v_f64m1(row_dst + j, res, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_27_RVV", "completion": "```c\nvoid matrix_hadamard_product_simd(const double* mat1, const double* mat2, double* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    for (size_t i = 0; i < m; i++) {\n        const double* row1 = mat1 + i * n;\n        const double* row2 = mat2 + i * n;\n        double* row_dst = dst + i * n;\n        vfloat64xm1_t vec1, vec2;\n        for (size_t j = 0; j < n; j += vl) {\n            vec1 = vle64_v_f64m1(row1 + j, vl);\n            vec2 = vle64_v_f64m1(row2 + j, vl);\n            vse64_v_f64m1(row_dst + j, vmul_vv_f64m1(vec1, vec2, vl), vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32xm1_t sum = vfmul_vx_e32m1(vle32_v_f32xm1(mat + i * n, vl), vec[0], vl);\n        for (size_t j = 1; j < n; j++) {\n            sum = vfadd_vv_e32m1(sum, vfmul_vx_e32m1(vle32_v_f32xm1(mat + i * n + j, vl), vec[j], vl), vl);\n        }\n        vse32_v_f32xm1(dst + i, sum, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32m1_t sum = vfmul_vf_f32m1(vec, *vec, vl);\n        for (size_t j = 1; j < n; j++) {\n            vfloat32m1_t row = vle32_v_f32m1(mat + j * m + i, vl);\n            sum = vfadd_vv_f32m1(sum, row, vl);\n        }\n        dst[i] = vfmv_f_s_f32_f32(sum);\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32xm1_t sum = vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n, vl), vec[0], vl);\n        for (size_t j = 1; j < n; j++) {\n            sum = vfadd_vv_e32m1(sum, vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n + j, vl), vec[j], vl), vl);\n        }\n        dst[i] = vfredsum_vs_f32m1_f32_e32m1(sum, vlev_f32m1(vec, vl), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32xm1_t sum = vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n, vl), vec[0], vl);\n        for (size_t j = 1; j < n; j++) {\n            sum = vfadd_vv_e32m1(sum, vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n + j, vl), vec[j], vl), vl);\n        }\n        vse32_v_f32m1(dst + i, sum, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_28_RVV", "completion": "```c\nvoid matrix_vector_mul_simd(const float* mat, const float* vec, float* dst, size_t m, size_t n) {\n    size_t vl = vsetvl_e32m1(n);\n    for (size_t i = 0; i < m; i++) {\n        vfloat32xm1_t sum = vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n, vl), vec[0], vl);\n        for (size_t j = 1; j < n; j++) {\n            sum = vfadd_vv_e32m1(sum, vfmul_vx_e32m1(vle32_v_f32m1(mat + i * n + j, vl), vec[j], vl), vl);\n        }\n        dst[i] = vfredsum_vs_f32m1_f32_e32m1(sum, vle32_v_f32m1(vec, vl), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64xm1_t vec_sum = vfmv_f_x_v_f64m1(0.0, vl);\n    \n    for (size_t i = 0; i < m; i++) {\n        vfloat64xm1_t vec_row = vle64_v_f64m1(mat + i * n, vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec_row, vl);\n    }\n    \n    double sum = vfredsum_vs_f64m1_f64m1(vec_sum, vfmv_x_f_f64m1(0.0, vl), vl);\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64xm1_t vec_sum = vfmul_vf_e64m1(vle64_v_f64m1(mat, vl), 0.0, vl);\n    for (size_t i = 1; i < m; i++) {\n        size_t offset = i * n;\n        vec_sum = vfadd_vv_e64m1(vec_sum, vle64_v_f64m1(mat + offset, vl), vl);\n    }\n    double sum = 0.0;\n    vfredsum_vs_f64m1_f64(&sum, vec_sum, &sum, vl);\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64xm1_t vec_sum = vfmv_v_f_f64m1(0.0, vl);\n    \n    for (size_t i = 0; i < m; i++) {\n        vfloat64xm1_t vec_row = vle64_v_f64m1(mat + i * n, vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec_row, vl);\n    }\n    \n    double sum = vfredsum_vs_f64m1_f64(0.0, vec_sum, vl);\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64xm1_t vec_sum = vfmul_vf_e64m1(vle64_v_f64m1(mat, vl), 0.0, vl);\n    for (size_t i = 1; i < m; i++) {\n        size_t offset = i * n;\n        vec_sum = vfadd_vv_e64m1(vec_sum, vle64_v_f64m1(mat + offset, vl), vl);\n    }\n    double sum = 0.0;\n    vfredsum_vs_f64m1_f64(&sum, vec_sum, &sum, vl);\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_29_RVV", "completion": "```c\ndouble matrix_average_simd(const double* mat, size_t m, size_t n) {\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64xm1_t vec_sum = vfmv_v_f_f64m1(0.0, vl);\n    \n    for (size_t i = 0; i < m; i++) {\n        vfloat64xm1_t vec_row = vle64_v_f64m1(mat + i * n, vl);\n        vec_sum = vfadd_vv_f64m1(vec_sum, vec_row, vl);\n    }\n    \n    double sum = vfredsum_vs_f64m1_f64(0.0, vec_sum, vl);\n    return sum / (m * n);\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vint32m1_t vec = vle32_v_i32m1(matrix + i * cols, vl);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j++) {\n            vint32m1_t next_vec = vle32_v_i32m1(matrix + i * cols + j, vl);\n            vint32m1_t diff = vsub_vx_i32m1(next_vec, vec);\n            vboolm1_t cond = vmslt_vx_i32m1(diff, 0);\n            if (ascending && !vmsum_u_b8m1(cond, cond)) {\n                return false;\n            }\n            if (!ascending && !vmsum_u_b8m1(cond, cond)) {\n                return false;\n            }\n            vec = next_vec;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vint32m1_t vec = vle32_v_i32m1(matrix + i * cols, vl);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j++) {\n            vint32m1_t next_vec = vle32_v_i32m1(matrix + i * cols + j, vl);\n            vint32m1_t diff = vsub_vx_i32m1(next_vec, vec);\n            vboolm1_t cond = vmslt_vx_i32m1(diff, 0);\n            if (ascending && !vmsum_u_b8m1(cond, cond, 0)) {\n                return false;\n            }\n            if (!ascending && !vmsum_u_b8m1(cond, cond, 0)) {\n                return false;\n            }\n            vec = next_vec;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vint32m1_t prev = vle32_v_i32m1(matrix + i * cols, vl);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j++) {\n            vint32m1_t curr = vle32_v_i32m1(matrix + i * cols + j * vl, vl);\n            vint32m1_t cmp_prev = vseq_v_i32m1(prev, curr, vl);\n            vint32m1_t cmp_curr = vseq_v_i32m1(curr, prev, vl);\n            bool all_prev = viseq_v_i32m1(cmp_prev, vsetvl_e32m1(1), vl);\n            bool all_curr = viseq_v_i32m1(cmp_curr, vsetvl_e32m1(1), vl);\n            if ((ascending && !all_prev) || (!ascending && !all_curr)) {\n                return false;\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vint32m1_t prev = vle32_v_i32m1(matrix + i * cols, vl);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j++) {\n            vint32m1_t curr = vle32_v_i32m1(matrix + i * cols + j * vl, vl);\n            vint32m1_t cmp_result = vseq_vv_i32m1(prev, curr, vl);\n            if (ascending) {\n                vint32m1_t gt_mask = vmgt_vv_i32m1(prev, curr, vl);\n                if (vmsum_vs_i32m1_i32m1(cmp_result, gt_mask, vl)) return false;\n            } else {\n                vint32m1_t lt_mask = vmul_vv_i32m1(prev, curr, vl);\n                if (vmsum_vs_i32m1_i32m1(cmp_result, lt_mask, vl)) return false;\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_30_RVV", "completion": "```c\nbool matrix_rows_sorted_verify_simd(const int* matrix, const bool* directions, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vint32m1_t prev = vle32_v_i32m1(matrix + i * cols, vl);\n        bool ascending = directions[i];\n        for (size_t j = 1; j < cols; j++) {\n            vint32m1_t curr = vle32_v_i32m1(matrix + i * cols + j * vl, vl);\n            vint32m1_t cmp_result = vseqge_vv_i32m1(curr, prev);\n            uint32m1_t mask = vmseq_vx_u32m1(cmp_result, 0, vl);\n            if (!ascending) {\n                cmp_result = vseqle_vv_i32m1(curr, prev);\n                mask = vmseq_vx_u32m1(cmp_result, 0, vl);\n            }\n            if (vmsum_u32m1(mask, vl) != vl) {\n                return false;\n            }\n            prev = curr;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const int16_t* src_ptr = src;\n    int16_t* dst_ptr = dst;\n\n    while (vl > 0) {\n        vint16m1_t src_vec = vle16_v_i16m1(src_ptr, vl);\n        vint16m1_t base_vec = vdup_e16m1(base);\n\n        // Compute the remainder: src % base\n        vint16m1_t remainder = vremu_vx_i16m1(src_vec, base_vec, vl);\n\n        // Compute the adjustment: remainder >= base / 2 ? base : 0\n        vint16m1_t half_base = vrgather_vx_i16m1(vle16_v_i16m1((const int16_t*)&base, vl), \n                                                 vluxei32_v_i16m1(remainder, vl, vl), vl);\n        vint16m1_t adjustment = vsub_vx_i16m1(half_base, remainder, vl);\n\n        // Compute the result: src - adjustment\n        vint16m1_t result = vsub_vx_i16m1(src_vec, adjustment, vl);\n\n        // Store the result back to dst\n        vse16_v_i16m1(dst_ptr, result, vl);\n\n        // Move pointers and update vector length\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e16m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const int16_t* src_ptr = src;\n    int16_t* dst_ptr = dst;\n\n    while (vl > 0) {\n        vint16m1_t src_vec = vle16_v_i16m1(src_ptr, vl);\n        vint16m1_t base_vec = vdup_e16m1(base);\n\n        // Compute floor division\n        vint16m1_t div_floor = vfloor_v_i16m1(src_vec, base_vec);\n\n        // Compute the nearest multiple\n        vint16m1_t nearest = vmul_v_i16m1(div_floor, base_vec);\n\n        // Store the result\n        vse16_v_i16m1(dst_ptr, nearest, vl);\n\n        // Move pointers forward\n        src_ptr += vl;\n        dst_ptr += vl;\n\n        // Update vector length\n        vl = vsetvl_e16m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const int16_t* src_ptr = src;\n    int16_t* dst_ptr = dst;\n\n    while (vl > 0) {\n        vint16m1_t src_vec = vle16_v_i16m1(src_ptr, vl);\n        vint16m1_t base_vec = vsub_vx_i16m1(vsmul_vx_i16m1(src_vec, base), base);\n\n        vse16_v_i16m1(dst_ptr, base_vec, vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e16m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const int16_t* src_ptr = src;\n    int16_t* dst_ptr = dst;\n\n    while (vl > 0) {\n        vint16m1_t src_vec = vle16_v_i16m1(src_ptr, vl);\n        vint16m1_t base_vec = vdup_e16m1(base, vl);\n\n        // Compute the remainder\n        vint16m1_t remainder = vremu_vx_i16m1(src_vec, base_vec);\n\n        // Compute the nearest lower multiple\n        vint16m1_t lower_multiple = vsub_vx_i16m1(src_vec, remainder);\n\n        // Store the result\n        vse16_v_i16m1(dst_ptr, lower_multiple, vl);\n\n        // Move pointers and reset vector length\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e16m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_31_RVV", "completion": "```c\nvoid nearest_multiple_simd(const int16_t* src, int16_t* dst, uint8_t base, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    const int16_t* src_ptr = src;\n    int16_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vint16m1_t src_vec = vle16_v_i16m1(src_ptr, vl);\n        vint16m1_t base_vec = vdup_e16m1(base, vl);\n\n        // Compute floor division\n        vint16m1_t div_floor = vfloor_v_i16m1(vfdiv_vx_i16m1(src_vec, base_vec));\n\n        // Multiply back to get the nearest lower multiple\n        vint16m1_t result = vmul_vx_i16m1(div_floor, base_vec);\n\n        // Store the result\n        vse16_v_i16m1(dst_ptr, result, vl);\n\n        // Update pointers and length\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec = vle64_v_f64m1(matrix + i * cols + j, vl);\n            vfloat64m1_t ref = vle64_v_f64m1(vector + j, vl);\n            vbool64m1_t mask = vfmseq_vf_f64m1(vec, ref, vl);\n            if (!vmcloak_b64m1(mask, vl)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m1(cols);\n    vfloat64m1_t vec;\n    for (size_t i = 0; i < rows; i++) {\n        vec = vle64_v_f64m1(matrix + i * cols, vl);\n        if (viseq_vf_f64m1(vec, vector[0], vl) == vtrue_m1_b64(vl)) {\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec = vle64_v_f64m1(matrix + i * cols + j, vl);\n            vfloat64m1_t ref = vle64_v_f64m1(vector + j, vl);\n            vboolm1_t mask = vfmseq_vf_f64m1(vec, ref, vl);\n            if (!vmcloak_b1(mask)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t vec = vle64_v_f64m1(matrix + i * cols + j, vl);\n            vfloat64m1_t ref = vle64_v_f64m1(vector + j, vl);\n            vboolm1_t mask = vfmseq_vf_f64m1(vec, ref, vl);\n            if (!vmulred_m_b1(mask)) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_32_RVV", "completion": "```c\nbool matrix_has_row_simd(const double* matrix, const double* vector, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        bool match = true;\n        for (size_t j = 0; j < cols; j += vl) {\n            vint8m1_t vec_mask = veq_vv_i8m1(vle_v_i64m1(matrix + i * cols + j, vl), vle_v_i64m1(vector + j, vl), vl);\n            if (vmul_mask_i8m1(vec_mask, 1) == 0) {\n                match = false;\n                break;\n            }\n        }\n        if (match) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_count = 0;\n    size_t max_len = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t vl = vsetvl_e8m1(max_len);\n\n    for (size_t i = 0; i < max_len; i += vl) {\n        vuint8m1_t vec_A = vle8_v_u8m1(A + i, vl);\n        vuint8m1_t vec_B = vle8_v_u8m1(B + i, vl);\n        vbool8m1_t mask = vmseq_vv_u8m1(vec_A, vec_B, vl);\n        size_t count = vpopc_v_u8m1(mask);\n        total_count += count;\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_count = 0;\n    size_t max_len = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t vl = vsetvl_e8m1(max_len);\n\n    for (size_t i = 0; i < max_len; i += vl) {\n        vuint8m1_t vec_A = vle8_v_u8m1(A + i, vl);\n        vuint8m1_t vec_B = vle8_v_u8m1(B + i, vl);\n        vbool8m1_t mask = vmseq_vv_u8m1(vec_A, vec_B, vl);\n        size_t count = vpopc_v_u8m1(mask);\n        total_count += count;\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_count = 0;\n    size_t max_len = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t vl = vsetvl_e8m1(max_len);\n\n    for (size_t i = 0; i < max_len; i += vl) {\n        vuint8m1_t vec_A = vle8_v_u8m1(A + i, vl);\n        vuint8m1_t vec_B = vle8_v_u8m1(B + i, vl);\n        vbool8m1_t mask = vmseq_vv_u8m1(vec_A, vec_B, vl);\n        size_t count = vpopc_v_u8m1(mask);\n        total_count += count;\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_count = 0;\n    size_t max_len = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t vl = vsetvl_e8m1(max_len);\n\n    for (size_t i = 0; i < max_len; i += vl) {\n        vuint8m1_t vec_A = vle8_v_u8m1(A + i, vl);\n        vuint8m1_t vec_B = vle8_v_u8m1(B + i, vl);\n        vbool8m1_t mask = vmseq_vv_u8m1(vec_A, vec_B, vl);\n        size_t count = vpopc_v_u8m1(mask);\n        total_count += count;\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_33_RVV", "completion": "```c\nsize_t tensor_4d_equal_count_simd(const uint8_t* A, const uint8_t* B, const size_t dims[4]) {\n    size_t total_count = 0;\n    size_t max_len = dims[0] * dims[1] * dims[2] * dims[3];\n    size_t vl = vsetvl_e8m1(max_len);\n\n    for (size_t i = 0; i < max_len; i += vl) {\n        vuint8m1_t vec_A = vle8_v_u8m1(A + i, vl);\n        vuint8m1_t vec_B = vle8_v_u8m1(B + i, vl);\n        vboolm1_t mask = vmseq_vv_u8m1(vec_A, vec_B, vl);\n        size_t count = vpopc_v_u8m1(mask);\n        total_count += count;\n    }\n\n    return total_count;\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *x_ptr = x;\n    int64_t *y_ptr = y;\n\n    vint64m1_t vec_a = vle64_v_i64m1(&a, 1);\n    vint64m1_t vec_x = vle64_v_i64m1(x_ptr, vl);\n\n    vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n    vint64m1_t vec_abs = vabs_v_i64m1(vec_ax);\n    vse64_v_i64m1(y_ptr, vec_abs, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *x_ptr = x;\n    int64_t *y_ptr = y;\n\n    vint64m1_t vec_a = vle64_v_i64m1(&a, 1);\n    vint64m1_t vec_x = vle64_v_i64m1(x_ptr, vl);\n\n    vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n    vint64m1_t vec_abs = vabs_v_i64m1(vec_ax);\n    vse64_v_i64m1(y_ptr, vec_abs, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *x_ptr = x;\n    int64_t *y_ptr = y;\n\n    vint64m1_t vec_a = vle64_v_i64m1(&a, 1);\n    vint64m1_t vec_x = vle64_v_i64m1(x_ptr, vl);\n\n    vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n    vint64m1_t vec_abs = vabs_v_i64m1(vec_ax);\n    vse64_v_i64m1(y_ptr, vec_abs, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *x_ptr = x;\n    int64_t *y_ptr = y;\n\n    vint64m1_t vec_a = vle64_v_i64m1(&a, 1);\n    vint64m1_t vec_x = vle64_v_i64m1(x_ptr, vl);\n\n    vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n    vint64m1_t vec_abs = vabs_v_i64m1(vec_ax);\n    vint64m1_t vec_sub = vsub_vx_i64m1(vec_abs, a, vl);\n\n    vse64_v_i64m1(y_ptr, vec_sub, vl);\n}\n```"}
{"task_id": "SimdBench_34_RVV", "completion": "```c\nvoid axm_abs_simd(size_t length, const int64_t a, const int64_t *x, int64_t *y) {\n    size_t vl = vsetvl_e64m1(length);\n    const int64_t *x_ptr = x;\n    int64_t *y_ptr = y;\n\n    vint64m1_t vec_a = vle64_v_i64m1(&a, 1);\n    vint64m1_t vec_x = vle64_v_i64m1(x_ptr, vl);\n\n    vint64m1_t vec_ax = vmul_vx_i64m1(vec_x, a, vl);\n    vint64m1_t vec_abs = vabs_v_i64m1(vec_ax);\n    vint64m1_t vec_sub = vsub_vx_i64m1(vec_abs, a, vl);\n\n    vse64_v_i64m1(y_ptr, vec_sub, vl);\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = { .min_num = vec[0], .max_num = vec[0] };\n    vint16m1x2_t vec_pair;\n    size_t vl;\n    for (size_t i = 0; i < length; i += 2) {\n        vec_pair = vle16_v_i16m1x2(vec + i, &vl);\n        int16_t min_val = vmin_vv_i16m1x2(vec_pair, vl);\n        int16_t max_val = vmax_vv_i16m1x2(vec_pair, vl);\n        if (min_val < result.min_num) result.min_num = min_val;\n        if (max_val > result.max_num) result.max_num = max_val;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = { .min_num = vec[0], .max_num = vec[0] };\n    vint16m1x2_t vec_pair;\n    size_t vl;\n    for (size_t i = 0; i < length; i += 2) {\n        vec_pair = vle16_v_i16m1x2(vec + i, &vl);\n        int16_t min_val = vmin_vv_i16m1(vec_pair, vl);\n        int16_t max_val = vmax_vv_i16m1(vec_pair, vl);\n        if (min_val < result.min_num) result.min_num = min_val;\n        if (max_val > result.max_num) result.max_num = max_val;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = { .min_num = vec[0], .max_num = vec[0] };\n    vint16m1x2_t vec_pair;\n    size_t vl;\n    for (size_t i = 0; i < length; i += 2) {\n        vec_pair = vle16_v_i16m1x2(vec + i, &vl);\n        int16_t min_val = vmin_vv_i16m1x2(vec_pair, vl);\n        int16_t max_val = vmax_vv_i16m1x2(vec_pair, vl);\n        if (min_val < result.min_num) result.min_num = min_val;\n        if (max_val > result.max_num) result.max_num = max_val;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = { .min_num = vec[0], .max_num = vec[0] };\n    vint16m1x2_t vec_pair;\n    size_t vl;\n    for (size_t i = 0; i < length; i += 2) {\n        vec_pair = vle16_v_i16m1x2(vec + i, &vl);\n        int16_t local_min = vmin_vv_i16m1x2(vec_pair, vl);\n        int16_t local_max = vmax_vv_i16m1x2(vec_pair, vl);\n        if (local_min < result.min_num) result.min_num = local_min;\n        if (local_max > result.max_num) result.max_num = local_max;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_35_RVV", "completion": "```c\nMinMaxPair min_max_pair_simd(const int16_t* vec, size_t length) {\n    MinMaxPair result = { .min_num = vec[0], .max_num = vec[0] };\n    vint16m1x2_t vec_pair;\n    vint16m1_t min_vec, max_vec;\n    size_t vl = vsetvl_e16m1(length);\n    for (size_t i = 0; i < length; i += 2) {\n        vec_pair = vle16_v_i16m1x2(vec + i, vl);\n        min_vec = vmin_vv_i16m1(vec_pair, vl);\n        max_vec = vmax_vv_i16m1(vec_pair, vl);\n        result.min_num = vmin_vx_i16(result.min_num, min_vec, vl);\n        result.max_num = vmax_vx_i16(result.max_num, max_vec, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    const int *end = matrix + rows * cols;\n    vint32m1_t prev_vec, curr_vec;\n    vbool16_t mask;\n    int i = 0;\n\n    while ((uint8_t*)matrix + i < (uint8_t*)end) {\n        prev_vec = vle32_v_i32m1(matrix + i, vlmax_b16(mask));\n        curr_vec = vle32_v_i32m1(matrix + i + cols, vlmax_b16(mask));\n\n        mask = vseqge_vv_b16(curr_vec, prev_vec);\n        if (vmulred_b16(mask)) {\n            return false;\n        }\n\n        i += vlmax_b16(mask);\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        const int* row_ptr = matrix + i * cols;\n        vint32m1_t prev_vec = vle32_v_i32m1(row_ptr, vl);\n        bool valid = true;\n        for (size_t j = 1; j < rows && valid; j++) {\n            row_ptr += cols;\n            vint32m1_t curr_vec = vle32_v_i32m1(row_ptr, vl);\n            vint32m1_t cmp_gt = vseqge_vv_i32m1(curr_vec, prev_vec);\n            uint32m1_t mask = vmseq_vx_u32m1(cmp_gt, 0, vl);\n            if (vmulred_x_u32(mask) > 0) {\n                valid = false;\n            }\n            prev_vec = curr_vec;\n        }\n        if (valid) return true;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    const int *end = matrix + rows * cols;\n    vint32m1_t prev_vec, curr_vec;\n    vbool16_t mask;\n    int i = 0;\n\n    while ((intptr_t)(matrix + i) < (intptr_t)end) {\n        vint32m1_t prev_vec = vle32_v_i32m1(matrix + i, vlmax_e32m1());\n        vint32m1_t curr_vec = vle32_v_i32m1(matrix + i + cols, vlmax_e32m1());\n\n        mask = vseqge_vv_b16(prev_vec, curr_vec);\n\n        if (vmulred_b16(mask)) {\n            return false;\n        }\n\n        i += vlmax_e32m1();\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    vint32m1x2_t vec_a, vec_b;\n    bool mask_all = true;\n\n    for (size_t i = 0; i < rows; i++) {\n        const int* row_a = matrix + i * cols;\n        const int* row_b = row_a + cols;\n\n        bool mask_row = true;\n        for (size_t j = 0; j < cols - 1; j += 2) {\n            vec_a = vle32_v_i32m1x2(row_a + j, LMUL_1, TA);\n            vec_b = vle32_v_i32m1x2(row_b + j, LMUL_1, TA);\n\n            vbool1_t mask = vlse32_v_i32m1x2_b1(vec_a, vec_b, LT);\n            if (!mask) {\n                mask_row = false;\n                break;\n            }\n        }\n\n        if (!mask_row) {\n            mask_all = false;\n            break;\n        }\n    }\n\n    return mask_all;\n}\n```"}
{"task_id": "SimdBench_36_RVV", "completion": "```c\nbool matrix_rows_strictly_increasing_simd(const int* matrix, size_t rows, size_t cols) {\n    if (rows == 0 || cols == 0) return false;\n\n    vint32m1x2_t vec_a, vec_b;\n    bool result = true;\n    size_t i = 0;\n\n    for (; i + 2 <= rows; i += 2) {\n        const int* row_a = matrix + i * cols;\n        const int* row_b = matrix + (i + 1) * cols;\n\n        for (size_t j = 0; j < cols; j += 2) {\n            vec_a = vle2_v_i32m1x2(row_a + j, vl);\n            vec_b = vle2_v_i32m1x2(row_b + j, vl);\n\n            vbool16_t mask = vmult_vv_i32m1x2(vec_a, vec_b, vl);\n            if (!vmall_v_i32m1x2(mask)) {\n                result = false;\n                break;\n            }\n        }\n\n        if (!result) break;\n    }\n\n    for (; i < rows && result; i++) {\n        const int* row = matrix + i * cols;\n        for (size_t j = 1; j < cols && result; j++) {\n            result = row[j - 1] < row[j];\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n    size_t num_rows = rows / block_size;\n    size_t num_cols = cols / block_size;\n    size_t vector_length = vlmax(); // Get maximum vector length\n    size_t block_elements = block_size * block_size;\n    size_t block_bytes = block_elements * sizeof(int);\n\n    // Load the first block\n    const int* first_block = matrix;\n    int32xm1_t ref_block = vle32_v_i32xm1(first_block, block_elements);\n\n    for (size_t i = 1; i < num_rows; i++) {\n        for (size_t j = 0; j < num_cols; j++) {\n            const int* current_block = matrix + i * block_size * cols + j * block_size;\n            int32xm1_t current_block_vec = vle32_v_i32xm1(current_block, block_elements);\n            int32xm1_t eq_mask = veq_vv_i32xm1(ref_block, current_block_vec, block_elements);\n            if (!vmall_i32xm1(eq_mask)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    size_t row_blocks = rows / block_size;\n    size_t col_blocks = cols / block_size;\n\n    // Check if block_size divides rows and cols perfectly\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    // Load the first block\n    vint32m1x4_t first_block = vle32_v_i32m1x4(matrix, vlse32_v_i32m1x4(0, matrix, vl));\n\n    for (size_t i = 1; i < row_blocks; i++) {\n        for (size_t j = 0; j < col_blocks; j++) {\n            size_t offset = i * block_size * cols + j * block_size;\n            vint32m1x4_t current_block = vle32_v_i32m1x4(matrix + offset, vlse32_v_i32m1x4(offset, matrix, vl));\n            if (!viseq_v_i32m1x4(first_block, current_block, vl)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    size_t row_blocks = rows / block_size;\n    size_t col_blocks = cols / block_size;\n\n    // Check if block_size divides rows and cols perfectly\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n\n    // Load the first block\n    vint32m1x4_t first_block = vle32_v_i32m1x4(matrix, vlse32_v_i32m1x4((intptr_t)matrix, block_size * sizeof(int), vl));\n\n    for (size_t i = 1; i < row_blocks; i++) {\n        for (size_t j = 0; j < col_blocks; j++) {\n            size_t offset = i * block_size * cols + j * block_size;\n            vint32m1x4_t current_block = vle32_v_i32m1x4(matrix + offset, vlse32_v_i32m1x4((intptr_t)(matrix + offset), block_size * sizeof(int), vl));\n            vbool4_t mask = vmseq_v_i32m1x4_i32m1x4(first_block, current_block, vl);\n            if (!vmall_v_i32m1x4(mask)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n    size_t num_rows = rows / block_size;\n    size_t num_cols = cols / block_size;\n    size_t block_len = block_size * block_size;\n    size_t vl = vsetvl_e32m1(block_len);\n    for (size_t i = 1; i < num_rows; i++) {\n        for (size_t j = 1; j < num_cols; j++) {\n            const int* current_block = matrix + i * block_size * cols + j * block_size;\n            const int* ref_block = matrix;\n            int32xm1_t ref_vec = vle32_v_i32xm1(ref_block, vl);\n            int32xm1_t curr_vec = vle32_v_i32xm1(current_block, vl);\n            if (!viseq_vx_i32xm1(curr_vec, ref_vec, vl)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_37_RVV", "completion": "```c\nbool matrix_blocks_equal_simd(const int* matrix, size_t block_size, size_t rows, size_t cols) {\n    if (rows % block_size != 0 || cols % block_size != 0) {\n        return false;\n    }\n    size_t num_rows = rows / block_size;\n    size_t num_cols = cols / block_size;\n    size_t vector_length = vlmax(); // Get the maximum vector length\n    size_t block_elements = block_size * block_size;\n    size_t block_bytes = block_elements * sizeof(int);\n\n    for (size_t i = 1; i < num_rows; i++) {\n        for (size_t j = 1; j < num_cols; j++) {\n            const int* current_block = matrix + i * block_size * cols + j * block_size;\n            const int* ref_block = matrix;\n            for (size_t k = 0; k < block_elements; k += vector_length) {\n                vint32m1_t vec_current = vle32_v_i32m1(current_block + k, vector_length);\n                vint32m1_t vec_ref = vle32_v_i32m1(ref_block + k, vector_length);\n                if (!viseq_vx_i32m1(vec_current, vec_ref, vector_length)) {\n                    return false;\n                }\n            }\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) return false;\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl);\n    size_t num_blocks = length / block_size;\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        size_t offset = i * block_size;\n        vfloat64m1_t current_block = vle64_v_f64m1(vec + offset, vl);\n        vboolm1_t mask = vfredge_sum_vs_f64m1_f64m1(vsub_vf_f64m1(current_block, ref_block, vl), \n                                                   vfmul_vf_f64m1(vfmabs_vf_f64m1(current_block, ref_block, vl), \n                                                                  vfmul_vf_f64m1(ref_block, ref_block, vl), vl), \n                                                   vl);\n        if (!vmret(mask)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) return false;\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl);\n    size_t num_blocks = (length / block_size);\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        size_t offset = i * block_size;\n        vfloat64m1_t current_block = vle64_v_f64m1(vec + offset, vl);\n        vfloat64m1_t diff = vfsub_vf_f64m1(current_block, ref_block, vl);\n        vfloat64m1_t abs_diff = vfabs_v_f64m1(diff, vl);\n        vbool16 mask = vmfgt_vf_b16(abs_diff, tolerance, vl);\n        if (vmulred_b16(mask)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) return false;\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl);\n    for (size_t i = block_size; i + block_size <= length; i += block_size) {\n        vfloat64m1_t current_block = vle64_v_f64m1(vec + i, vl);\n        vboolm1_t mask = vfredge_sum_vs_f64m1_f64m1(vsub_vv_f64m1(current_block, ref_block), \n                                                   vfmul_vf_f64m1(ref_block, tolerance, vl), vl);\n        if (!vmseq_vx_b8(mask, vl)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) return false;\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref_block = vle64_v_f64m1(vec, vl);\n    for (size_t i = block_size; i + block_size <= length; i += block_size) {\n        vfloat64m1_t current_block = vle64_v_f64m1(vec + i, vl);\n        vboolm1_t mask = vfredge_sum_vs_f64m1_f64m1(vsub_vf_f64m1(current_block, ref_block, vl), \n                                                   vfmul_vf_f64m1(vfmabs_vf_f64m1(current_block, ref_block, vl), \n                                                                  vfmadd_vf_f64m1(ref_block, -1.0, vl), vl), \n                                                   vl);\n        if (!vmseq_vx_b1(mask, vl)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_38_RVV", "completion": "```c\nbool vector_block_equal_simd(const double* vec, double tolerance, size_t length, size_t block_size) {\n    if (length < block_size || block_size == 0) return false;\n\n    size_t vl = vsetvl_e64m1(block_size);\n    vfloat64m1_t ref = vle64_v_f64m1(vec, vl);\n    size_t num_blocks = length / block_size;\n\n    for (size_t i = 1; i < num_blocks; i++) {\n        size_t offset = i * block_size;\n        vfloat64m1_t current = vle64_v_f64m1(vec + offset, vl);\n        vboolm1_t mask = vfredge_sum_vs_f64m1_f64m1(vsub_vf_f64m1(current, ref, vl), \n                                                   vfmul_vf_f64m1(ref, tolerance, vl), vl);\n        if (!vmseq_v_bm_f64m1(mask, vl)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vfloat64m1_t row_sum = vfmul_vf_f64m1(vle64_v_f64m1(matrix + i * cols, vl), 0.0, vl);\n        for (size_t j = 0; j < cols; j += vl) {\n            vfloat64m1_t values = vle64_v_f64m1(matrix + i * cols + j, vl);\n            row_sum = vfadd_vv_f64m1(row_sum, values, vl);\n        }\n        double norm = vsqrt_f64m1(row_sum, vl);\n        result[i] = (norm > thresholds[i]);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vfloat64m1_t row_sum = vfmul_vf_f64m1(vle64_v_f64m1(matrix + i * cols, vl), 0.0, vl);\n        for (size_t j = 0; j < cols; j++) {\n            vfloat64m1_t val = vle64_v_f64m1(matrix + i * cols + j, vl);\n            row_sum = vfadd_vv_f64m1(row_sum, val, vl);\n        }\n        double norm = vsqrt_vf_f64(row_sum, vl);\n        double threshold = thresholds[i];\n        result[i] = (norm > threshold);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vfloat64m1_t row_sum = vfmul_vf_f64m1(vle64_v_f64m1(matrix + i * cols, vl), 0.0, vl);\n        for (size_t j = 0; j < cols; j++) {\n            vfloat64m1_t val = vle64_v_f64m1(matrix + i * cols + j, vl);\n            row_sum = vfadd_vv_f64m1(row_sum, val, vl);\n        }\n        double norm = vsqrt_vf_f64(row_sum, vl);\n        double threshold = thresholds[i];\n        result[i] = (norm > threshold);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vfloat64m1_t row_sum = vfmul_vf_f64m1(vle64_v_f64m1(matrix + i * cols, vl), 0.0, vl);\n        for (size_t j = 0; j < cols; j++) {\n            vfloat64m1_t val = vle64_v_f64m1(matrix + i * cols + j, vl);\n            row_sum = vfadd_vv_f64m1(row_sum, val, vl);\n        }\n        double norm = vsqrt_x_f64m1(row_sum);\n        double threshold = thresholds[i];\n        result[i] = (norm > threshold);\n    }\n}\n```"}
{"task_id": "SimdBench_39_RVV", "completion": "```c\nvoid matrix_row_norm_compare_simd(const double* matrix, const double* thresholds, size_t rows, size_t cols, bool* result) {\n    size_t vl = vsetvl_e64m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        vfloat64m1_t row_sum = vfmul_vf_f64m1(vle64_v_f64m1(matrix + i * cols, vl), 0.0, vl);\n        for (size_t j = 0; j < cols; j++) {\n            vfloat64m1_t val = vle64_v_f64m1(matrix + i * cols + j, vl);\n            row_sum = vfadd_vv_f64m1(row_sum, val, vl);\n        }\n        double norm = vsqrt_vf_f64(row_sum, vl);\n        double threshold = thresholds[i];\n        result[i] = (norm > threshold);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_B = vle32_v_u32m1(B + i, vl);\n        vuint32m1_t vec_C = vor_vv_u32m1(vec_A, vec_B, vl);\n        vse32_v_u32m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_B = vle32_v_u32m1(B + i, vl);\n        vuint32m1_t vec_C = vor_vv_u32m1(vec_A, vec_B, vl);\n        vse32_v_u32m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_B = vle32_v_u32m1(B + i, vl);\n        vuint32m1_t vec_C = vor_vv_u32m1(vec_A, vec_B, vl);\n        vse32_v_u32m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_B = vle32_v_u32m1(B + i, vl);\n        vuint32m1_t vec_C = vor_vv_u32m1(vec_A, vec_B, vl);\n        vse32_v_u32m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_40_RVV", "completion": "```c\nvoid tensor_bitwise_or_simd(const uint32_t* A, const uint32_t* B, uint32_t* C, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_B = vle32_v_u32m1(B + i, vl);\n        vuint32m1_t vec_C = vor_vv_u32m1(vec_A, vec_B, vl);\n        vse32_v_u32m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    const int8_t *A_ptr = A;\n    const int8_t *B_ptr = B;\n    uint8_t sum_of_squares[16] __attribute__((aligned(16))) = {0};\n    uint8_t sum_of_products[16] __attribute__((aligned(16))) = {0};\n\n    while (length > 0) {\n        size_t chunk_length = vl;\n        if (chunk_length > length) {\n            chunk_length = length;\n        }\n\n        vint8m1_t A_vec = vle8_v_i8m1(A_ptr, vl);\n        vint8m1_t B_vec = vle8_v_i8m1(B_ptr, vl);\n\n        vint16m2_t A_sq = vmul_vv_i16m2(A_vec, A_vec, vl);\n        vint16m2_t B_sq = vmul_vv_i16m2(B_vec, B_vec, vl);\n        vint16m2_t AB_prod = vmul_vv_i16m2(A_vec, B_vec, vl);\n\n        vse16_v_i16m2(sum_of_squares, vadd_vv_i16m2(A_sq, B_sq, vl), vl);\n        vse16_v_i16m2(sum_of_products, vadd_vv_i16m2(sum_of_products, AB_prod, vl), vl);\n\n        A_ptr += chunk_length;\n        B_ptr += chunk_length;\n        length -= chunk_length;\n    }\n\n    int64_t total_sum_of_squares = 0;\n    int64_t total_sum_of_products = 0;\n\n    for (size_t i = 0; i < 16; ++i) {\n        total_sum_of_squares += sum_of_squares[i];\n        total_sum_of_products += sum_of_products[i];\n    }\n\n    return (int64_t)total_sum_of_squares - (int64_t)total_sum_of_products;\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    const int8_t *A_ptr = A;\n    const int8_t *B_ptr = B;\n    int32_t sum_of_squares = 0;\n    int32_t sum_of_products = 0;\n\n    while (length > 0) {\n        vint8m1_t vec_A = vle8_v_i8m1(A_ptr, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B_ptr, vl);\n\n        vint16m2_t squares = vmul_vv_i16m2(vec_A, vec_A, vl);\n        vint16m2_t products = vmul_vv_i16m2(vec_A, vec_B, vl);\n\n        sum_of_squares += vsum_sigm2_i16m2(squares, vl);\n        sum_of_products += vsum_sigm2_i16m2(products, vl);\n\n        length -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n\n    return (int64_t)(sum_of_squares) - (int64_t)(sum_of_products);\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    const int8_t *A_ptr = A;\n    const int8_t *B_ptr = B;\n    int32_t sum_of_squares = 0;\n    int32_t sum_of_products = 0;\n\n    while (length > 0) {\n        vint8m1_t vec_A = vle8_v_i8m1(A_ptr, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B_ptr, vl);\n\n        vint16m2_t squares = vmul_vv_i16m2(vec_A, vec_A, vl);\n        vint16m2_t products = vmul_vv_i16m2(vec_A, vec_B, vl);\n\n        sum_of_squares += vsum_sigm2_i16m2(squares, vl);\n        sum_of_products += vsum_sigm2_i16m2(products, vl);\n\n        length -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n\n    return (int64_t)(sum_of_squares) - (int64_t)(sum_of_products);\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    const int8_t *A_ptr = A;\n    const int8_t *B_ptr = B;\n    vint8m1_t vec_A, vec_B;\n    vint16m2_t vec_A_sq;\n    vint16m1_t vec_AB;\n    int32_t sum_sq = 0;\n    int32_t sum_prod = 0;\n\n    while (length > 0) {\n        vec_A = vle8_v_i8m1(A_ptr, vl);\n        vec_B = vle8_v_i8m1(B_ptr, vl);\n\n        vec_A_sq = vmul_vx_i16m2(vec_A, vec_A, vl);\n        vec_AB = vmul_vv_i16m1(vec_A, vec_B, vl);\n\n        sum_sq += vseal_v_i16m2_sum(vec_A_sq, vl);\n        sum_prod += vseal_v_i16m1_sum(vec_AB, vl);\n\n        length -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n        vl = vsetvl_e8m1(length);\n    }\n\n    return (int64_t)(sum_sq) - (int64_t)(sum_prod);\n}\n```"}
{"task_id": "SimdBench_41_RVV", "completion": "```c\nint64_t squarediff_simd(const int8_t * A, const int8_t * B, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    const int8_t *A_ptr = A;\n    const int8_t *B_ptr = B;\n    vint8m1_t vec_A, vec_B;\n    vint16m2_t vec_A_sq;\n    vint16m1_t vec_AxB;\n    int32_t sum_sq = 0;\n    int32_t sum_xB = 0;\n\n    while (length > 0) {\n        vec_A = vle8_v_i8m1(A_ptr, vl);\n        vec_B = vle8_v_i8m1(B_ptr, vl);\n\n        vec_A_sq = vmul_vx_i16m2(vec_A, 1, vl); // Square each element\n        vec_AxB = vmul_vv_i16m1(vec_A, vec_B, vl); // Multiply corresponding elements\n\n        sum_sq += vse16_v_i16m2_sum(vsux_s_i16m2_i32(vec_A_sq, vl), 0);\n        sum_xB += vse16_v_i16m1_sum(vsux_s_i16m1_i32(vec_AxB, vl), 0);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        length -= vl;\n    }\n\n    return (int64_t)(sum_sq - sum_xB);\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint64m1_t vec_A = vle64_v_u64m1(A + i, vl);\n        vuint64m1_t vec_B = vle64_v_u64m1(B + i, vl);\n        vuint64m1_t vec_not_B = vmnot_vx_u64m1(vec_B, vl);\n        vuint64m1_t vec_result = vmand vv_u64m1(vec_A, vec_not_B, vl);\n        vse64_v_u64m1(C + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint64m1_t vec_A = vle64_v_u64m1(A + i, vl);\n        vuint64m1_t vec_B = vle64_v_u64m1(B + i, vl);\n        vuint64m1_t vec_not_B = vbmxor_vx_u64m1(vec_B, ~0ULL, vl);\n        vuint64m1_t vec_result = vor_vv_u64m1(vec_A, vec_not_B, vl);\n        vse64_v_u64m1(C + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint64m1_t vec_A = vle64_v_u64m1(A + i, vl);\n        vuint64m1_t vec_B = vle64_v_u64m1(B + i, vl);\n        vuint64m1_t vec_not_B = vmnot_v_u64m1(vec_B, vl);\n        vuint64m1_t vec_result = vmand_mm(vec_A, vec_not_B, vl);\n        vse64_v_u64m1(C + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint64m1_t vec_A = vle64_v_u64m1(A + i, vl);\n        vuint64m1_t vec_B = vle64_v_u64m1(B + i, vl);\n        vuint64m1_t vec_not_B = vmnot_v_u64m1(vec_B, vl);\n        vuint64m1_t vec_result = vmand_mm(vec_A, vec_not_B, vl);\n        vse64_v_u64m1(C + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_42_RVV", "completion": "```c\nvoid tensor_bit_clear_simd(const uint64_t* A, const uint64_t* B, uint64_t* C, size_t length) {\n    size_t vl = vsetvl_e64m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vuint64m1_t vec_A = vle64_v_u64m1(A + i, vl);\n        vuint64m1_t vec_B = vle64_v_u64m1(B + i, vl);\n        vuint64m1_t vec_not_B = vmnot_vx_u64m1(vec_B, vl);\n        vuint64m1_t vec_result = vmand_mm_u64m1(vec_A, vec_not_B);\n        vse64_v_u64m1(C + i, vec_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t vec_A = vle8_v_i8m1(A + i, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B + i, vl);\n        vbool8m1_t mask_positive = vmgt_vb_i8m1(vec_A, 0, vl);\n        vbool8m1_t mask_negative = vmneg_vb_i8m1(mask_positive, vl);\n        vint8m1_t vec_C = vmseq_vv_i8m1(vec_A, vec_B, vl);\n        vec_C = vmux_vmb_i8m1(mask_positive, vsetvl_e8m1(1), vec_C, vl);\n        vec_C = vmux_vmb_i8m1(mask_negative, vsetvl_e8m1(-1), vec_C, vl);\n        vse8_v_i8m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t vec_A = vle8_v_i8m1(A + i, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B + i, vl);\n        vbool8m1_t mask_positive = vmgt_v_i8m1(vec_A, vint8m1_t{0}, vl);\n        vbool8m1_t mask_negative = vmcle_v_i8m1(vec_A, vint8m1_t{0}, vl);\n        vint8m1_t vec_C = vsub_vx_i8m1(vmv_x_i8m1(0), vl);\n        vse8_v_i8m1(C + i, vternary_vvvx_i8m1(mask_positive, vadd_vx_i8m1(vec_C, 1, vl), vec_C, vl), vl);\n        vse8_v_i8m1(C + i, vternary_vvvx_i8m1(vmseq_v_i8m1(vec_A, vec_B, vl), vadd_vx_i8m1(vec_C, 1, vl), \n                                              vternary_vvvx_i8m1(mask_negative, vadd_vx_i8m1(vec_C, -1, vl), vec_C, vl), vl), vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t vec_A = vle8_v_i8m1(A + i, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B + i, vl);\n        vbool8_t cond_pos = vmgt_v_i8m1(vec_A, vint8m1_t{0}, vl) & vmgt_v_i8m1(vec_B, vint8m1_t{0}, vl);\n        vbool8_t cond_neg = vmneg_v_i8m1(vec_A, vint8m1_t{0}, vl) & vmneg_v_i8m1(vec_B, vint8m1_t{0}, vl);\n        vint8m1_t vec_C = vmv_x_i8m1(0);\n        vec_C = vmseq_vx_i8m1(vec_C, cond_pos, vl, vint8m1_t{1});\n        vec_C = vmseq_vx_i8m1(vec_C, cond_neg, vl, vint8m1_t{-1});\n        vse8_v_i8m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t vec_A = vle8_v_i8m1(A + i, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B + i, vl);\n        vint8m1_t vec_C = vmseq_vv_i8m1(vec_A, vec_B, vl); // A == B\n        vint8m1_t mask_pos = vmgt_vv_i8m1(vec_A, vint8m1_t{0}, vl); // A > 0\n        vint8m1_t mask_neg = vmcle_vv_i8m1(vec_A, vint8m1_t{0}, vl); // A <= 0\n        vint8m1_t pos_result = vmseq_vv_i8m1(mask_pos, vint8m1_t{1}, vl); // Both positive\n        vint8m1_t neg_result = vmseq_vv_i8m1(mask_neg, vint8m1_t{1}, vl); // Both negative\n        vint8m1_t final_result = vmselect_vmm_i8m1(pos_result, vint8m1_t{1}, neg_result, vint8m1_t{-1}, vl);\n        vse8_v_i8m1(C + i, final_result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_43_RVV", "completion": "```c\nvoid tensor_three_valued_logic_simd(const int8_t* A, const int8_t* B, int8_t* C, size_t length) {\n    size_t vl = vsetvl_e8m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vint8m1_t vec_A = vle8_v_i8m1(A + i, vl);\n        vint8m1_t vec_B = vle8_v_i8m1(B + i, vl);\n        vint8m1_t vec_C = vmseq_vv_i8m1(vec_A, vec_B, vl); // Both positive\n        vint8m1_t mask_neg = vmultiv_i8m1(vec_A, vl);      // All negative\n        vint8m1_t vec_C_neg = vmseq_vv_i8m1(vec_A, vec_B, vl); // Both negative\n        vec_C_neg = vmvn_i8m1(vec_C_neg);                 // Invert for negative case\n        vec_C_neg = vmseq_vx_i8m1(vec_C_neg, -1, vl);     // Set to -1\n        vec_C = vmerge_vv_i8m1(vec_C, vec_C_neg, mask_neg); // Merge negative case\n        vint8m1_t zero_mask = vmslt_vv_i8m1(vec_A, vdup_n_i8m1(0, vl), vl); // Any negative\n        zero_mask = vmslt_vv_i8m1(zero_mask, vdup_n_i8m1(0, vl), vl);       // All negative\n        vec_C = vmseq_vx_i8m1(vec_C, 0, vl);              // Set to 0 if not both positive or both negative\n        vse8_v_i8m1(C + i, vec_C, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    size_t mid = length / 2;\n    for (size_t i = 0; i < length; i += vl) {\n        size_t this_vl = vsetvl_e16m1(length - i);\n        vuint16m1_t vec_A = vle16_v_u16m1(A + i, this_vl);\n        vuint16m1_t vec_B = vle16_v_u16m1(B + i, this_vl);\n        vuint16m1_t vec_C = vsub_vx_u16m1(0, this_vl); // Initialize to zero\n\n        if (i < mid) {\n            vuint16m1_t vec_XOR = vor_vv_u16m1(vec_A, vec_B, this_vl);\n            vse16_v_u16m1(C + i, vec_XOR, this_vl);\n        } else {\n            vuint16m1_t vec_AND = vand_vv_u16m1(vec_A, vec_B, this_vl);\n            vse16_v_u16m1(C + i, vec_AND, this_vl);\n        }\n\n        if (i == mid) {\n            vse16_v_u16m1(C + i, vec_A, this_vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    size_t mid = length / 2;\n    for (size_t i = 0; i < length; i += vl) {\n        size_t this_vl = vsetvl_e16m1(length - i);\n        vuint16m1_t vec_A = vle16_v_u16m1(A + i, this_vl);\n        vuint16m1_t vec_B = vle16_v_u16m1(B + i, this_vl);\n        vuint16m1_t vec_C = vsub_vx_u16m1(0, this_vl); // Initialize to zero\n\n        if (i < mid * 2) {\n            vuint16m1_t vec_XOR = vor_vv_u16m1(vec_A, vec_B, this_vl);\n            vuint16m1_t vec_AND = vand_vv_u16m1(vec_A, vec_B, this_vl);\n            if (i < mid) {\n                vse16_v_u16m1(C + i, vec_XOR, this_vl);\n            } else {\n                vse16_v_u16m1(C + i, vec_AND, this_vl);\n            }\n        } else {\n            vse16_v_u16m1(C + i, vec_A, this_vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    size_t mid = length / 2;\n    for (size_t i = 0; i < length; i += vl) {\n        size_t this_vl = vsetvl_e16m1(length - i);\n        vuint16m1_t vec_A = vle16_v_u16m1(A + i, this_vl);\n        vuint16m1_t vec_B = vle16_v_u16m1(B + i, this_vl);\n        vuint16m1_t vec_C = vmsltu_vx_u16m1(vec_A, mid, this_vl); // Mask for mid-point\n        vuint16m1_t vec_XOR = vxor_vx_u16m1(vec_A, vec_B, this_vl);\n        vuint16m1_t vec_AND = vand_vx_u16m1(vec_A, vec_B, this_vl);\n        vse16_v_u16m1(C + i, \n            vmux_vxx_u16m1(vec_C, vec_A, vec_XOR, this_vl), this_vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    size_t mid = length / 2;\n    for (size_t i = 0; i < length; i += vl) {\n        size_t this_vl = vsetvl_e16m1(length - i);\n        vuint16m1_t vec_A = vle16_v_u16m1(A + i, this_vl);\n        vuint16m1_t vec_B = vle16_v_u16m1(B + i, this_vl);\n        vuint16m1_t vec_C = vmsltu_vx_u16m1(vec_A, mid, this_vl); // Mask for mid condition\n        vuint16m1_t vec_XOR = vxor_vx_u16m1(vec_A, vec_B, this_vl);\n        vuint16m1_t vec_AND = vand_vx_u16m1(vec_A, vec_B, this_vl);\n        vse16_v_u16m1(C + i, \n            vmseq_vx_u16m1(vec_C, mid, this_vl) ? vec_A : \n            vmv_x_s_u16m1_v(vec_XOR), this_vl);\n    }\n}\n```"}
{"task_id": "SimdBench_44_RVV", "completion": "```c\nvoid tensor_bit_op_simd(const uint16_t* A, const uint16_t* B, uint16_t* C, size_t length) {\n    size_t vl = vsetvl_e16m1(length);\n    size_t mid = length / 2;\n    for (size_t i = 0; i < length; i += vl) {\n        size_t this_vl = vsetvl_e16m1(length - i);\n        vuint16m1_t vec_A = vle16_v_u16m1(A + i, this_vl);\n        vuint16m1_t vec_B = vle16_v_u16m1(B + i, this_vl);\n        vuint16m1_t vec_C = vsub_vx_u16m1(0, this_vl); // Initialize to zero\n\n        if (i < mid * 2) {\n            vuint16m1_t vec_mask_before_mid = vseqm1_u16m1(i, mid - 1);\n            vuint16m1_t vec_mask_after_mid = vseqlm1_u16m1(i, mid, length);\n\n            vec_C = vmux_vmm_u16m1(vec_mask_before_mid, vor_vv_u16m1(vec_A, vec_B, this_vl),\n                                   vec_mask_after_mid, vand_vv_u16m1(vec_A, vec_B, this_vl),\n                                   this_vl);\n        } else {\n            vec_C = vec_A;\n        }\n        vse16_v_u16m1(C + i, vec_C, this_vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_A = vle32_v_f32m8(A + i, vl);\n        vfloat32m8_t vec_B = vle32_v_f32m8(B + i, vl);\n        vfloat32m8_t vec_C = vle32_v_f32m8(C + i, vl);\n        vfloat32m8_t vec_D = vle32_v_f32m8(D + i, vl);\n        vboolm8_t vec_cond1 = vle8_v_b8m8(cond1 + i, vl);\n        vboolm8_t vec_cond2 = vle8_v_b8m8(cond2 + i, vl);\n\n        vfloat32m8_t vec_out = vfmv_v_f_f32m8(0.0f); // Initialize to zero\n\n        vfloat32m8_t vec_mask1 = vmseq_vb_f32m8(vec_cond1, 1.0f, vl);\n        vfloat32m8_t vec_mask2 = vmseq_vb_f32m8(vec_cond2, 1.0f, vl);\n\n        vfloat32m8_t vec_case1 = vmask_vv_f32m8(vec_mask1, vec_A, vec_B, vl);\n        vfloat32m8_t vec_case2 = vmask_vv_f32m8(vec_mask2, vec_C, vec_D, vl);\n\n        vec_out = vmask_vv_f32m8(vec_mask1, vec_case1, vec_case2, vl);\n\n        vse32_v_f32m8(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_A = vle32_v_f32m8(A + i, vl);\n        vfloat32m8_t vec_B = vle32_v_f32m8(B + i, vl);\n        vfloat32m8_t vec_C = vle32_v_f32m8(C + i, vl);\n        vfloat32m8_t vec_D = vle32_v_f32m8(D + i, vl);\n        vboolm8_t vec_cond1 = vbmsel_v_bm(vle8_v_i8m8((const int8_t*)(cond1 + i), vl), 1, 0);\n        vboolm8_t vec_cond2 = vbmsel_v_bm(vle8_v_i8m8((const int8_t*)(cond2 + i), vl), 1, 0);\n\n        vfloat32m8_t vec_out = vmerge_vff32m8m8(vec_cond1, vec_cond2, vec_A, vec_B, vec_C, vec_D);\n\n        vse32_v_f32m8(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vbool8 mask = vmsne_vx_mask(vle32_v_i32m8(cond1 + i, vl), 0, vl);\n        vbool8 mask1 = vmsne_vx_mask(vle32_v_i32m8(cond2 + i, vl), 0, vl);\n\n        vfloat32m8 va = vle32_v_f32m8(A + i, vl);\n        vfloat32m8 vb = vle32_v_f32m8(B + i, vl);\n        vfloat32m8 vc = vle32_v_f32m8(C + i, vl);\n        vfloat32m8 vd = vle32_v_f32m8(D + i, vl);\n\n        vfloat32m8 result = vmerge_vvm(va, vb, vmand_mm(mask, mask1));\n        result = vmerge_vvm(result, vc, vmxor_mm(mask, mask1));\n        result = vmerge_vvm(result, vd, vmnot_mm(vmand_mm(mask, mask1)));\n\n        vse32_v_f32m8(out + i, result, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_A = vle32_v_f32m8(A + i, vl);\n        vfloat32m8_t vec_B = vle32_v_f32m8(B + i, vl);\n        vfloat32m8_t vec_C = vle32_v_f32m8(C + i, vl);\n        vfloat32m8_t vec_D = vle32_v_f32m8(D + i, vl);\n        vboolm8_t vec_cond1 = vbmsel_v_bm_b(vle8_v_i8m8((const int8_t*)(cond1 + i), vl), 1, 0);\n        vboolm8_t vec_cond2 = vbmsel_v_bm_b(vle8_v_i8m8((const int8_t*)(cond2 + i), vl), 1, 0);\n\n        vfloat32m8_t vec_out = vmerge_vv_f32m8(\n            vmerge_vx_f32m8(\n                vmseq_vx_bf32m8(vec_cond1, 1),\n                vec_A,\n                vec_B\n            ),\n            vmseq_vx_bf32m8(vec_cond2, 1),\n            vec_C,\n            vec_D\n        );\n\n        vse32_v_f32m8(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_45_RVV", "completion": "```c\nvoid tensor_multi_select_simd(const float* A, const float* B, const float* C, const float* D, const bool* cond1, const bool* cond2, float* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m8(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vfloat32m8_t vec_A = vle32_v_f32m8(A + i, vl);\n        vfloat32m8_t vec_B = vle32_v_f32m8(B + i, vl);\n        vfloat32m8_t vec_C = vle32_v_f32m8(C + i, vl);\n        vfloat32m8_t vec_D = vle32_v_f32m8(D + i, vl);\n        vboolm8_t vec_cond1 = vle8_v_b8m8(cond1 + i, vl);\n        vboolm8_t vec_cond2 = vle8_v_b8m8(cond2 + i, vl);\n\n        vfloat32m8_t vec_out = vsub_vv_f32m8(vec_A, vec_A); // Initialize to zero\n\n        vfloat32m8_t vec_mask1 = vand_vb_b8m8(vec_cond1, vec_cond2);\n        vfloat32m8_t vec_mask2 = vandn_b_v_b8m8(vec_cond1, vec_cond2);\n        vfloat32m8_t vec_mask3 = vandn_b_v_b8m8(vnot_b8m8(vec_cond1), vec_cond2);\n        vfloat32m8_t vec_mask4 = vnot_b8m8(vor_b_v_b8m8(vec_cond1, vec_cond2));\n\n        vec_out = vmerge_vvm_f32m8(vec_out, vec_A, vec_mask1);\n        vec_out = vmerge_vvm_f32m8(vec_out, vec_B, vec_mask2);\n        vec_out = vmerge_vvm_f32m8(vec_out, vec_C, vec_mask3);\n        vec_out = vmerge_vvm_f32m8(vec_out, vec_D, vec_mask4);\n\n        vse32_v_f32m8(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    while(i < total_elements){\n        size_t len = total_elements - i;\n        vuint32m1_t vec_a;\n        vuint8m1_t vec_out;\n        vsetvl_e32m1(len);\n        for(int j = 0; j < vsetvl_e32m1(len); j++){\n            vec_a[j] = A[i + j];\n        }\n        vec_out = __builtin_rvv_vpopc_invm_v_u32m1(vec_a);\n        for(int j = 0; j < vsetvl_e32m1(len); j++){\n            out[i + j] = vec_out[j];\n        }\n        i += vsetvl_e32m1(len);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    while(i < total_elements){\n        vuint32m1_t vector_A;\n        vuint8m1_t vector_out;\n        size_t j;\n\n        for(j = 0; j < VLMAX; j++){\n            if(i + j >= total_elements){\n                break;\n            }\n            vector_A.v[j] = A[i + j];\n        }\n\n        vector_out = __builtin_rvv_vpopc_v_u32m1(vector_A);\n\n        for(j = 0; j < VLMAX && i + j < total_elements; j++){\n            out[i + j] = vector_out.v[j];\n        }\n\n        i += VLMAX;\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t vl = vsetvl_e32m1(total_elements);\n\n    for (size_t i = 0; i < total_elements; i += vl) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A + i, vl);\n        vuint32m1_t vec_bits = vpopc_v_u32m1(vec_A);\n        vse8_v_u8m1(out + i, vec_bits, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    while(i < total_elements){\n        size_t len = total_elements - i;\n        vuint32m1_t vec_a;\n        vuint8m1_t vec_out;\n        vsetvl_e32m1(len);\n        vec_a = vle32_v_u32m1(A + i);\n        vec_out = vcpu_popc_w_b32m1(vec_a);\n        vse8_v_u8m1(out + i, vec_out);\n        i += vsetvl_e32m1(len);\n    }\n}\n```"}
{"task_id": "SimdBench_46_RVV", "completion": "```c\nvoid tensor_bit_count_simd(const uint32_t* A, uint8_t* out, size_t dim1, size_t dim2, size_t dim3) {\n    size_t total_elements = dim1 * dim2 * dim3;\n    size_t i = 0;\n\n    while(i < total_elements){\n        vuint32m1_t vector_A;\n        vuint8m1_t vector_out;\n        size_t j;\n\n        for(j = 0; j < VL; j++){\n            if(i + j >= total_elements){\n                break;\n            }\n            vector_A[j] = A[i + j];\n        }\n\n        vector_out = __builtin_rvv_vpopc_v_u32m1(vector_A);\n\n        for(j = 0; j < VL && i + j < total_elements; j++){\n            out[i + j] = vector_out[j];\n        }\n\n        i += VL;\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vint32m1_t vec_a = vle32_v_i32m1(A + i * cols + j, vl);\n            vboolm1_t mask = vmseq_v_i32m1_i32m1(vmodi_v_i32m1_i32m1(vec_a, (int32_t)3, vl), (int32_t)0, vl);\n            vint32m1_t vec_b = vmseq_v_i32m1_i32m1(mask, 1, vl) ? vabs_v_i32m1(vec_a) : vec_a;\n            vse32_v_i32m1(B + i * cols + j, vec_b, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vint32m1_t vec_a = vle32_v_i32m1(A + i * cols + j, vl);\n            vboolm1_t mask = vmseq_v_i32m1_i32m1(vmodi_v_i32m1_i32m1(vec_a, (int32_t)3, vl), (int32_t)0, vl);\n            vint32m1_t vec_b = vmseq_v_i32m1_i32m1(mask, 1, vl) ? vabs_v_i32m1(vec_a) : vec_a;\n            vse32_v_i32m1(B + i * cols + j, vec_b, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vint32m1_t vec_a = vle32_v_i32m1(A + i * cols + j, vl);\n            vboolm1_t mask = vmseq_v_i32m1_i32m1(vmodi_v_i32m1_i32m1(vec_a, (int32_t)3, vl), (int32_t)0, vl);\n            vint32m1_t vec_b = vmseq_v_i32m1_i32m1(mask, (int32_t)1, vl) ? vabs_v_i32m1(vec_a) : vec_a;\n            vse32_v_i32m1(B + i * cols + j, vec_b, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vint32m1_t vec_a = vle32_v_i32m1(A + i * cols + j, vl);\n            vboolm1_t mask = vmseq_v_i32m1_i32m1(vmodi_v_i32m1_i32m1(vec_a, (int32_t)3, vl), (int32_t)0, vl);\n            vint32m1_t vec_b = vmseq_v_i32m1_i32m1(mask, 1, vl) ? vabs_v_i32m1(vec_a) : vec_a;\n            vse32_v_i32m1(B + i * cols + j, vec_b, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_47_RVV", "completion": "```c\nvoid matrix_conditional_abs_simd(const int* A, int* B, size_t rows, size_t cols) {\n    size_t vl = vsetvl_e32m1(cols);\n    for (size_t i = 0; i < rows; i++) {\n        for (size_t j = 0; j < cols; j += vl) {\n            vint32m1_t vec_a = vle32_v_i32m1(A + i * cols + j, vl);\n            vboolm1_t mask = vmseq_v_i32m1_i32m1(vmodi_v_i32m1_i32m1(vec_a, (int32_t)3, vl), (int32_t)0, vl);\n            vint32m1_t vec_b = vmseq_v_i32m1_i32m1(mask, 1, vl) ? vabs_v_i32m1(vec_a) : vec_a;\n            vse32_v_i32m1(B + i * cols + j, vec_b, vl);\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while(vl > 0){\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vboolm1_t cond_vec = vmseq_vim_u32m1(src_vec, 0xF, vl); // Check if low 4 bits are all 1\n\n        vuint32m1_t rotated_vec = vror_vx_u32m1(src_vec, rotate_bits, vl); // Rotate left by rotate_bits\n        vuint32m1_t negated_vec = vnot_v_u32m1(src_vec); // Bitwise negation\n\n        vse32_v_u32m1(dst_ptr, vmux_vxx_u32m1(cond_vec, rotated_vec, negated_vec, vl), vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e32m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while(vl > 0){\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vboolm1_t cond_vec = vmseq_vim_u32m1(src_vec, 0xF, vl); // Check if low 4 bits are all 1\n\n        vuint32m1_t rotated_vec = vror_vx_u32m1(src_vec, rotate_bits, vl); // Rotate left by rotate_bits\n        vuint32m1_t negated_vec = vnot_v_u32m1(src_vec); // Bitwise negation\n\n        vse32_v_u32m1(dst_ptr, vmux_vxx_u32m1(cond_vec, rotated_vec, negated_vec, vl), vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e32m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while(vl > 0){\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vboolm1_t cond_vec = vmseq_vx_u32m1(src_vec, 0xF, vl); // Check if low 4 bits are all 1\n\n        vuint32m1_t rotated_vec = vror_vx_u32m1(src_vec, rotate_bits, vl); // Rotate left if condition met\n        vuint32m1_t negated_vec = vnot_v_u32m1(src_vec); // Negate otherwise\n\n        vse32_v_u32m1(dst_ptr, vmux_vxx_u32m1(cond_vec, rotated_vec, negated_vec, vl), vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e32m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while(vl > 0){\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vbool4_t cond = vmseq_v_i32m1_u32m1(vand_vv_u32m1(src_vec, 0xF), 0xF, vl);\n        \n        vuint32m1_t rotated = vror_vx_u32m1(src_vec, rotate_bits, vl);\n        vuint32m1_t negated = vnot_v_u32m1(src_vec);\n\n        vse32_v_u32m1(dst_ptr, vmux_vxx_u32m1(cond, rotated, negated, vl), vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e32m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_48_RVV", "completion": "```c\nvoid matrix_conditional_bit_rotate_simd(const uint32_t* src, uint32_t* dst, uint8_t rotate_bits, size_t length){\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint32_t* dst_ptr = dst;\n\n    while(vl > 0){\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vboolm1_t cond_vec = vmseq_vim_u32m1(src_vec, 0xF, vl); // Check if low 4 bits are all 1\n\n        vuint32m1_t rotated_vec = vror_vx_u32m1(src_vec, rotate_bits, vl); // Rotate left if condition met\n        vuint32m1_t negated_vec = vnot_v_u32m1(src_vec); // Negate otherwise\n\n        vse32_v_u32m1(dst_ptr, vmux_vmm_u32m1(cond_vec, rotated_vec, negated_vec, vl), vl);\n\n        src_ptr += vl;\n        dst_ptr += vl;\n        vl = vsetvl_e32m1(length - (src_ptr - src));\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_B, vl);\n        vfloat32m1_t vec_epsilon = vfmul_vf_f32m1(vfmabs_vf_f32m1(vle32_v_f32m1((float*)&epsilon, 1), vl), -1.0f, vl);\n        \n        vbool32m1_t cond_gt = vcompge_vx_f32m1(vec_diff, vec_epsilon, vl);\n        vbool32m1_t cond_lt = vcomple_vx_f32m1(vec_diff, vec_epsilon, vl);\n        \n        vint8m1_t vec_out = vmseq_vx_i8m1(vec_diff, 0, vl); // Initialize to 0\n        vec_out = vmv_x_b8m1(vec_out, 1, cond_gt);         // Set to 1 where diff > epsilon\n        vec_out = vmv_x_b8m1(vec_out, -1, cond_lt);        // Set to -1 where diff < -epsilon\n        \n        vse8_v_i8m1(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_B, vl);\n        vfloat32m1_t vec_epsilon = vfmul_vf_f32m1(vfmabs_vf_f32m1(vle32_v_f32m1((float*)&epsilon, 1), vl), -1.0f, vl);\n        \n        vbool32m1_t cond_gt = vcompge_vx_f32m1(vec_diff, 0.0f, vl);\n        vbool32m1_t cond_lt = vcompge_vx_f32m1(vec_diff, 0.0f, vl);\n        \n        vint8m1_t vec_out = vmseq_vx_i8m1(vec_diff, 0, vl);\n        vec_out = vmv_x_b8m1(vec_out, cond_gt, 1);\n        vec_out = vmv_x_b8m1(vec_out, cond_lt, -1);\n        \n        vse8_v_i8m1(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_B, vl);\n        vfloat32m1_t vec_epsilon = vfmul_vf_f32m1(vfmabs_vf_f32m1(vle32_v_f32m1((float*)&epsilon, 1), vl), -1.0f, vl);\n        \n        vbool32m1_t cond_gt = vcompge_vx_f32m1(vec_diff, 0, vl);\n        vbool32m1_t cond_lt = vcompge_vx_f32m1(vec_diff, 0, vl);\n        \n        vint8m1_t vec_out = vmseq_vx_i8m1(vec_diff, 0, vl);\n        vec_out = vmv_x_b8_m(vec_out, (int8_t)1, cond_gt);\n        vec_out = vmv_x_b8_m(vec_out, (int8_t)-1, cond_lt);\n        \n        vse8_v_i8m1(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vec_diff = vsub_vv_i32m1(vec_A, vec_B, vl);\n        vfloat32m1_t vec_epsilon = vfmul_vf_f32m1(vfabs_v_f32m1(vle32_v_f32m1(&epsilon, 1)), 1.0f, vl);\n\n        vboolm1_t cond_gt = vcomp_gt_vx(vec_diff, 0, vl);\n        vboolm1_t cond_lt = vcomp_lt_vx(vec_diff, 0, vl);\n\n        vint8m1_t vec_out_gt = vmseq_vx_i8m1(vec_diff, 1, vl);\n        vint8m1_t vec_out_lt = vmseq_vx_i8m1(vec_diff, -1, vl);\n        vint8m1_t vec_out_eq = vmseq_vx_i8m1(vec_diff, 0, vl);\n\n        vint8m1_t vec_out = vmselect(cond_gt, vec_out_gt, vmselect(cond_lt, vec_out_lt, vec_out_eq));\n\n        vse8_v_i8m1(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_49_RVV", "completion": "```c\nvoid tensor_ternary_compare_simd(const float* A, const float* B, int8_t* out, float epsilon, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    for (size_t i = 0; i < length; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_B = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vec_diff = vfsub_vf_f32m1(vec_A, vec_B, vl);\n        vfloat32m1_t vec_epsilon = vfmul_vf_f32m1(vfmabs_vf_f32m1(vec_diff, vl), epsilon, vl);\n        \n        vbool32m1_t cond_gt = vfredge_v_m_b32m1(vfmax_vf_f32m1(vec_diff, 0.0f, vl), vec_epsilon, vl);\n        vbool32m1_t cond_lt = vfredge_v_m_b32m1(vfmin_vf_f32m1(vec_diff, 0.0f, vl), -vec_epsilon, vl);\n        \n        vint8m1_t vec_out = vmseq_vx_i8m1(cond_gt, 1, vl);\n        vec_out = vmseq_vx_i8m1(cond_lt, -1, vl);\n        \n        vse8_v_i8m1(out + i, vec_out, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const float* A_ptr = A;\n    int32_t* B_ptr = B;\n\n    while (size > 0) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A_ptr, vl);\n        vint32m1_t vec_B = vfncvt_x_f_w_v_i32m1(vec_A, vl);\n\n        // Saturate to INT32_MIN\n        vboolm1_t lt_min_mask = vfredmin_vs_b_m_f32m1(vint32m1_t(INT32_MIN), vec_B, vl);\n        vec_B = vmerge_vx_i32m1(vec_B, INT32_MIN, lt_min_mask);\n\n        // Saturate to INT32_MAX\n        vboolm1_t gt_max_mask = vfredmax_vs_b_m_f32m1(vint32m1_t(INT32_MAX), vec_B, vl);\n        vec_B = vmerge_vx_i32m1(vec_B, INT32_MAX, gt_max_mask);\n\n        vse32_v_i32m1(B_ptr, vec_B, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const float* A_ptr = A;\n    int32_t* B_ptr = B;\n\n    while (size > 0) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A_ptr, vl);\n        vint32m1_t vec_B = vfncvt_x_f_w_v_i32m1(vec_A, vl);\n\n        // Saturate to INT32_MIN\n        vboolm1_t lt_min_mask = vmflt_vx_f32m1(vec_A, (float)INT32_MIN, vl);\n        vint32m1_t min_vec = vmslt_vx_i32m1(vec_B, INT32_MIN, vl);\n        vec_B = vmerge_vx_i32m1(vec_B, INT32_MIN, lt_min_mask);\n\n        // Saturate to INT32_MAX\n        vboolm1_t gt_max_mask = vmfgt_vx_f32m1(vec_A, (float)INT32_MAX, vl);\n        vint32m1_t max_vec = vmsgt_vx_i32m1(vec_B, INT32_MAX, vl);\n        vec_B = vmerge_vx_i32m1(vec_B, INT32_MAX, gt_max_mask);\n\n        vse32_v_i32m1(B_ptr, vec_B, vl);\n\n        size -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const float* A_ptr = A;\n    int32_t* B_ptr = B;\n\n    while (size > 0) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A_ptr, vl);\n        vint32m1_t vec_B = vfncvt_x_f_w_v_i32m1(vec_A, vl);\n\n        // Saturate to INT32_MIN\n        vboolm1_t lt_min_mask = vclipped_lt_v_i32m1(vec_B, INT32_MIN);\n        vint32m1_t min_vec = vsetvl_e32m1(1);\n        min_vec = vsub_vx_i32m1(min_vec, INT32_MIN);\n        vec_B = vmseq_vx_i32m1(vec_B, INT32_MIN, lt_min_mask);\n\n        // Saturate to INT32_MAX\n        vboolm1_t gt_max_mask = vclipped_gt_v_i32m1(vec_B, INT32_MAX);\n        vint32m1_t max_vec = vsetvl_e32m1(1);\n        max_vec = vadd_vx_i32m1(max_vec, INT32_MAX);\n        vec_B = vmseq_vx_i32m1(vec_B, INT32_MAX, gt_max_mask);\n\n        vse32_v_i32m1(B_ptr, vec_B, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const float* A_ptr = A;\n    int32_t* B_ptr = B;\n\n    while (size > 0) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A_ptr, vl);\n        vint32m1_t vec_B = vfncvt_x_f_w_v_i32m1(vec_A, vl);\n\n        // Clamp to INT32_MIN\n        vint32m1_t vec_min = vsetvl_e32m1(1);\n        int32_t min_val = INT32_MIN;\n        vint32m1_t vec_INT32_MIN = v\u52d2\u6d6e\u70b9\u6570\u5230\u6574\u6570\u7684\u9971\u548c\u8f6c\u6362\uff0c\u786e\u4fdd\u503c\u5728INT32\u8303\u56f4\u5185\u3002"}
{"task_id": "SimdBench_50_RVV", "completion": "```c\nvoid float_to_int_saturate_simd(const float* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const float* A_ptr = A;\n    int32_t* B_ptr = B;\n\n    while (size > 0) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A_ptr, vl);\n        vint32m1_t vec_B = vfncvt_x_f_w_v_i32m1(vec_A, vl, NULL);\n\n        // Clamp to INT32_MIN\n        vboolm1_t mask_min = vclippedmin_v_f32m1(vec_A, vl, INT32_MIN);\n        vint32m1_t vec_min = vsetvl_e32m1(1) ? vle32_v_i32m1((int32_t*)&INT32_MIN, 1) : vint32m1_t {0};\n        vec_B = vmseq_v_i32m1(vec_B, vec_min, mask_min);\n\n        // Clamp to INT32_MAX\n        vboolm1_t mask_max = vclippedmax_v_f32m1(vec_A, vl, INT32_MAX);\n        vint32m1_t vec_max = vsetvl_e32m1(1) ? vle32_v_i32m1((int32_t*)&INT32_MAX, 1) : vint32m1_t {0};\n        vec_B = vmseq_v_i32m1(vec_B, vec_max, mask_max);\n\n        vse32_v_i32m1(B_ptr, vec_B, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const int32_t* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vint32m1_t vec_A = vle32_v_i32m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vfncvt_f_x_v_f32m1(vec_A, vl);\n        vint32m1_t vec_scaled = vsmul_vx_i32m1(vec_B, (1 << scale), vl);\n        vse32_v_f32m1(B_ptr, vec_scaled, vl);\n\n        size -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const int32_t* src = A;\n    float* dst = B;\n\n    while (size > 0) {\n        vint32m1_t vec_src = vle32_v_i32m1(src, vl);\n        vfloat32m1_t vec_dst = vfncvt_f_x_v_f32m1(vec_src, vl);\n        vfloat32m1_t scaled_vec = vfmul_vf_f32m1(vec_dst, (float)(1 << scale), vl);\n        vse32_v_f32m1(dst, scaled_vec, vl);\n\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const int32_t* src = A;\n    float* dst = B;\n\n    while (size > 0) {\n        vint32m1_t vec_a = vle32_v_i32m1(src, vl);\n        vfloat32m1_t vec_b = vfncvt_f_x_v_f32m1(vec_a, vl);\n        vfloat32m1_t scaled_vec_b = vfadd_vf_f32m1(vec_b, (float)(1 << scale), vl);\n        vse32_v_f32m1(dst, scaled_vec_b, vl);\n\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const int32_t* src = A;\n    float* dst = B;\n\n    while (size > 0) {\n        vint32m1_t vec_a = vle32_v_i32m1(src, vl);\n        vfloat32m1_t vec_b = vfncvt_f_x_v_f32m1(vec_a, vl);\n        vfloat32m1_t scaled_vec_b = vfmul_vf_f32m1(vec_b, (float)(1 << scale), vl);\n        vse32_v_f32m1(dst, scaled_vec_b, vl);\n\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_51_RVV", "completion": "```c\nvoid int_to_float_scaled_simd(const int32_t* A, int8_t scale, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const int32_t* src = A;\n    float* dst = B;\n\n    while (size > 0) {\n        vint32m1_t vec_a = vle32_v_i32m1(src, vl);\n        vfloat32m1_t vec_b = vfncvt_f_x_v_f32m1(vec_a, vl);\n        vint32m1_t scaled_vec_a = vssrl_v_i32m1(vec_a, scale, vl);\n        vfloat32m1_t scaled_vec_b = vfncvt_f_x_v_f32m1(scaled_vec_a, vl);\n        vse32_v_f32m1(dst, scaled_vec_b, vl);\n\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t va = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vc = vfncvt_x_f_w_v_i32m1(va / vb, vl);\n        vse32_v_i32m1(C + i, vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t va = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vc = vfredround_vs_f32m1_i32m1(vfdiv_vx(va, 1.0f, vl), vb, vl);\n        vse32_v_i32m1(C + i, vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t va = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vc = vfncvt_x_f_w_v_i32m1(va / vb, vl);\n        vse32_v_i32m1(C + i, vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_a = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vec_b = vle32_v_f32m1(B + i, vl);\n        vfloat32m1_t vec_div = vfdiv_vf_f32m1(vec_a, vec_b, vl);\n        vint32m1_t vec_c = vrnd_x_f32m1(vec_div, vl);\n        vse32_v_i32m1(C + i, vec_c, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_52_RVV", "completion": "```c\nvoid float_div_round_simd(const float* A, const float* B, int32_t* C, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t va = vle32_v_f32m1(A + i, vl);\n        vfloat32m1_t vb = vle32_v_f32m1(B + i, vl);\n        vint32m1_t vc = vround_v_f32m1(va / vb, vl);\n        vse32_v_i32m1(C + i, vc, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    const double* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vbool16 vm = __riscv_vmsne_vxm_b16(vle32_v_f32(vsetvl_e32m1(1)), 0.0f, vl);\n        vdouble vd = vle64_v_d(vl);\n        \n        vfloat32_t vf_sat_max = vfmul_vx_f32(vsetvl_e32m1(1), FLT_MAX, vl);\n        vfloat32_t vf_sat_min = vfmul_vx_f32(vsetvl_e32m1(1), -FLT_MAX, vl);\n\n        vfloat32_t vf = vfcvt_x_f_f32(vd);\n        vf = __riscv_vsmask_select_b16(vm, vf, vf_sat_max);\n        vf = __riscv_vsmask_select_b16(vm, vf, vf_sat_min);\n\n        vse32_v_f32(B_ptr, vf, vl);\n        \n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n        vl = vsetvl_e64m1(size);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    const double* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vbool16 vm = __riscv_vmsne_vxm_b16(vle64_v_f64m1(A_ptr), 0.0, vl);\n        vfloat64 t1 = __riscv_vfsge_vx_f64m1(vle64_v_f64m1(A_ptr), (double)FLT_MAX, vl);\n        vfloat64 t2 = __riscv_vfslt_vx_f64m1(vle64_v_f64m1(A_ptr), (double)-FLT_MAX, vl);\n\n        vfloat32 t3 = vfncvt_x_f_f_v_f32m1(__riscv_vfwcvt_f_f_v_f64m1(vle64_v_f64m1(A_ptr), vl), vl);\n        vfloat32 t4 = vfmul_vf_f32m1(vfmul_vf_f32m1(t3, (float)(FLT_MAX / 2.0), vl), 2.0f, vl);\n\n        vfloat32 t5 = vfnmsub_vf_f32m1(t4, (float)2.0, (float)FLT_MAX, vl);\n        vfloat32 t6 = vfadd_vf_f32m1(t4, (float)FLT_MAX, vl);\n\n        vfloat32 t7 = __riscv_vselect_b_f32m1(t5, t6, t2, vl);\n        vfloat32 t8 = __riscv_vselect_b_f32m1(t7, t4, t1, vl);\n\n        vse32_v_f32m1(B_ptr, t8, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n        vl = vsetvl_e64m1(size);\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    const double* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vbool16 vm = __riscv_vmsne_vxm_b16(vle64_v_f64m1(A_ptr), 0.0, vl);\n        vfloat64 t = vfredmax_vs_f64m1_f64m1(vm, vle64_v_f64m1(A_ptr), vd_f64m1(0.0), vl);\n        vfloat32 res = vfncvt_x_f_f32m1(t, vl);\n        vfloat32 max_val = vd_f32m1(FLT_MAX);\n        vfloat32 min_val = vd_f32m1(-FLT_MAX);\n        res = vmerge_vvm_f32m1(res, max_val, vfredge_max_vf_f32m1(res, max_val, vl));\n        res = vmerge_vvm_f32m1(res, min_val, vfredge_min_vf_f32m1(res, min_val, vl));\n        vse32_v_f32m1(B_ptr, res, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    const double* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vfloat64_t vec_A = vle64_v_f64m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vfncvt_x_f_f32m1(vec_A, vl);\n\n        // Saturate to FLT_MAX and -FLT_MAX\n        vboolm1_t gt_mask = vfredge_vs_f64m1_bm(1.0f, vec_A, vl);\n        vboolm1_t lt_mask = vfredge_vs_f64m1_bm(-1.0f, vec_A, vl);\n        vfloat32m1_t max_val = vfmv_s_f_f32m1(FLT_MAX, vl);\n        vfloat32m1_t min_val = vfmv_s_f_f32m1(-FLT_MAX, vl);\n\n        vec_B = vmseq_vf_f32m1(vec_B, max_val, gt_mask, vl);\n        vec_B = vmslt_vf_f32m1(vec_B, min_val, lt_mask, vl);\n\n        vse32_v_f32m1(B_ptr, vec_B, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_53_RVV", "completion": "```c\nvoid double_to_float_saturate_simd(const double* A, float* B, size_t size) {\n    size_t vl = vsetvl_e64m1(size);\n    const double* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vfloat64_t vec_A = vle64_v_f64m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vfncvt_x_f_f_v_f32m1(vec_A, vl);\n\n        // Saturate to FLT_MAX and -FLT_MAX\n        vboolm1_t gt_mask = vfredge_vs_f64m1_bm(1.0f, vec_B, vl);\n        vboolm1_t lt_mask = vfredge_vs_f64m1_bm(-1.0f, vec_B, vl);\n        vec_B = vmseq_vf_f32m1(vec_B, FLT_MAX, gt_mask);\n        vec_B = vmseq_vf_f32m1(vec_B, -FLT_MAX, lt_mask);\n\n        vse32_v_f32m1(B_ptr, vec_B, vl);\n\n        A_ptr += vl;\n        B_ptr += vl;\n        size -= vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    const int16_t* src = A;\n    int32_t* dst = B;\n\n    while (size > 0) {\n        vint16m1_t vec_src = vle16_v_i16m1(src, vl);\n        vint32m1_t vec_dst = vmv_x_s_i32m1_i32(0);\n        vec_dst = vsext_vf32(vec_dst, vec_src);\n        vse32_v_i32m1(dst, vec_dst, vl);\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    const int16_t* src = A;\n    int32_t* dst = B;\n\n    while (size > 0) {\n        vint16m1_t vec_src = vle16_v_i16m1(src, vl);\n        vint32m1_t vec_dst = vmv_x_s_i32m1_i32(0);\n        vec_dst = vsext_vf32(vec_dst, vec_src);\n        vse32_v_i32m1(dst, vec_dst, vl);\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    const int16_t* src = A;\n    int32_t* dst = B;\n\n    while (size > 0) {\n        vint16m1_t vec_src = vle16_v_i16m1(src, vl);\n        vint32m1_t vec_dst = vmv_x_s_i32m1_i32(0);\n        vec_dst = vsext_vf32(vec_dst, vec_src);\n        vse32_v_i32m1(dst, vec_dst, vl);\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    const int16_t* src = A;\n    int32_t* dst = B;\n\n    while (size > 0) {\n        vint16m1_t vec_src = vle16_v_i16m1(src, vl);\n        vint32m1_t vec_dst = vmv_x_s_i32m1_i32(0);\n        vec_dst = vsext_vx_i32m1(vec_src);\n        vse32_v_i32m1(dst, vec_dst, vl);\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_54_RVV", "completion": "```c\nvoid int16_to_int32_simd(const int16_t* A, int32_t* B, size_t size) {\n    size_t vl = vsetvl_e16m1(size);\n    const int16_t* src = A;\n    int32_t* dst = B;\n\n    while (size > 0) {\n        vint16m1_t vec_src = vle16_v_i16m1(src, vl);\n        vint32m1_t vec_dst = vmv_x_s_i32m1_i32(0);\n        vec_dst = vsext_vf32(vec_dst, vec_src);\n        vse32_v_i32m1(dst, vec_dst, vl);\n        size -= vl;\n        src += vl;\n        dst += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vint32m1_t vec_control = vle32_v_i32m1(control + i, vl);\n        vfloat32m1_t vec_B;\n\n        // Compute min_val and max_val as vectors\n        vfloat32m1_t vec_min_val = vfmv_s_f_f32m1(min_val);\n        vfloat32m1_t vec_max_val = vfmv_s_f_f32m1(max_val);\n\n        // Compute the difference vector\n        vfloat32m1_t vec_diff = vsub_vx_f32m1(vec_A, min_val, vl);\n\n        // Compute the divisor vector\n        vfloat32m1_t vec_divisor = vsub_vx_f32m1(vec_max_val, min_val, vl);\n\n        // Perform division where control > 0\n        vboolm1_t mask = vmgt_vx_i32m1(vec_control, 0, vl);\n        vfloat32m1_t vec_normalized = vfredosum_vs_f32m1_f32m1_mask(vec_diff, vec_divisor, vl, mask);\n\n        // Clamp between 0.0f and 1.0f\n        vfloat32m1_t vec_clamped = vmax_vx_f32m1(vmin_vx_f32m1(vec_normalized, 1.0f, vl), 0.0f, vl);\n\n        // Copy where control <= 0\n        vfloat32m1_t vec_copy = vle32_v_f32m1(A + i, vl);\n        vec_B = vmerge_vv_f32m1(vec_clamped, vec_copy, mask);\n\n        // Store the result\n        vse32_v_f32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vint32m1_t vec_control = vle32_v_i32m1(control + i, vl);\n        vfloat32m1_t vec_B;\n\n        // Compute min-max normalization for control > 0\n        vfloat32m1_t vec_diff = vsub_vx_f32m1(vec_A, min_val, vl);\n        vfloat32m1_t vec_divisor = vsub_vx_f32m1(max_val, min_val, vl);\n        vfloat32m1_t vec_normalized = vdiv_vx_f32m1(vec_diff, vec_divisor, vl);\n\n        // Clamp to [0, 1]\n        vfloat32m1_t vec_clamped = vclip_f32m1(vec_normalized, 0.0f, 1.0f, vl);\n\n        // Conditional selection: use clamped value if control > 0, else copy A\n        vboolm1_t mask = vmgt_vx_i32m1(vec_control, 0, vl);\n        vec_B = vmerge_vx_f32m1(vec_clamped, vec_A, mask, vl);\n\n        // Store results\n        vse32_v_f32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vint32m1_t vec_control = vle32_v_i32m1(control + i, vl);\n        vfloat32m1_t vec_B;\n\n        // Compute min_max_normalized values where control > 0\n        vboolm1_t mask = vmgt_vx_i32m1(vec_control, 0, vl);\n        vfloat32m1_t vec_diff = vfsub_vx_f32m1(vec_A, min_val, vl);\n        vfloat32m1_t vec_range = vfsub_vx_f32m1(max_val, min_val, vl);\n        vfloat32m1_t vec_result = vfdiv_vx_f32m1(vec_diff, vec_range, vl);\n\n        // Clamp to [0, 1]\n        vec_result = vmax_vx_f32m1(vec_result, 0.0f, vl);\n        vec_result = vmin_vx_f32m1(vec_result, 1.0f, vl);\n\n        // Copy values where control <= 0\n        vec_B = vmerge_vxm_f32m1(vec_result, vec_A, mask, vl);\n\n        // Store results\n        vse32_v_f32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vint32m1_t vec_control = vle32_v_i32m1(control + i, vl);\n        vfloat32m1_t vec_B;\n\n        // Compute min_max_normalized values where control > 0\n        vboolm1_t mask = vmgt_vx_i32m1(vec_control, 0, vl);\n        vfloat32m1_t vec_diff = vsub_vx_f32m1(vec_A, min_val, vl);\n        vfloat32m1_t vec_range = vsub_vx_f32m1(max_val, min_val, vl);\n        vfloat32m1_t vec_result = vdiv_vx_f32m1(vec_diff, vec_range, vl);\n\n        // Clamp to [0, 1]\n        vec_result = vmax_vx_f32m1(vec_result, 0.0f, vl);\n        vec_result = vmin_vx_f32m1(vec_result, 1.0f, vl);\n\n        // Copy A where control <= 0\n        vfloat32m1_t vec_A_copy = vle32_v_f32m1(A + i, vl);\n        vec_B = vmerge_vv_f32m1(vec_result, vec_A_copy, mask, vl);\n\n        // Store results\n        vse32_v_f32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_55_RVV", "completion": "```c\nvoid conditional_normalize_simd(const float* A, const int32_t* control, float* B, size_t size, float min_val, float max_val) {\n    size_t vl = vsetvl_e32m1(size);\n    for (size_t i = 0; i < size; i += vl) {\n        vfloat32m1_t vec_A = vle32_v_f32m1(A + i, vl);\n        vint32m1_t vec_control = vle32_v_i32m1(control + i, vl);\n        vfloat32m1_t vec_B;\n\n        // Compute min_max_normalized values where control > 0\n        vboolm1_t mask = vmgt_vx_i32m1(vec_control, 0, vl);\n        vfloat32m1_t vec_diff = vsub_vx_f32m1(vec_A, min_val, vl);\n        vfloat32m1_t vec_range = vsub_vx_f32m1(max_val, min_val, vl);\n        vfloat32m1_t vec_normalized = vdiv_vx_f32m1(vec_diff, vec_range, vl);\n\n        // Clamp to [0, 1]\n        vec_normalized = vmax_vx_f32m1(vec_normalized, 0.0f, vl);\n        vec_normalized = vmin_vx_f32m1(vec_normalized, 1.0f, vl);\n\n        // Copy values where control <= 0\n        vec_B = vmerge_vx_f32m1(vec_normalized, vec_A, mask, vl);\n\n        // Store results\n        vse32_v_f32m1(B + i, vec_B, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vfredusum_vs_f32m1_u32m1(vfmul_vx_f32m1(vsqrt_v_f32m1(vec_a), 1.0f, vl), vec_a, vl);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vfredusum_vs_f32m1_u32m1(vfmul_vx_f32m1(vsqrt_vf_f32m1(vec_a, vl), 1.0f, vl), vec_a, vl);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vfredusum_vs_f32m1_u32m1(\n            vsqrt_vf_f32m1(vsextu_x_f32m1(vget_high_v_u32m1(vec_a), vl), 0.0f), vec_a, vl);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vfwcvt_f_x_v_f32m1(vget_high_w_v_u32m1(vec_a), vl);\n        vec_b = vsqrt_f32_v_f32m1(vec_b, vl);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_56_RVV", "completion": "```c\nvoid int_to_float_sqrt_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    for (size_t i = 0; i < size; i += vl) {\n        vuint32m1_t vec_in = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_out = vfredusum_vs_f32m1_f32m1(\n            vsqrt_vf_f32m1(vsextu_hf_f32m1(vec_in), vl), \n            vfmul_vf_f32m1(vec_in, 0.0f, vl), vl);\n        vse32_v_f32m1(dst_ptr, vec_out, vl);\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vreinterpret_v_f32m1_u32m1(vec_a);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vreinterpret_v_f32m1_u32m1(vec_A);\n        vse32_v_f32m1(B_ptr, vec_B, vl);\n\n        size -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* src_ptr = A;\n    float* dst_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_a = vle32_v_u32m1(src_ptr, vl);\n        vfloat32m1_t vec_b = vreinterpret_v_f32m1_u32m1(vec_a);\n        vse32_v_f32m1(dst_ptr, vec_b, vl);\n\n        size -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vreinterpret_v_f32m1_u32m1(vec_A);\n        vse32_v_f32m1(B_ptr, vec_B, vl);\n\n        size -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_57_RVV", "completion": "```c\nvoid int_bits_to_float_simd(const uint32_t* A, float* B, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    const uint32_t* A_ptr = A;\n    float* B_ptr = B;\n\n    while (size > 0) {\n        vuint32m1_t vec_A = vle32_v_u32m1(A_ptr, vl);\n        vfloat32m1_t vec_B = vreinterpret_v_f32m1_u32m1(vec_A);\n        vse32_v_f32m1(B_ptr, vec_B, vl);\n\n        size -= vl;\n        A_ptr += vl;\n        B_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vec_A;\n    vbool32_t vec_cond;\n    vfloat32m1_t vec_diff;\n\n    // Initialize diff[0] to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vec_A = vle32_v_i32m1(A + i, vl);\n        vec_cond = vbmslt_u32m1((vuint32m1_t)vle8_v_i8m1((const int8_t*)(cond + i), vl), 0);\n\n        // Compute A[i] - A[i-1]\n        vint32m1_t prev_A = vle32_v_i32m1(A + i - 1, vl);\n        vint32m1_t diff_A = vsub_vx_i32m1(vec_A, prev_A);\n\n        // Convert to float and apply condition\n        vec_diff = vfcvt_x_f_v_f32m1(vmslt_vx_u32m1(vec_cond, diff_A, diff_A), vl);\n\n        // Store result\n        vse32_v_f32m1(diff + i, vec_diff, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vec_A;\n    vbool32_t vec_cond;\n    vfloat32m1_t vec_diff;\n\n    // Initialize diff[0] to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vec_A = vle32_v_i32m1(A + i, vl);\n        vec_cond = vbmslt_v_i32m1_u32m1((vint32m1_t)vle32_v_i32m1((const int32_t*)cond + i, vl), 0);\n        vec_diff = vsub_vv_f32m1(vec_A, vle32_v_i32m1(A + i - 1, vl));\n        vec_diff = vmseq_vx_f32m1(vec_diff, 0.0f, vec_cond);\n        vse32_v_f32m1(diff + i, vec_diff, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vec_A_prev = vle32_v_i32m1(A, vl);\n    vbool32_t vec_cond = vbmslt_u32m1((uint32_t)vget_v_i32m1(vec_A_prev, 0), (uint32_t)vget_v_i32m1(vec_A_prev, 0));\n    vfloat32m1_t vec_diff = vfmv_s_f_f32m1(0.0f, vl);\n\n    for (size_t i = 1; i < size; i++) {\n        vint32m1_t vec_A_curr = vle32_v_i32m1(A + i, vl);\n        vint32m1_t vec_diff_temp = vsub_vx_i32m1(vec_A_curr, vget_v_i32m1(vec_A_prev, 0));\n        vbool32_t vec_cond_temp = vbmslt_u32m1((uint32_t)vget_v_i32m1(vec_A_curr, 0), (uint32_t)vget_v_i32m1(vec_A_curr, 0));\n        vec_diff_temp = vmseq_vx_i32m1(vec_diff_temp, 0, vec_cond_temp);\n        vec_diff = vmerge_vx_f32m1(vfcvt_x_f_f32m1(vec_diff_temp), vec_diff, vec_cond_temp);\n        vse32_v_i32m1(diff + i, vec_diff, vl);\n        vec_A_prev = vec_A_curr;\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vec_A;\n    vbool16_t vec_cond;\n    vfloat32m1_t vec_diff;\n\n    // Initialize diff[0] to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vec_A = vle32_v_i32m1(A + i, vl);\n        vec_cond = vbmslt_v_i32m1_b16(cond + i, vl);\n        vint32m1_t prev_vec_A = vle32_v_i32m1(A + i - 1, vl);\n        vec_diff = vsub_vx_f32m1(vfredusum_vs_f32m1_i32m1(vfnmsub_vx_f32m1(vec_A, 1.0f, prev_vec_A), vec_cond, 0.0f), vec_cond);\n        vse32_v_f32m1(diff + i, vec_diff, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_58_RVV", "completion": "```c\nvoid conditional_diff_simd(const int32_t* A, const bool* cond, float* diff, size_t size) {\n    size_t vl = vsetvl_e32m1(size);\n    vint32m1_t vec_A;\n    vbool16_t vec_cond;\n    vfloat32m1_t vec_diff;\n\n    // Initialize diff[0] to 0.0f\n    diff[0] = 0.0f;\n\n    for (size_t i = 1; i < size; i += vl) {\n        vl = vsetvl_e32m1(size - i);\n        vec_A = vle32_v_i32m1(A + i, vl);\n        vec_cond = vbmslt_v_i32m1_u8(vle8_v_u8m1((const uint8_t*)(cond + i), vl), 0);\n\n        // Compute A[i] - A[i-1]\n        vint32m1_t prev_vec_A = vle32_v_i32m1(A + i - 1, vl);\n        vint32m1_t diff_vec = vsub_vx_i32m1(vec_A, vlsr_w_i32m1(prev_vec_A, 1));\n\n        // Convert to float and apply condition mask\n        vec_diff = vfncvt_f_x_v_f32m1(diff_vec, vec_cond);\n\n        // Store results\n        vse32_v_f32m1(diff + i, vec_diff, vl);\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint64_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint64m1_t dst_vec = vmseq_vx_u64m1(vluxei32_v_u64m1(src_vec, 0, vl), 0xFFFFFFFF00000000UL, vl);\n        vse64_v_u64m1(dst_ptr, dst_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint64_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint64m1_t dst_vec = vmseq_vx_u64m1(vluxei32_v_u64m1(src_vec, 0, vl), 0xFFFFFFFF00000000UL, vl);\n        vse64_v_u64m1(dst_ptr, dst_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint64_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint64m1_t dst_vec = vmseq_vx_u64m1(vluxei32_v_u64m1(src_vec, 0, vl), 0xFFFFFFFF00000000UL, vl);\n        vse64_v_u64m1(dst_ptr, dst_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint64_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint64m1_t dst_vec = vmseq_vx_u64m1(vluxei32_v_u64m1(src_vec, 0, vl), 0xFFFFFFFF00000000UL, vl);\n        vse64_v_u64m1(dst_ptr, dst_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_59_RVV", "completion": "```c\nvoid widening_uint_simd(const uint32_t* src, uint64_t* dst, size_t length) {\n    size_t vl = vsetvl_e32m1(length);\n    const uint32_t* src_ptr = src;\n    uint64_t* dst_ptr = dst;\n\n    while (length > 0) {\n        vuint32m1_t src_vec = vle32_v_u32m1(src_ptr, vl);\n        vuint64m1_t dst_vec = vmseq_vx_u64m1(vluxei32_v_u64m1(src_vec, 0, vl), 0xFFFFFFFF00000000UL, vl);\n        vse64_v_u64m1(dst_ptr, dst_vec, vl);\n\n        length -= vl;\n        src_ptr += vl;\n        dst_ptr += vl;\n    }\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    vfloat64m1_t vs_sum = vfmv_f_s_f64m1_f64(0.0);\n    for (size_t i = 0; i < length; i += 8) {\n        vint16m8_t vi_indices = vle16_v_i16m8(index + i, 8);\n        vbool16m8_t vmask = vmseq_v_i16m8_i16(vi_indices, vi_indices);\n        vfloat64m8_t vs_vec = vle64_v_f64m8(vec + vlsse32(vi_indices, vi_indices, length), 8, vmask);\n        vs_sum = vfadd_vf_f64m1(vs_sum, vfredsum_vs_f64m8_f64(vs_vec, vs_sum));\n    }\n    return vfmv_s_f_f64_f64(vs_sum);\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    vfloat64m1_t vec_sum = vfmv_f_s_f64m1_f64(0.0);\n    for (size_t i = 0; i < length; i += 8) {\n        vint16m8_t idx_vec = vle16_v_i16m8(index + i, 8);\n        vbool16m8_t mask = vmslt_int_v_i16m8_i16m8(idx_vec, (vint16m8_t)vflsub(0, 1));\n        vfloat64m8_t vec_sel = vle64_v_f64m8(vec + vlsse32(0, idx_vec, 1), 8, mask);\n        vec_sum = vfadd_sum_vs_f64m1_f64m8(vec_sum, vec_sel, mask);\n    }\n    return vfmv_s_f_f64_f64(vredsum_vs_f64m1_f64m1(vec_sum, vec_sum, NULL));\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    vfloat64m1_t vs_sum = vfmv_f_s_f64m1_f64(0.0);\n    for (size_t i = 0; i < length; i += 8) {\n        vint16m2_t vi_idx = vle16_v_i16m2(index + i, 8);\n        vbool16 vmask = vmslt_vx_i16m2(0, vi_idx, 8); // Mask for valid indices\n        vfloat64m1_t vs_vec = vle64_v_f64m1(vec + vlsse32(vi_idx, vi_idx, 8), 8);\n        vs_sum = vfredusum_vs_f64m1_f64m1(vs_sum, vs_vec, vmseq_v_i16m2_i16m2(vi_idx, vi_idx, 8));\n    }\n    double sum = 0.0;\n    for (size_t i = 0; i < 8; i++) {\n        sum += vfncvt_x_f_f64m1(vs_sum, i);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    vfloat64m1_t vec_sum = vfmv_f_s_f64m1_f64(0.0);\n    for (size_t i = 0; i < length; i += 8) {\n        vint16m2_t idx_vec = vle16_v_i16m2(index + i, 8);\n        vbool16m2_t mask = vmslt_int_v_i16m2_i16m2(idx_vec, vint16m2_v_i16m2(length));\n        vfloat64m1_t vec_part = vle64_v_f64m1(vec + vlsse32_v_i32m2_i32(idx_vec, mask), 8);\n        vec_sum = vfadd_vf_f64m1_f64(vec_sum, vfredsum_vs_f64m1_f64m1(vec_part, vec_sum, mask));\n    }\n    return vfmv_s_f_f64_f64(vfredsum_vs_f64m1_f64m1(vec_sum, vfmv_f_s_f64_f64(0.0), vsetvl_e64m1(1)));\n}\n```"}
{"task_id": "SimdBench_60_RVV", "completion": "```c\ndouble indexed_sum_simd(const double* vec, const int16_t* index, size_t length) {\n    vfloat64m1_t vs_sum = vfmv_f_s_f64m1_f64(0.0);\n    for (size_t i = 0; i < length; i += 8) {\n        vint16m8_t vi_indices = vle16_v_i16m8(index + i, 8);\n        vbool16m8_t vmask = vmseq_v_i16m8_i16(vi_indices, vi_indices);\n        vfloat64m8_t vs_vec = vle64_v_f64m8(vec + i, 8);\n        vfloat64m8_t vs_selected = vmsltu_v_i16m8_f64m8(vs_vec, vi_indices, vmask);\n        vs_sum = vfadd_vf_f64m1(vs_sum, vfredsum_vs_f64m8_f64m1(vs_selected), 8);\n    }\n    return vfmv_s_f_f64_f64m1(vs_sum);\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t vl = vsetvl_e64m1(kernel_size * kernel_size);\n    size_t out_h = input_size - kernel_size + 1;\n    size_t out_w = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < out_h; i++) {\n        for (size_t j = 0; j < out_w; j++) {\n            vfloat64m1_t sum = vfmul_vf_e64m1(vle64_v_f64m1(kernel, vl), 0.0, vl);\n            for (size_t m = 0; m < kernel_size; m++) {\n                for (size_t n = 0; n < kernel_size; n++) {\n                    size_t idx_in = (i + m) * input_size + (j + n);\n                    size_t idx_ker = m * kernel_size + n;\n                    sum = vfadd_vv_e64m1(sum, vfmul_vf_e64m1(vle64_v_f64m1(input + idx_in, vl), vle64_v_f64m1(kernel + idx_ker, vl), vl), vl);\n                }\n            }\n            double result = vfmax_vf_f64m1(sum, 0.0, vl);\n            output[i * out_w + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t vl = vsetvl_e64m1(kernel_size * kernel_size);\n    size_t out_h = input_size - kernel_size + 1;\n    size_t out_w = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < out_h; i++) {\n        for (size_t j = 0; j < out_w; j++) {\n            vfloat64xm1_t sum = vfmul_vf_e64m1(vle64_v_f64m1(kernel, vl), 0.0, vl);\n            for (size_t m = 0; m < kernel_size; m++) {\n                for (size_t n = 0; n < kernel_size; n++) {\n                    size_t idx_in = (i + m) * input_size + (j + n);\n                    size_t idx_ker = m * kernel_size + n;\n                    sum = vfadd_vv_e64m1(sum, vfmul_vf_e64m1(vle64_v_f64m1(input + idx_in, vl), vle64_v_f64m1(kernel + idx_ker, vl), vl), vl);\n                }\n            }\n            double result = vfmax_vf_e64m1(sum, 0.0, vl);\n            output[i * out_w + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t vl = vsetvl_e64m1(kernel_size * kernel_size);\n    size_t out_h = input_size - kernel_size + 1;\n    size_t out_w = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < out_h; i++) {\n        for (size_t j = 0; j < out_w; j++) {\n            vfloat64xm1_t sum = vfmul_vf_e64m1(vle64_v_f64m1(kernel, vl), 0.0, vl);\n            for (size_t m = 0; m < kernel_size; m++) {\n                for (size_t n = 0; n < kernel_size; n++) {\n                    size_t idx_in = (i + m) * input_size + (j + n);\n                    size_t idx_ker = m * kernel_size + n;\n                    sum = vfadd_vv_e64m1(sum, vfmul_vf_e64m1(vle64_v_f64m1(input + idx_in, vl), vle64_v_f64m1(kernel + idx_ker, vl), vl), vl);\n                }\n            }\n            double result = vfmax_vf_f64m1(sum, 0.0, vl);\n            output[i * out_w + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t vl = vsetvl_e64m1(kernel_size * kernel_size);\n    size_t out_h = input_size - kernel_size + 1;\n    size_t out_w = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < out_h; i++) {\n        for (size_t j = 0; j < out_w; j++) {\n            vfloat64xm1_t sum = vfmul_vf_e64m1(vle64_v_f64m1(kernel, vl), 0.0, vl);\n            for (size_t m = 0; m < kernel_size; m++) {\n                for (size_t n = 0; n < kernel_size; n++) {\n                    size_t idx_in = (i + m) * input_size + (j + n);\n                    size_t idx_ker = m * kernel_size + n;\n                    sum = vfadd_vv_e64m1(sum, vfmul_vf_e64m1(vle64_v_f64m1(input + idx_in, vl), vle64_v_f64m1(kernel + idx_ker, vl), vl), vl);\n                }\n            }\n            double result = vfmax_vf_f64m1(sum, 0.0, vl);\n            output[i * out_w + j] = result;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_61_RVV", "completion": "```c\nvoid simple_conv2d_simd(const double* input, const double* kernel, double * output, size_t input_size, size_t kernel_size) {\n    size_t vlen = vsetvl_e64m1(1);\n    size_t out_size = input_size - kernel_size + 1;\n\n    for (size_t i = 0; i < out_size; i++) {\n        for (size_t j = 0; j < out_size; j++) {\n            size_t idx = i * input_size + j;\n            double sum = 0.0;\n            for (size_t m = 0; m < kernel_size; m++) {\n                for (size_t n = 0; n < kernel_size; n++) {\n                    size_t k_idx = m * kernel_size + n;\n                    size_t in_idx = (i + m) * input_size + (j + n);\n                    sum += input[in_idx] * kernel[k_idx];\n                }\n            }\n            output[idx] = sum > 0.0 ? sum : 0.0;\n        }\n    }\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    size_t len = numbers.size();\n    size_t vl = vsetvl_e64m1(len);\n    const double *nums = numbers.data();\n    bool has_close = false;\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e64m1(len - i);\n        vfloat64m1_t vec = vle64_v_f64m1(nums + i, this_vl);\n        for(size_t j=0; j<this_vl; j++){\n            for(size_t k=j+1; k<this_vl; k++){\n                float64_t diff = fabs(vfmul_vf_f64m1(vec, -1.0, this_vl)[j] - vfmul_vf_f64m1(vec, -1.0, this_vl)[k]);\n                if(diff < threshold){\n                    has_close = true;\n                    break;\n                }\n            }\n            if(has_close) break;\n        }\n        if(has_close) break;\n    }\n    return has_close;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    const size_t vl = vsetvl_e64m1(numbers.size());\n    const double *data = numbers.data();\n    for (size_t i = 0; i < numbers.size(); i += vl) {\n        size_t len = std::min(vl, numbers.size() - i);\n        vfloat64m1_t vec = vle64_v_f64m1(data + i, len);\n        for (size_t j = 0; j < len; j++) {\n            for (size_t k = j + 1; k < len; k++) {\n                double diff = std::abs(vfmv_f_s_f64m1_f64(vec, j) - vfmv_f_s_f64m1_f64(vec, k));\n                if (diff < threshold) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    size_t len = numbers.size();\n    size_t vl = vsetvl_e64m1(len);\n    const double *data = numbers.data();\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e64m1(std::min(len - i, vl));\n        vfloat64m1_t vec = vle64_v_f64m1(data + i, this_vl);\n        for(size_t j=0; j<this_vl; j++){\n            for(size_t k=j+1; k<this_vl; k++){\n                double diff = std::fabs(vfmv_f_s_f64m1_f64(vsub_vv_f64m1(vec, j, k, this_vl)) - data[i+j]);\n                if(diff < threshold){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```c\nbool has_close_elements_simd(const std::vector<double> & numbers, double threshold){\n    size_t vl = vsetvl_e64m1(numbers.size());\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    \n    for(size_t i = 0; i < numbers.size(); i++){\n        vfloat64m1_t diff = vsub_vv_f64m1(vec_numbers, vec_numbers, vl);\n        vboolm1_t mask = vfredmin_vs_f64m1_bm(diff, vcreate_boolm1(0), vl);\n        if(vmsbf_m_f64m1(mask)){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_62_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nbool has_close_elements_simd(const std::vector<double> &numbers, double threshold) {\n    const size_t vl = vsetvl_e64m1(numbers.size());\n    const double *data = numbers.data();\n    for (size_t i = 0; i < numbers.size(); i += vl) {\n        size_t l = vl;\n        if (i + vl > numbers.size()) {\n            l = numbers.size() - i;\n        }\n        vfloat64m1_t vec = vle64_v_f64m1(data + i, l);\n        for (size_t j = 0; j < l; j++) {\n            for (size_t k = j + 1; k < l; k++) {\n                double diff = std::fabs(vget_f64(vec, j) - vget_f64(vec, k));\n                if (diff < threshold) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    size_t vl = vsetvl_e32m1(operations.size());\n    int32xm1_t ops_vec = vle32_v_i32m1(operations.data(), vl);\n    int32xm1_t balance_vec = vsub.vx_i32m1(ops_vec, vint32xm1_zero, vl);\n    \n    for(int i=1; i<vl; i++){\n        balance_vec = vadd.vv_i32m1(balance_vec, vsub.vx_i32m1(vget_v_i32m1(balance_vec, i, 1), ops_vec, vl), vl);\n        if(vmslt_x_mask_i32m1(balance_vec, vint32xm1_zero, vl)){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    size_t vl = vsetvl_e32m1(operations.size());\n    int32xm1_t acc = vlmul_vx_i32xm1(0, vl, vl);\n    \n    for(size_t i = 0; i < operations.size(); i += vl){\n        size_t chunk_size = (operations.size() - i >= vl) ? vl : operations.size() - i;\n        int32xm1_t ops = vle32_v_i32xm1(&operations[i], chunk_size);\n        acc = vadd_vx(acc, vlsux(acc, chunk_size, vl), vl);\n        acc = vadd_vx(acc, ops, vl);\n        \n        if(vmsltu_mask(acc, vl)){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    size_t vl = vsetvl_e32m1(operations.size());\n    int32xm1_t ops_vec = vle32_v_i32m1(operations.data(), vl);\n    int32xm1_t balance_vec = vsub.vx_i32m1(ops_vec, vint32xm1_zero, vl);\n    \n    for(int i=1; i<vl; i++){\n        balance_vec = vadd.vv_i32m1(balance_vec, vsub.vx_i32m1(vget_v_i32m1(balance_vec, i, 1), ops_vec, vl), vl);\n        if(vmslt_x_m_b32m1(balance_vec, vint32xm1_zero, vl)){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    size_t vl = vsetvl_e32m1(operations.size());\n    vint32m1_t vec_ops = vlev_int32m1(operations.data(), vl);\n    vint32m1_t acc = vsub.vx_int32m1(vint32m1_t(), vec_ops, vl);\n    int32_t min_balance = vredmin_vs_int32m1_int32m1(acc, acc, vint32m1_t(), vl);\n    return min_balance < 0;\n}\n```"}
{"task_id": "SimdBench_63_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_zero_simd(std::vector<int> operations){\n    size_t vl = vsetvl_e32m1(operations.size());\n    int32xm1_t acc = vlmul_vx_i32xm1(0, vl, vl);\n    \n    for(size_t i = 0; i < operations.size(); i += vl){\n        size_t chunk_size = (operations.size() - i >= vl) ? vl : operations.size() - i;\n        int32xm1_t ops = vle32_v_i32xm1(&operations[i], chunk_size);\n        acc = vadd_vx(acc, vlsux(acc, chunk_size), vl);\n        acc = vadd_vx(acc, ops, vl);\n        int32xm1_t zero = vlmul_vx_i32xm1(0, vl, vl);\n        if(vmsltu_mask(acc, zero, vl)){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t vl = vsetvl_e64m1(numbers.size());\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    vfloat64m1_t mean_vec = vfmul_vf_f64m1(vec_numbers, 0.0, vl); // Initialize with zero\n    float64m1_t sum = vfredusum_vs_f64m1_f64m1(mean_vec, vec_numbers, mean_vec, vl);\n    double mean = sum / numbers.size();\n    \n    vfloat64m1_t mean_rep = vfmul_vf_f64m1(vle64_v_f64m1(&mean, 1), vl);\n    vfloat64m1_t deviations = vfabs_vf_f64m1(vsub_vf_f64m1(vec_numbers, mean_rep, vl), vl);\n    vfloat64m1_t mad_sum = vfredusum_vs_f64m1_f64m1(deviations, deviations, deviations, vl);\n    return mad_sum / numbers.size();\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t vl = vsetvl_e64m1(numbers.size());\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    vfloat64m1_t mean_vec = vfmul_vf_f64m1(vec_numbers, 0.0, vl); // Initialize with zero\n    float64m1_t sum = vfredusum_vs_f64m1_f64m1(mean_vec, vec_numbers, mean_vec, vl);\n    double mean = sum / numbers.size();\n    \n    vfloat64m1_t mean_rep = vfmul_vf_f64m1(vle64_v_f64m1(&mean, 1), vl);\n    vfloat64m1_t deviations = vfabs_vf_f64m1(vsub_vf_f64m1(vec_numbers, mean_rep, vl), vl);\n    vfloat64m1_t mad_sum = vfredusum_vs_f64m1_f64m1(deviations, deviations, deviations, vl);\n    return mad_sum / numbers.size();\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t vl = vsetvl_e64m1(numbers.size());\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    vfloat64m1_t mean_vec = vfmul_vf_f64m1(vec_numbers, 0.0, vl); // Initialize with zero\n    float64_t sum = 0.0;\n\n    mean_vec = vredsum_vs_f64m1_f64m1(mean_vec, vec_numbers, mean_vec, vl);\n    sum = mean_vec[0];\n\n    double mean = sum / numbers.size();\n\n    vfloat64m1_t mean_rep = vfmul_vf_f64m1(vle64_v_f64m1(&mean, 1), vl);\n    vfloat64m1_t deviations = vfabs_vf_f64m1(vsub_vf_f64m1(vec_numbers, mean_rep, vl), vl);\n\n    deviations = vredsum_vs_f64m1_f64m1(deviations, deviations, deviations, vl);\n    double mad_sum = deviations[0];\n\n    return mad_sum / numbers.size();\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t vl = vsetvl_e64m1(numbers.size());\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    vfloat64m1_t mean_vec = vfmul_vf_f64m1(vec_numbers, 0.0, vl); // Initialize mean vector\n    double sum = 0.0;\n    for(int i=0; i<numbers.size(); i++) {\n        sum += numbers[i];\n    }\n    double mean = sum / numbers.size();\n    mean_vec = vfmul_vf_f64m1(vsetvl_e64m1(1), mean, 1);\n    vfloat64m1_t diff = vfabs_vf_f64m1(vsub_vf_f64m1(vec_numbers, mean_vec, vl), vl);\n    double mad_sum = 0.0;\n    for(int i=0; i<vl; i++) {\n        mad_sum += diff[i];\n    }\n    return mad_sum / numbers.size();\n}\n```"}
{"task_id": "SimdBench_64_RVV", "completion": "```c\ndouble mean_absolute_deviation_simd(std::vector<double> numbers){\n    size_t n = numbers.size();\n    size_t vl = vsetvl_e64m1(n);\n    vfloat64m1_t vec_numbers = vle64_v_f64m1(numbers.data(), vl);\n    vfloat64m1_t mean_vec = vfmul_vf_f64m1(vec_numbers, 0.0, vl); // Initialize with zero\n    mean_vec = vredsum_vs_f64m1_f64m1(mean_vec, vec_numbers, vl);\n    double mean = mean_vec[0] / n;\n\n    vfloat64m1_t mean_vec_broadcast = vfmv_f_s_f64m1_f64(mean, vl);\n    vfloat64m1_t diff = vsub_vf_f64m1(vec_numbers, mean_vec_broadcast, vl);\n    vfloat64m1_t abs_diff = vfabs_vf_f64m1(diff, vl);\n    vfloat64m1_t mad_sum = vredsum_vs_f64m1_f64m1(mean_vec, abs_diff, vl);\n    return mad_sum[0] / n;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    const size_t n = numbers.size();\n    if(n == 0) return {};\n\n    size_t max_len = n * 2 -1;\n    std::vector<int> result(max_len);\n    size_t vl = vsetvl_e32m1(max_len);\n\n    vint32m1_t vec_delim = vlev_int32m1(&delimeter, 1);\n    vint32m1_t vec_numbers = vle32_v_i32m1(numbers.data(), vl);\n    \n    for(size_t i=0; i<n-1; ++i){\n        size_t offset = i*2;\n        vst32_v_i32m1(result.data()+offset, vec_numbers, vl);\n        vst32_v_i32m1(result.data()+offset+1, vec_delim, vl);\n    }\n    if(n >0){\n        vst32_v_i32m1(result.data()+(n-1)*2, vec_numbers, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    const size_t n = numbers.size();\n    if(n == 0) return {};\n\n    size_t max_len = n * 2 -1;\n    std::vector<int> result(max_len);\n    size_t vl = vsetvl_e32m1(max_len);\n\n    vint32m1_t vec_delim = vlev_int32m1(&delimeter, 1);\n    \n    size_t i = 0;\n    for(i = 0; i < n-1; i++){\n        vint32m1_t vec_num = vlev_int32m1(numbers.data() + i, 1);\n        vsev_int32m1(result.data() + 2*i, vec_num, 1);\n        vsev_int32m1(result.data() + 2*i +1, vec_delim, 1);\n    }\n    // Handle the last element\n    vint32m1_t vec_last = vlev_int32m1(numbers.data() + i, 1);\n    vsev_int32m1(result.data() + 2*i, vec_last, 1);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    const size_t n = numbers.size();\n    if(n == 0) return {};\n\n    size_t max_len = n * 2 -1;\n    std::vector<int> result(max_len);\n    size_t vl = vsetvl_e32m1(max_len);\n\n    vint32m1_t vec_delim = vlev_int32m1(&delimeter, 1);\n    vint32m1_t vec_numbers = vle32_v_i32m1(numbers.data(), vl);\n    \n    for(size_t i=0; i<n-1; ++i){\n        size_t offset = i*2;\n        vst32_v_i32m1(result.data()+offset, vec_numbers, vl);\n        vst32_v_i32m1(result.data()+offset+1, vec_delim, vl);\n    }\n    if(n >0){\n        vst32_v_i32m1(result.data()+(n-1)*2, vec_numbers, vl);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    const size_t n = numbers.size();\n    if(n == 0) return {};\n\n    size_t max_len = n * 2 -1;\n    std::vector<int> result(max_len);\n    size_t vl = vsetvl_e32m1(max_len);\n\n    vint32m1_t vec_delim = vlev_int32m1(&delimeter, 1);\n    vint32m1_t vec_numbers = vle32_v_i32m1(numbers.data(), vl);\n    \n    vint32m1_t interleaved;\n    for(int i=0; i<n-1; ++i){\n        vint32m1_t temp = vmsli_vv_i32m1(vec_numbers, vec_delim, i*2+1);\n        if(i ==0){\n            interleaved = temp;\n        }\n        else{\n            interleaved = vor_vv_i32m1(interleaved, temp, vl);\n        }\n    }\n    vse32_v_i32m1(result.data(), interleaved, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_65_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> intersperse_simd(std::vector<int> numbers, int delimeter){\n    const size_t n = numbers.size();\n    if(n == 0) return {};\n\n    size_t max_len = n * 2 -1;\n    std::vector<int> result(max_len);\n    size_t vl = vsetvl_e32m1(max_len);\n\n    vint32m1_t vec_delim = vle32_v_i32m1(&delimeter, 1);\n    vint32m1_t vec_numbers = vle32_v_i32m1(numbers.data(), n);\n    \n    for(size_t i=0; i<n-1; ++i){\n        size_t idx = i*2;\n        vint32m1_t temp = v\u52d2\u5f97\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    size_t len = numbers.size();\n    size_t vl = vsetvl_e16m1(len);\n    int16_t sum_vec[vl];\n    int16_t product_vec[vl];\n    \n    for(int i=0; i<vl; i++) {\n        sum_vec[i] = 0;\n        product_vec[i] = 1;\n    }\n    \n    for(size_t i=0; i<len; i+=vl) {\n        vint16m1_t vec = vle16_v_i16m1(numbers.data()+i, vl);\n        vint16m1_t sum_mask = vsub_vx_i16m1(vec, 0);\n        vint16m1_t prod_mask = vmul_vx_i16m1(vec, 1);\n        \n        sum_vec = vadd_vv_i16m1(sum_vec, sum_mask, vl);\n        product_vec = vmul_vv_i16m1(product_vec, prod_mask, vl);\n    }\n    \n    int64_t sum = 0;\n    int64_t product = 1;\n    for(int i=0; i<vl; i++) {\n        sum += sum_vec[i];\n        product *= product_vec[i];\n    }\n    \n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    size_t len = numbers.size();\n    size_t vl = vsetvl_e16m1(len);\n    int16_t sum_seg[vl] __attribute__((aligned(64))) = {0};\n    int16_t product_seg[vl] __attribute__((aligned(64))) = {1};\n    vint16m1_t sum_vec = vload_v_i16m1(sum_seg, vl);\n    vint16m1_t product_vec = vload_v_i16m1(product_seg, vl);\n\n    for(size_t i = 0; i < len; i += vl){\n        size_t chunk_len = std::min(vl, len - i);\n        vint16m1_t data = vle16_v_i16m1(numbers.data() + i, chunk_len);\n        sum_vec = vadd_vv_i16m1(sum_vec, data, chunk_len);\n        product_vec = vmul_vv_i16m1(product_vec, data, chunk_len);\n    }\n\n    int64_t sum = vsum_v_i16m1(sum_vec, vl);\n    int64_t product = vproduct_v_i16m1(product_vec, vl);\n\n    return {sum, product};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    const size_t vl = vsetvl_e16m1(numbers.size());\n    const int16_t *nums = numbers.data();\n    vint16m1_t vec_nums = vloxei16(nums, 0, vl);\n    \n    vint16m1_t sum_vec = vsub_vx(vec_nums, 0, vl);\n    vint16m1_t prod_vec = vmul_vx(vec_nums, 1, vl);\n    \n    int64_t sum = 0;\n    int64_t prod = 1;\n    \n    for(size_t i=0; i<vl; i++){\n        sum += static_cast<int64_t>(vget_v_i16m1(sum_vec, i));\n        prod *= static_cast<int64_t>(vget_v_i16m1(prod_vec, i));\n    }\n    \n    return {sum, prod};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    const int vl = vsetvl_e16m1(numbers.size());\n    const int16_t *src = numbers.data();\n    vint16m1_t vec = vle16_v_i16m1(src, vl);\n    \n    vint16m1_t sum_vec = vsub_vx_i16m1(vec, 0, vl);\n    vint16m1_t prod_vec = vmul_vx_i16m1(vec, 1, vl);\n    \n    int64_t sum = vsum_v_i16m1(sum_vec, vl);\n    int64_t prod = vprod_v_i16m1(prod_vec, vl);\n    \n    return {sum, prod};\n}\n```"}
{"task_id": "SimdBench_66_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int64_t> sum_product_simd(std::vector<int16_t> numbers){\n    const int vl = vsetvl_e16m1(numbers.size());\n    const int16_t *nums = numbers.data();\n    vint16m1_t vec_nums = vloade_v_i16m1(nums, vl);\n    \n    vint16m1_t sum_vec = vsub_vx_i16m1(vec_nums, 0, vl);\n    vint16m1_t prod_vec = vmul_vx_i16m1(vec_nums, 1, vl);\n    \n    int64_t sum = 0;\n    int64_t prod = 1;\n    \n    for(int i=0; i<vl; i++){\n        sum += vget_v_i16m1(sum_vec, i);\n        prod *= vget_v_i16m1(prod_vec, i);\n    }\n    \n    return {sum, prod};\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    const size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<int> result(numbers.size(), 0);\n    std::vector<int> temp(vl, 0);\n\n    for(size_t i = 0; i < numbers.size(); i += vl){\n        size_t chunk_size = std::min(vl, numbers.size() - i);\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], chunk_size);\n        vint32m1_t vec_temp = vle32_v_i32m1(temp.data(), chunk_size);\n\n        vint32m1_t vec_max = vmax_vx_i32m1(vec_numbers, vec_temp, chunk_size);\n        vse32_v_i32m1(&temp[0], vec_max, chunk_size);\n\n        vse32_v_i32m1(&result[i], vec_max, chunk_size);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    const size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<int> result(numbers.size(), 0);\n    std::vector<int> temp(vl, 0);\n\n    for(size_t i = 0; i < numbers.size(); i += vl){\n        size_t chunk_size = std::min(vl, numbers.size() - i);\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], chunk_size);\n        vint32m1_t vec_temp = vle32_v_i32m1(temp.data(), chunk_size);\n\n        vint32m1_t vec_max = vmax_vx_i32m1(vec_numbers, vec_temp, chunk_size);\n        vse32_v_i32m1(&temp[0], vec_max, chunk_size);\n\n        vse32_v_i32m1(&result[i], vec_max, chunk_size);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    const size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<int> result(numbers.size(), 0);\n    std::vector<int> current_max(numbers.size(), 0);\n\n    for(size_t i = 0; i < numbers.size(); i += vl){\n        const size_t chunk_size = (i + vl <= numbers.size()) ? vl : numbers.size() - i;\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], vl);\n        vint32m1_t vec_current_max = vle32_v_i32m1(&current_max[i], vl);\n        vint32m1_t vec_result = vmax_vv_i32m1(vec_current_max, vec_numbers, vl);\n        vse32_v_i32m1(&result[i], vec_result, vl);\n        vse32_v_i32m1(&current_max[i], vec_result, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    const size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<int> result(numbers.size(), 0);\n    std::vector<int> temp(vl, 0);\n\n    for(size_t i = 0; i < numbers.size(); i += vl){\n        size_t chunk_size = (i + vl <= numbers.size()) ? vl : numbers.size() - i;\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], vl);\n        vint32m1_t vec_temp = vle32_v_i32m1(temp.data(), vl);\n\n        // Compute max element in the current chunk\n        vint32m1_t vec_max = venelement_v_i32m1(vec_numbers, 0);\n        for(int j = 1; j < chunk_size; j++){\n            vint32m1_t current = venelement_v_i32m1(vec_numbers, j);\n            vint32m1_t max_j = vmax_v_i32m1(vec_max, current);\n            vec_max = max_j;\n        }\n\n        // Update temp with max value\n        for(int j = 0; j < chunk_size; j++){\n            venelement_v_i32m1(&vec_temp, j, vec_max);\n        }\n\n        // Store results back to result vector\n        vse32_v_i32m1(&result[i], vec_temp, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_67_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> rolling_max_simd(std::vector<int> numbers){\n    const size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<int> result(numbers.size(), 0);\n    std::vector<int> temp(vl, 0);\n\n    for(size_t i = 0; i < numbers.size(); i += vl){\n        size_t chunk_size = std::min(vl, numbers.size() - i);\n        vint32m1_t vec_numbers = vle32_v_i32m1(&numbers[i], chunk_size);\n        vint32m1_t vec_temp = vle32_v_i32m1(temp.data(), chunk_size);\n\n        vec_temp = vmax_vx_i32m1(vec_temp, 0); // Initialize with 0\n        vec_temp = vmax_vv_i32m1(vec_temp, vec_numbers);\n\n        vse32_v_i32m1(&temp[0], vec_temp, chunk_size);\n        for(size_t j = 0; j < chunk_size; j++){\n            result[i + j] = temp[j];\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    const char* in1 = a.c_str();\n    const char* in2 = b.c_str();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t src1[vl];\n    uint8_t src2[vl];\n    uint8_t dst[vl];\n\n    // Load input data into vectors\n    for (size_t i = 0; i < vl; i++) {\n        src1[i] = in1[i];\n        src2[i] = in2[i];\n    }\n\n    // Perform XOR operation\n    vuint8m1_t vec_src1 = vle8_v_u8m1(src1, vl);\n    vuint8m1_t vec_src2 = vle8_v_u8m1(src2, vl);\n    vuint8m1_t vec_dst = vor_vv_u8m1(vec_src1, vec_src2, vl);\n\n    // Store the result back to memory\n    vse8_v_u8m1(dst, vec_dst, vl);\n\n    // Convert result back to string\n    std::string result;\n    result.resize(len);\n    for (size_t i = 0; i < len; i++) {\n        result[i] = (dst[i] == 0) ? '0' : '1';\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cstring>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* a_data = reinterpret_cast<uint8_t*>(const_cast<char*>(a.c_str()));\n    uint8_t* b_data = reinterpret_cast<uint8_t*>(const_cast<char*>(b.c_str()));\n    uint8_t res[64] __attribute__((aligned(64)));\n\n    vuint8m1_t va, vb, vr;\n    va = vle8_v_u8m1(a_data, vl);\n    vb = vle8_v_u8m1(b_data, vl);\n    vr = vor_vx_u8m1(vxor_vv_u8m1(va, vb, vl), 0, vl);\n\n    vsse8_v_u8m1(res, 1, vr, vl);\n    return std::string(reinterpret_cast<char*>(res), len);\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cstring>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    uint8_t* a_data = (uint8_t*)a.c_str();\n    uint8_t* b_data = (uint8_t*)b.c_str();\n    uint8_t result[len];\n\n    size_t vl = vsetvl_e8m1(len);\n    vuint8m1_t vec_a, vec_b, vec_result;\n\n    for (size_t i = 0; i < len; i += vl) {\n        vl = vsetvl_e8m1(len - i);\n        vec_a = vle8_v_u8m1(a_data + i, vl);\n        vec_b = vle8_v_u8m1(b_data + i, vl);\n        vec_result = vor_vv_u8m1(vec_a, vec_b, vl);\n        vse8_v_u8m1(result + i, vec_result, vl);\n    }\n\n    return std::string((char*)result, len);\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cstring>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* a_data = reinterpret_cast<uint8_t*>(const_cast<char*>(a.c_str()));\n    uint8_t* b_data = reinterpret_cast<uint8_t*>(const_cast<char*>(b.c_str()));\n    uint8_t res[64] __attribute__((aligned(64)));\n\n    vuint8m1_t va, vb, vr;\n    va = vle8_v_u8m1(a_data, vl);\n    vb = vle8_v_u8m1(b_data, vl);\n    vr = vor_vx_u8m1(vxor_vv_u8m1(va, vb, vl), 0, vl);\n    vse8_v_u8m1(res, vr, vl);\n\n    return std::string(reinterpret_cast<char*>(res), len);\n}\n```"}
{"task_id": "SimdBench_68_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n#include <cstring>\n\nstd::string string_xor_simd(std::string a, std::string b) {\n    size_t len = a.size();\n    uint8_t* a_data = (uint8_t*)a.data();\n    uint8_t* b_data = (uint8_t*)b.data();\n    uint8_t result[len];\n    \n    size_t vl = vsetvl_e8m1(len);\n    vuint8m1_t vec_a, vec_b, vec_result;\n    \n    for (size_t i = 0; i < len; i += vl) {\n        vl = vsetvl_e8m1(len - i);\n        vec_a = vle8_v_u8m1(a_data + i, vl);\n        vec_b = vle8_v_u8m1(b_data + i, vl);\n        vec_result = vor_b(vec_a, vec_b);\n        vse8_v_u8m1(result + i, vec_result, vl);\n    }\n    \n    return std::string((char*)result, len);\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) return \"\";\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    size_t n = strings.size();\n    size_t vl = vsetvl_e8m1(n);\n\n    for(size_t i=0; i<n; i+=vl){\n        size_t l = (vl <= n-i) ? vl : n-i;\n        vuint8m1_t idx = vsub_vx_u8m1(vseqm1_u8m1(l), i);\n        vint8m1_t chars = vlsseg8_v_u8m1((const unsigned char**)&strings[i], l);\n        vbool16m2_t mask = vmsne_vx_u8m1(chars, 0, l);\n\n        size_t len = vpopc_m_b16m2(mask);\n        if(len > max_len){\n            max_len = len;\n            max_idx = i;\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"\";\n\n    const size_t len = strings.size();\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    size_t vl = vsetvl_e8m1(len);\n    __rvv_char_t indices = vsub_vx_u8(vl, 0);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t chunk_size = std::min(vl, len - i);\n        __rvv_char_t lens = vle8_v_u8(chunk_size);\n        for(size_t j=0; j<chunk_size; j++){\n            lens[j] = strings[i+j].length();\n        }\n        __rvv_uint8m1_t greater = vmgtu_vx_u8(lens, max_len, chunk_size);\n        __rvv_uint8m1_t update_max = vor_vx_u8(greater, vmsltu_vx_u8(lens, max_len, chunk_size), chunk_size);\n        max_len = vmerge_vx_u8(max_len, lens, update_max, chunk_size);\n        __rvv_uint8m1_t new_indices = vor_vx_u8(vsub_vx_u8(indices, i), vsub_vx_u8(indices, i), chunk_size);\n        __rvv_uint8m1_t update_idx = vmseq_vx_u8(new_indices, vlsge_vx_u8(lens, max_len, chunk_size), chunk_size);\n        max_idx = vmerge_vx_u8(max_idx, new_indices, update_idx, chunk_size);\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) {\n        return \"\";\n    }\n    const int vl = vsetvl_e8m1(strings.size());\n    const char* data[vl];\n    for(int i=0; i<vl; i++) {\n        data[i] = strings[i].data();\n    }\n    vint8m1_t indices = vseq_w_b(vl);\n    vbool16m1_t mask = vmsne_vx_b16m1(indices, 0, vl);\n    vint8m1_t max_len = vle8_v_i8m1(data, vl);\n    int8xm1_t max_idx = vsub_vx_i8xm1(indices, 0, vl);\n    for(int i=1; i<strings.size(); i+=vl){\n        vint8m1_t current_len = vseq_w_b(vl);\n        for(int j=0; j<vl; j++) {\n            current_len[j] = strings[i+j].size();\n        }\n        vbool16m1_t new_mask = vmslt_vx_b16m1(current_len, max_len, vl);\n        max_len = vmseq_vx_i8m1(vmseq_vx_i8m1(max_len, current_len, vl), current_len, vl);\n        max_idx = vmerge_vx_i8xm1(max_idx, vsub_vx_i8xm1(indices, i, vl), new_mask);\n    }\n    return strings[vse32_v_i32m1(max_idx)];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if(strings.empty()) return \"\";\n\n    const size_t len = strings.size();\n    size_t max_len = 0;\n    size_t max_idx = 0;\n\n    size_t vl = vsetvl_e8m1(len);\n    __rvv_char_t indices = vsub_vx_u8(vl, 0);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t chunk_size = std::min(vl, len - i);\n        __rvv_char_t lens = vsub_vx_u8(chunk_size, 0);\n        __rvv_char_t chars = vle8_v_i8u8(strings[i].data(), vl);\n        \n        // Compute lengths in parallel\n        __rvv_char_t lens_cmp = vseq_vx_u8(chars, 0);\n        lens_cmp = vmseq_vx_u8(lens_cmp, 0, vl);\n\n        // Find max length\n        __rvv_char_t max_mask = vmseq_vx_u8(vmax_vx_u8(lens_cmp, max_len, vl), max_len, vl);\n        if(vmsum_vs_u8_u8(max_mask, indices, vl)){\n            max_len = vmax_vx_u8(lens_cmp, max_len, vl);\n            max_idx = vadd_vx_u8(indices, i, vl);\n        }\n    }\n\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_69_RVV", "completion": "```cpp\nstd::string longest_simd(const std::vector<std::string> & strings){\n    if (strings.empty()) return \"\";\n\n    size_t max_len = 0;\n    size_t max_idx = 0;\n    size_t idx = 0;\n\n    const size_t vl = vsetvl_e8m1(strings.size());\n    uint8_t lens[vl];\n    for(size_t i=0; i<strings.size(); i+=vl){\n        size_t chunk_size = std::min(vl, strings.size() - i);\n        for(size_t j=0; j<chunk_size; j++){\n            lens[j] = strings[i+j].length();\n        }\n        vuint8m1_t lens_vec = vload_v_u8m1(lens, vl);\n        vuint8m1_t cmp_mask = vmseq_v_u8m1(lens_vec, vle8_v_u8m1(&max_len, vl));\n        vse32_v_i32(&max_idx, vmseq_v_i32(vredmax_vs_u32(vumax_v_u32(lens_vec, vle32_v_i32(&max_len, vl)), vle32_v_i32(&max_len, vl)), vli32(1), vl), vl);\n        max_len = vredmax_vs_u32(vumax_v_u32(lens_vec, vle32_v_i32(&max_len, vl)), vle32_v_i32(&max_len, vl), vl);\n    }\n    return strings[max_idx];\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    vui64m1_t va = {a};\n    vui64m1_t vb = {b};\n    vui64m1_t temp;\n    while (vb[0] != 0) {\n        temp = va % vb;\n        va = vb;\n        vb = temp;\n    }\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    vui64m1_t vec_a, vec_b, vec_r;\n    vbool16_t mask;\n    uint64_t result = 0;\n\n    // Initialize vectors with input values\n    vec_a = (vui64m1_t){a};\n    vec_b = (vui64m1_t){b};\n\n    while (vec_any_lt(vec_b, vec_a)) {\n        vec_r = vfsub_vx(vec_a, vec_b, LMUL_1);\n        mask = vmsltu_vx(vec_b, vec_a, LMUL_1);\n        vec_a = vmsif_b(mask, vec_r, vec_a, LMUL_1);\n        vec_b = vmsif_b(mask, vec_b, vfsub_vx(vec_b, vec_r, LMUL_1), LMUL_1);\n    }\n\n    result = vfirst_u(vec_a);\n    return result;\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    vui64m1_t va = {a};\n    vui64m1_t vb = {b};\n    vbool16_t mask;\n    vui64m1_t temp;\n\n    while (vb[0] != 0) {\n        temp = va % vb;\n        va = vb;\n        vb = temp;\n    }\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    return __rv_vgcd(a, b);\n}\n```"}
{"task_id": "SimdBench_70_RVV", "completion": "```c\nuint64_t greatest_common_divisor_simd(uint64_t a, uint64_t b){\n    vui64m1_t va = {a};\n    vui64m1_t vb = {b};\n    vbool16m1_t mask;\n    vui64m1_t temp;\n\n    while (vb[0] != 0) {\n        temp = va % vb;\n        va = vb;\n        vb = temp;\n    }\n    return va[0];\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    vfloat32m1_t vec_numbers = vfmv_s_f_v_f32m1(numbers.data(), vl);\n    \n    vfloat32m1_t min_diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, 1, vl), vl);\n    vint32m1_t min_indices = vcreate_int32m1(0);\n    \n    for(int i=1; i<numbers.size(); i++){\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, i, vl), vl);\n        vint32m1_t mask = vfredmin_vs_f32m1_i32m1(min_diff, diff, vl);\n        min_diff = vselect_bf32m1(mask, diff, min_diff, vl);\n        min_indices = vselect_bf32m1(mask, vcreate_int32m1(i), min_indices, vl);\n    }\n    \n    int idx = vpopc_b32m1(vmsne_vx_i32m1(min_indices, 0, vl));\n    float first = numbers[idx];\n    float second = numbers[idx + 1];\n    if(first > second){\n        std::swap(first, second);\n    }\n    return {first, second};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    vfloat32m1_t vec_numbers = vfmv_s_f_v_f32m1(numbers.data(), vl);\n    \n    vfloat32m1_t min_diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, 1, vl), vl);\n    size_t min_idx = 0;\n    \n    for(size_t i = 1; i < numbers.size() - 1; i++){\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, i + 1, vl), vl);\n        vint32m1_t mask = vmseq_vf_f32m1(diff, min_diff, vl);\n        min_diff = vsubff_vv_f32m1(min_diff, diff, mask, vl);\n        min_idx = vmselect_vim(mask, i, min_idx);\n    }\n    \n    float num1 = numbers[min_idx];\n    float num2 = numbers[min_idx + 1];\n    return {std::min(num1, num2), std::max(num1, num2)};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    vfloat32m1_t vec_numbers = vfmv_s_f_v_f32m1(numbers.data(), vl);\n    \n    vfloat32m1_t min_diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, 1, vl), vl);\n    vint32m1_t min_indices = vcreate_int32m1(0);\n    \n    for(int i=1; i<numbers.size(); i++){\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, i, vl), vl);\n        vint32m1_t mask = vfredmin_vs_f32m1_i32m1(min_diff, diff, vl);\n        min_diff = vsub_mask_f32m1(min_diff, diff, mask);\n        min_indices = vmerge_mask_i32m1(min_indices, vlsr_w_i32m1(vlconst_i32m1(i), 1), mask);\n    }\n    \n    int index1 = vget_v_i32m1(min_indices, 0);\n    int index2 = index1 + 1;\n    return {numbers[index1], numbers[index2]};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    vfloat32m1_t vec_numbers = vfmv_s_f_v_f32m1(numbers.data(), vl);\n    \n    vfloat32m1_t min_diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, 1, vl), vl);\n    vint32m1_t min_indices = vcreate_int32m1(0);\n    \n    for(int i=1; i<numbers.size(); i++){\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, i, vl), vl);\n        vint32m1_t mask = vfredmin_vs_f32m1_i32m1(min_diff, diff, min_indices, vl);\n        min_diff = vsub_mask_f32m1(min_diff, diff, mask);\n        min_indices = vselect_mask_i32m1(min_indices, vadd_mask_i32m1(vlmanip_i32m1(vlnewi(i), vl), min_indices, mask), mask);\n    }\n    \n    int idx = vle32_v_i32(min_indices);\n    return {numbers[idx], numbers[idx+1]};\n}\n```"}
{"task_id": "SimdBench_71_RVV", "completion": "```cpp\nstd::vector<float> find_closest_elements_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    vfloat32m1_t vec_numbers = vfmv_s_f_v_f32m1(numbers.data(), vl);\n    \n    vfloat32m1_t min_diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, 1, vl), vl);\n    vint32m1_t min_indices = vcreate_int32m1(0);\n    \n    for(int i=1; i<numbers.size(); i++){\n        vfloat32m1_t diff = vfsub_vv_f32m1(vec_numbers, vslideup_vx_f32m1(vec_numbers, i, vl), vl);\n        vint32m1_t mask = vfredmin_vs_f32m1_i32m1(min_diff, diff, vl);\n        min_diff = vmerge_vv_f32m1(min_diff, diff, mask);\n        min_indices = vmerge_vv_i32m1(min_indices, vlseg16_v_i32m1(vle16_v_i32m1((const int16_t*)&i, vl)), mask);\n    }\n    \n    int index1 = vget_v_i32m1(min_indices, 0);\n    int index2 = (index1 + 1) % numbers.size();\n    \n    float num1 = numbers[index1];\n    float num2 = numbers[index2];\n    \n    if(num1 > num2){\n        std::swap(num1, num2);\n    }\n    \n    return {num1, num2};\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<float> minmax(2, std::numeric_limits<float>::max());\n    \n    // Find min and max in parallel\n    for(int i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t vmin = vfmin_vf_f32m1(vec, minmax[0], vl);\n        minmax[0] = vfmin_vf_f32m1(vmin, minmax[0], 1)[0];\n        vfloat32m1_t vmax = vfmax_vf_f32m1(vec, minmax[1], vl);\n        minmax[1] = vfmax_vf_f32m1(vmax, minmax[1], 1)[0];\n    }\n    \n    float min_val = minmax[0];\n    float max_val = minmax[1];\n    if(min_val == max_val){\n        return std::vector<float>(numbers.size(), 0.0f);\n    }\n    \n    std::vector<float> result(numbers.size());\n    for(int i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t scaled = vfsub_vf_f32m1(vec, min_val, vl);\n        scaled = vfdiv_vf_f32m1(scaled, max_val - min_val, vl);\n        vse32_v_f32m1(result.data()+i, scaled, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<float> minmax(2, std::numeric_limits<float>::max());\n    \n    // Find min and max in parallel\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t vmin = vreduce_min_vf_f32m1(vec, std::numeric_limits<float>::max(), vl);\n        vfloat32m1_t vmax = vreduce_max_vf_f32m1(vec, -std::numeric_limits<float>::max(), vl);\n        float local_min = vfmin_vf_f32(vmin, vmin);\n        float local_max = vfmax_vf_f32(vmax, vmax);\n        if(local_min < minmax[0]) minmax[0] = local_min;\n        if(local_max > minmax[1]) minmax[1] = local_max;\n    }\n    \n    float global_min = minmax[0];\n    float global_max = minmax[1];\n    \n    std::vector<float> result(numbers.size());\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t scaled = vsub_vf_f32(vec, global_min);\n        vfloat32m1_t range = vsub_vf_f32(global_max, global_min);\n        vfloat32m1_t normalized = vdiv_vf_f32(scaled, range);\n        vse32_v_f32m1(result.data()+i, normalized, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    float range = max_val - min_val;\n    \n    vfloat32m1_t vec_in, vec_out;\n    float32m1_t min_vec = vfmv_s_f_f32m1(min_val, vl);\n    float32m1_t range_vec = vfmv_s_f_f32m1(range, vl);\n\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vec_in = vle32_v_f32m1(&numbers[i], vl);\n        vec_out = vfsub_vf_f32m1(vec_in, min_vec, vl);\n        vec_out = vfdiv_vf_f32m1(vec_out, range_vec, vl);\n        vse32_v_f32m1(&numbers[i], vec_out, vl);\n    }\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    float min_val = *std::min_element(numbers.begin(), numbers.end());\n    float max_val = *std::max_element(numbers.begin(), numbers.end());\n    float range = max_val - min_val;\n    \n    vfloat32m1_t vec_in, vec_out;\n    float32m1_t min_vec = vfmv_s_f_f32m1(min_val, vl);\n    float32m1_t range_vec = vfmv_s_f_f32m1(range, vl);\n\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vec_in = vle32_v_f32m1(&numbers[i], vl);\n        vec_out = vfsub_vf_f32m1(vec_in, min_vec, vl);\n        vec_out = vfredusum_vs_f32m1_f32m1(vec_out, range_vec, vl);\n        vse32_v_f32m1(&numbers[i], vec_out, vl);\n    }\n    return numbers;\n}\n```"}
{"task_id": "SimdBench_72_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> rescale_to_unit_simd(std::vector<float> numbers){\n    size_t vl = vsetvl_e32m1(numbers.size());\n    std::vector<float> minmax(2, std::numeric_limits<float>::max());\n    \n    // Find min and max in parallel\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t vmin = vreduce_min_f32(vec);\n        vfloat32m1_t vmax = vreduce_max_f32(vec);\n        float local_min = vfmin_f32(vmin, vmin);\n        float local_max = vfmax_f32(vmax, vmax);\n        if(local_min < minmax[0]) minmax[0] = local_min;\n        if(local_max > minmax[1]) minmax[1] = local_max;\n    }\n    \n    float global_min = minmax[0];\n    float global_max = minmax[1];\n    \n    // Rescale in parallel\n    std::vector<float> rescaled(numbers.size());\n    for(size_t i=0; i<numbers.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(numbers.data()+i, vl);\n        vfloat32m1_t scaled = vsub_vf_f32(vec, global_min);\n        float range = global_max - global_min;\n        if(range != 0.0f){\n            scaled = vdiv_vf_f32(scaled, range);\n        }\n        vse32_v_f32m1(rescaled.data()+i, scaled, vl);\n    }\n    \n    return rescaled;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64_t mask = 1ULL << 63;\n    vbool64 vm = __rvv_vsetvl_e64m1(1);\n    vuint64m1_t v_n = __rvv_vle64_v_u64m1(&n, 1);\n    vuint64m1_t v_result = __rvv_vluxseg64x1_v_u64m1(&n, vm);\n    \n    for(int i=62; i>=1; i--){\n        vbool64 vmask = __rvv_vmsltu_vx_b64(0, i, vm);\n        vuint64m1_t v_divisor = __rvv_vluxseg64x1_v_u64m1(&n, vmask);\n        vresult = __rvv_vsub_vv_u64m1(vresult, v_divisor, vmask);\n        vmask = __rvv_vmand_mm_b64(vmask, __rvv_vbleu_vx_b64(n, v_divisor, vm), vm);\n        vresult = __rvv_vluxseg64x1_v_u64m1(&n, vmask);\n    }\n    \n    return __rvv_vamo_argred_sum_u64m1(vresult, vm);\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64_t mask = 1ULL << 63;\n    uint64_t result = 0;\n    vuint64m1_t vec_n = {n};\n    vbool64_t vmask;\n\n    for(int i=62; i>=1; i--){\n        vmask = vmsltu_vx_u64(vec_n, (uint64_t)1 << i);\n        result = vfirst_u64(vmsle_vx_u64(vec_n, (uint64_t)1 << i, vmask));\n        if(result != 0){\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64_t mask = 1ULL << 63;\n    vuint64m1_t vec_n = vle64_v_u64m1(&n, 1);\n    vint64m1_t result = vsub_vx_i64m1(vec_n, 1, vl);\n    while(vmsltu_vx_u64m1(result, n, vl)){\n        result = vsub_vx_i64m1(result, 1, vl);\n    }\n    return vget_v_i64m1(result, 0);\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64_t mask = 1ULL << 63;\n    vuint64m1_t vec_n = {n};\n    vbool64_t mask_v;\n    vuint64m1_t result = {0};\n\n    for(int i = 62; i >= 0; i--){\n        mask_v = vmsltu_vx_u64(vec_n, (uint64_t)(1ULL << i));\n        result = vmseq_vx_u64(result, (uint64_t)(1ULL << i), mask_v);\n    }\n    return vget_v_u64(result);\n}\n```"}
{"task_id": "SimdBench_73_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t largest_divisor_simd(uint64_t n){\n    uint64_t mask = 1ULL << 63;\n    vuint64m1_t vec_n = {n};\n    vbool64_t vec_mask;\n    vuint64m1_t result = {0};\n\n    for(int i = 62; i >= 0; i--){\n        vec_mask = vmsltu_vx_u64(vec_n, (uint64_t)(1ULL << i));\n        result = vmseq_vx_u64(result, (uint64_t)(1ULL << i), vec_mask);\n    }\n    return vget_v_x_u64(result);\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int max_factor = n / 2 + 1;\n    int8_t mask = 0;\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    vint32m1_t vec_factors = vlev_i32m1(factors.data(), factors.size(), 1);\n    vbool4_t cond;\n\n    for(int i=2; i<=max_factor; ++i){\n        vint32m1_t vec_i = vsetvl_e32m1(1);\n        vint32m1_t vec_i_rep = vrgather_vx_i32m1(vec_i, i, 1);\n        vint32m1_t vec_mod = vrem_vx_i32m1(vec_n, i, 1);\n        cond = vmsltu_vx_u32m1(vec_mod, 0, 1);\n        if(vfirst_b(cond) != -1){\n            do{\n                factors.push_back(i);\n                vec_factors = vse32_v_i32m1(factors.data(), factors.size(), 1);\n            }while(cond);\n        }\n    }\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int max_factor = n / 2 + 1;\n    int8_t mask = 0;\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    vint32m1_t vec_factors = vlev_i32m1(factors.data(), factors.size(), 1);\n    vbool4_t cond;\n\n    for(int i=2; i<=max_factor; ++i){\n        vint32m1_t vec_i = vle32_v_i32m1(&i, 1);\n        cond = vseq_v_i32m1(vec_n, vec_i, 1);\n        if(vfirst_m_u32(mask, cond)){\n            int count = 0;\n            while(vfirst_m_u32(mask, cond)){\n                count++;\n                vec_n = vdiv_vx_i32m1(vec_n, i, 1);\n            }\n            for(int j=0; j<count; ++j){\n                factors.push_back(i);\n            }\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int max_factor = n / 2 + 1;\n    int8_t mask = 0;\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    vint32m1_t vec_factors = vlev_i32m1(factors.data(), factors.size(), 1);\n    vbool4_t cond;\n\n    for(int i=2; i<=max_factor; ++i){\n        vint32m1_t vec_i = vle32_v_i32m1(&i, 1);\n        vint32m1_t remainder = vremu_vx_i32m1(vec_n, vec_i, 1);\n        cond = vmsltu_vx_u32m1(remainder, 0, 1);\n        if(vfirst_m_u32m1(cond) != -1){\n            vse32_v_i32m1(vec_factors, &i, 1);\n            vec_n = vdivu_vx_i32m1(vec_n, vec_i, 1);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\nstd::vector<int> factorize_simd(int n){\n    int vl = vsetvl_e32m1(1);\n    int32xm1_t vec_factors = v\u52d20e32m1;\n    int count = 0;\n    int factor = 2;\n    \n    while(n > 1){\n        int temp_n = n;\n        int valid = 0;\n        while(temp_n % factor == 0){\n            temp_n /= factor;\n            valid += 1;\n        }\n        if(valid > 0){\n            vec_factors = v\u52d20e32m1;\n            for(int i=0; i<valid && i<vl; i++){\n                vec_factors = v\u52d20e32m1;\n            }\n            count += valid;\n        }\n        factor += 1;\n        if(factor * factor > n){\n            if(n > 1){\n                vec_factors = v\u52d20e32m1;\n                count += 1;\n            }\n            break;\n        }\n    }\n    \n    std::vector<int> result(count);\n    for(int i=0; i<count; i++){\n        result[i] = v\u52d20e32m1;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_74_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> factorize_simd(int n){\n    std::vector<int> factors;\n    int max_factor = n / 2 + 1;\n    int8_t mask = 0;\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    vint32m1_t vec_factors = vlev_i32m1(factors.data(), factors.size(), 1);\n    vbool4_t cond;\n\n    for(int i=2; i<=max_factor; ++i){\n        vint32m1_t vec_i = vle32_v_i32m1(&i, 1);\n        vint32m1_t remainder = vremu_vx_i32m1(vec_n, vec_i, 1);\n        cond = vmsltu_vx_u32m1(remainder, 0, 1);\n        if(vfirst_m_u32m1(cond) != -1){\n            vse32_v_i32m1(vec_factors, &i, 1);\n            vec_n = vdivu_vx_i32m1(vec_n, vec_i, 1);\n        }\n    }\n\n    return factors;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vfloat32m1_t vec_in = vfmv_s_f_v_f32m1(l.data(), vl);\n    vbool32m1_t mask = vmflt_vf_f32m1(vec_in, 0.0f, vl);\n    vfloat32m1_t vec_out = vcompress_v_x_f32m1(vec_in, mask, vl);\n    size_t new_len = vpopc_b32m1(mask, vl);\n    std::vector<float> result(new_len);\n    vfmv_f_s_f32m1_f32(result.data(), vec_out, new_len);\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> get_positive_simd(const std::vector<float> &l) {\n    const size_t vl = vsetvl_e32m1(l.size());\n    std::vector<float> result(l.size(), 0.0f);\n    float *res_data = result.data();\n    const float *data = l.data();\n\n    vfloat32m1_t vec_in = vle32_v_f32m1(data, vl);\n    vbool32_t mask = vmgt_vf_f32m1_f32m1(vec_in, 0.0f, vl);\n\n    vfloat32m1_t vec_out = vmslt_vf_f32m1_f32m1(vec_in, 0.0f, mask, vl);\n\n    vse32_v_f32m1(res_data, vec_out, vl);\n\n    // Resize result to actual number of positives\n    size_t num_positives = vpopc_v_b32(mask, vl);\n    result.resize(num_positives);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vfloat32m1_t vec_in = vfromf32m1(l.data(), vl);\n    vbool32m1_t mask = vfredge_m32m1(vseq_m32m1(vle32_v_i32m1((int32_t*)l.data(), vl), 0));\n    vfloat32m1_t vec_out = vcompress_vx_f32m1(vec_in, mask, vl);\n    std::vector<float> result(vlen_v_f32m1(vec_out));\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vfloat32m1_t vec_in = vload_v_f32m1(l.data(), vl);\n    vbool32m1_t mask = vfredge_vs_f32m1_b32m1(vle32_v_i32m1(reinterpret_cast<const int32_t*>(l.data()), vl), vec_in, vl);\n    vfloat32m1_t vec_out = vcompress_v_x_f32m1(vec_in, mask, vl);\n    std::vector<float> result(vse32_v_f32m1(vec_out, vcnt_v_i32m1(mask, vl)));\n    return result;\n}\n```"}
{"task_id": "SimdBench_75_RVV", "completion": "```cpp\nstd::vector<float> get_positive_simd(const std::vector<float> & l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vfloat32m1_t vec_in = vload_v_f32m1(l.data(), vl);\n    vbool32m1_t mask = vfredge_vs_f32m1_b32m1(vle32_v_i32m1(reinterpret_cast<const int32_t*>(l.data()), vl), vec_in, vl);\n    vfloat32m1_t vec_out = vcompress_v_x_f32m1(vec_in, mask, vl);\n    std::vector<float> result(vlenb / sizeof(float));\n    vstore_v_f32m1(result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int vl = vsetvl_e64m1(n);\n    vint64m1_t primes = v\u52d20m1(v\u52d20m1(1), vl);\n    vint64m1_t candidates = v\u52d20m1(5, vl);\n\n    while (candidates[0] * candidates[0] <= n) {\n        primes = v\u52d20m1(primes & (v\u52d20m1(n % candidates, vl) != 0), vl);\n        candidates = v\u52d20m1(candidates + 2, vl);\n    }\n\n    return v\u52d20m1_sum(primes, vl) == vl;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int vl = vsetvl_e64m1(n);\n    vint64m1_t nums = vseq_w_b(vl);\n    vboolm1_t mask = vmsne_vx_b(nums, n, vl);\n\n    vint64m1_t divisors = vsub_vx(nums, 1, vl);\n    divisors = vsub_vx(divisors, 1, vl);\n\n    while (vfirst_m_b(mask, vl) != -1) {\n        vint64m1_t divisor = vle64_v_i64m1((int64_t *)divisors, vl);\n        vint64m1_t remainder = vrem_vx(nums, divisor, vl);\n        vboolm1_t divisible = vmseq_vx_b(remainder, 0, vl);\n\n        if (vany_b(divisible, vl)) {\n            return false;\n        }\n\n        divisors = vsub_vx(divisors, 1, vl);\n        mask = vmsle_vx_b(divisors, 2, vl);\n    }\n\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int vl = vsetvl_e64m1(n);\n    vint64m1_t nums = vseq_w_b(vl);\n    vboolm1_t mask = vmsne_vx_b(nums, n, vl);\n\n    vint64m1_t divisors = vsub_vx(nums, 1, vl);\n    divisors = vsub_vx(divisors, 1, vl);\n\n    while (vfirst_m_b(mask, vl) != -1) {\n        vint64m1_t divisor = vle64_v_i64m1(&divisors, vl);\n        vint64m1_t remainder = vrem_vx(nums, divisor, vl);\n        vboolm1_t divisible = vmseq_vx_b(remainder, 0, vl);\n\n        if (vany_b(divisible, vl)) {\n            return false;\n        }\n\n        divisors = vsub_vx(divisors, 1, vl);\n        mask = vmsne_vx_b(divisors, 0, vl);\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int vl = vsetvl_e64m1(n);\n    vint64m1_t primes = v\u52d2index(1, vl);\n    vint64m1_t candidates = v\u52d2index(n, vl);\n\n    for(int i=5; i*i<=n; i+=6){\n        vint64m1_t factors = v\u52d2index(i, vl);\n        vint64m1_t factors_plus_2 = v\u52d2index(i+2, vl);\n        primes = v\u52d2and(primes, v\u52d2not(v\u52d2or(v\u52d2eq(candidates, v\u52d2mul(factors, factors)), v\u52d2eq(candidates, v\u52d2mul(factors_plus_2, factors_plus_2)))));\n    }\n\n    return v\u52d2any(primes);\n}\n```"}
{"task_id": "SimdBench_76_RVV", "completion": "```c\nbool is_prime_simd(int64_t n){\n    if (n <= 1) return false;\n    if (n <= 3) return true;\n    if (n % 2 == 0 || n % 3 == 0) return false;\n\n    int vl = vsetvl_e64m1(n);\n    vint64m1_t nums = vseq_v_i64m1(vl);\n    vboolm1_t mask = vmsltu_vx_i64m1(nums, n);\n\n    vint64m1_t divisors = vsub_vx_i64m1(nums, 1);\n    divisors = vadd_vx_i64m1(divisors, 2);\n\n    vboolm1_t is_prime_mask = vtrue_m1_b();\n    for(int i=5; i*i<=n; i+=6){\n        vint64m1_t divisor = vle64_v_i64m1(&i, vl);\n        vboolm1_t temp_mask = vmseq_vx_i64m1(divisor, n);\n        is_prime_mask = vmseq_vx_i64m1(divisor, n) ? vand_m1_b(is_prime_mask, temp_mask) :\n                      vmseq_vx_i64m1(divisor+2, n) ? vand_m1_b(is_prime_mask, temp_mask) : is_prime_mask;\n    }\n    bool result = viseq_vx_i64m1(nums, n, vl) & !vmreduce_or_m1_b(is_prime_mask);\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cctype>\n#include <cstring>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.size();\n    size_t vl = vsetvl_e8m1(len);\n\n    // Convert string to vector\n    uint8_t input[len];\n    std::memcpy(input, s.c_str(), len);\n    uint8_t output[len];\n\n    for (size_t i = 0; i < len; i += vl) {\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, this_vl);\n        vboolm1_t mask = vmsne_vx_u8(vec_in, 0, this_vl);\n\n        // Check if any character in this vector is a letter\n        vboolm1_t has_letter = false;\n        for (int j = 0; j < this_vl; j++) {\n            if (isalpha(vec_in[j])) {\n                has_letter = true;\n                break;\n            }\n        }\n\n        if (has_letter) {\n            // Reverse case for letters, keep others unchanged\n            vuint8m1_t vec_out = vreinterpret_u8m1_vbmask(mask);\n            for (int j = 0; j < this_vl; j++) {\n                if (isalpha(vec_in[j])) {\n                    if (islower(vec_in[j])) {\n                        vec_out[j] = toupper(vec_in[j]);\n                    } else {\n                        vec_out[j] = tolower(vec_in[j]);\n                    }\n                }\n            }\n            vse8_v_u8m1(output + i, vec_out, this_vl);\n        } else {\n            // Reverse the entire vector if no letters are present\n            vuint8m1_t reversed = vreverse_v_u8m1(vec_in);\n            vse8_v_u8m1(output + i, reversed, this_vl);\n        }\n    }\n\n    return std::string((char *)output, len);\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cctype>\n#include <cstring>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.size();\n    if (len == 0) return s;\n\n    // Determine the vector length\n    size_t vl = vsetvl_e8m1(len);\n\n    // Convert string to vector\n    uint8_t input[len];\n    std::memcpy(input, s.c_str(), len);\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n\n    // Create mask for letters\n    vbool16_t mask_letters = vmsne_vx_u8m1(vec_input, 0, vl);\n\n    // Check if there's at least one letter\n    bool has_letter = vmsum_vs_u8m1_bool(mask_letters, mask_letters, v\u52d20m1_t(0), vl)[0];\n\n    vuint8m1_t result_vec;\n    if (has_letter) {\n        // Process letters\n        result_vec = vmseq_vx_u8m1(vec_input, 'a', vl); // Compare with 'a'\n        result_vec = vmslt_vx_u8m1(result_vec, 'z' - 'a' + 1, vl); // Check if in range\n        result_vec = vmsub_vx_u8m1(result_vec, 'A', vl); // Convert to uppercase\n\n        vuint8m1_t result_vec_upper = vmseq_vx_u8m1(vec_input, 'A', vl); // Compare with 'A'\n        result_vec_upper = vmslt_vx_u8m1(result_vec_upper, 'Z' - 'A' + 1, vl); // Check if in range\n        result_vec_upper = vadd_vx_u8m1(result_vec_upper, 'a' - 'A', vl); // Convert to lowercase\n\n        result_vec = vor_vv_u8m1(result_vec, result_vec_upper, vl); // Combine results\n    } else {\n        // Reverse the string if no letters\n        result_vec = vreverse_v_u8m1(vec_input, vl);\n    }\n\n    // Copy back to result\n    uint8_t result[len];\n    vse8_v_u8m1(result, result_vec, vl);\n    return std::string((char*)result, len);\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cctype>\n#include <cstring>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.size();\n    size_t vl = vsetvl_e8m1(len);\n\n    // Convert string to vector of unsigned chars\n    uint8_t input[len];\n    std::memcpy(input, s.c_str(), len);\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n\n    // Create mask for letters\n    vbool8_t mask_letters = vmsne_vx_u8m1(vec_input, 0, vl);\n    for (int i = 'A'; i <= 'Z'; i++) {\n        mask_letters = vmseq_vx_b8(mask_letters, vec_input, i, vl);\n    }\n    for (int i = 'a'; i <= 'z'; i++) {\n        mask_letters = vmseq_vx_b8(mask_letters, vec_input, i, vl);\n    }\n\n    // Create mask for non-letters\n    vbool8_t mask_non_letters = vmv_x_b8(vluxei8_mask(0, mask_letters, vl));\n\n    // Reverse case for letters\n    vuint8m1_t vec_output = vec_input;\n    vec_output = vmsltu_vx_u8m1(vec_output, 'Z' + 1, vl); // Lowercase to Uppercase\n    vec_output = vsub_vx_u8m1(vec_output, 'A' - 'a', vl);\n    vec_output = vmsltu_vx_u8m1(vec_output, 'a' - 1, vl); // Uppercase to Lowercase\n    vec_output = vadd_vx_u8m1(vec_output, 'A' - 'a', vl);\n\n    // Keep non-letters unchanged\n    vec_output = vmerge_vx_u8m1(vec_output, vec_input, mask_non_letters, vl);\n\n    // Check if there are no letters\n    bool has_letters = false;\n    for (int i = 'A'; i <= 'Z'; i++) {\n        has_letters |= vlsge_vx_b8(mask_letters, i, vl);\n    }\n    for (int i = 'a'; i <= 'z'; i++) {\n        has_letters |= vlsge_vx_b8(mask_letters, i, vl);\n    }\n\n    // Reverse string if no letters\n    if (!has_letters) {\n        vuint8m1_t reversed_vec = vec_output;\n        for (size_t i = 0; i < vl / 2; i++) {\n            uint8_t temp = vle8_v_u8m1(reversed_vec, i);\n            vse8_v_u8m1(reversed_vec, i, vle8_v_u8m1(reversed_vec, vl - i - 1));\n            vse8_v_u8m1(reversed_vec, vl - i - 1, temp);\n        }\n        vec_output = reversed_vec;\n    }\n\n    // Convert vector back to string\n    uint8_t output[len];\n    vse8_v_u8m1(vec_output, 0, vl);\n    std::string result(reinterpret_cast<char*>(output), len);\n    return result;\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cctype>\n#include <cstring>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.size();\n    if (len == 0) return s;\n\n    // Convert string to vector of chars\n    const char *str = s.c_str();\n    vbool16_t mask;\n    vuint8m1_t vec_len = vle8_v_u8m1((const uint8_t *)(&len), 1);\n    vuint8m1_t vec_str = vle8_v_u8m1((const uint8_t *)str, len);\n\n    // Check if there's at least one alphabetic character\n    vbool16_t mask_alpha = vmsne_vx_u8m1(vec_str, 0, len);\n    uint8_t has_alpha = 0;\n    vse8_v_u8m1(&has_alpha, vmseq_vx_u8m1(mask_alpha, 0, len), 1);\n\n    if (!has_alpha) {\n        // Reverse the string if no alphabetic characters exist\n        vuint8m1_t reversed_vec = vnsra_vx_u8m1(vec_str, vec_len, len);\n        char reversed_str[len];\n        vse8_v_u8m1((uint8_t *)reversed_str, reversed_vec, len);\n        return std::string(reversed_str, len);\n    }\n\n    // Process each character in parallel\n    vbool16_t mask_upper = vmgt_vx_u8m1(vec_str, 'A', len);\n    vbool16_t mask_lower = vmgt_vx_u8m1(vec_str, 'a', len);\n    vbool16_t mask_alpha_check = vor_vv_b16(mask_upper, mask_lower, len);\n\n    vuint8m1_t result_vec = vsub_vx_u8m1(vec_str, 'A', len); // Temporary buffer\n\n    // Convert uppercase to lowercase and vice versa\n    result_vec = vsub_vx_u8m1(result_vec, 'A' - 'a', len);\n    result_vec = vsub_vx_u8m1(result_vec, 'a' - 'A', len);\n\n    // Keep non-alphabetic characters unchanged\n    result_vec = vmerge_vx_u8m1(result_vec, vec_str, vmseq_vx_u8m1(vmsne_vx_u8m1(vec_str, 0, len), 0, len));\n\n    // Convert back to string\n    char result_str[len];\n    vse8_v_u8m1((uint8_t *)result_str, result_vec, len);\n    return std::string(result_str, len);\n}\n```"}
{"task_id": "SimdBench_77_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cctype>\n#include <cstring>\n\nstd::string solve_simd(const std::string &s) {\n    size_t len = s.size();\n    if (len == 0) return s;\n\n    // Determine the number of elements per vector lane\n    const int vl = vsetvl_e8m1(len);\n\n    // Convert string to vector of unsigned chars\n    uint8_t input[len];\n    memcpy(input, s.c_str(), len);\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n\n    // Create a mask for letters\n    vbool8 mask_letters = vmsne_vx_u8m1(vec_input, 0, vl);\n\n    // Check if there's at least one letter\n    bool has_letter = vmsum_vs_b8m1_u8m1(0, mask_letters, vl) > 0;\n\n    // Prepare output buffer\n    uint8_t output[len];\n    vuint8m1_t vec_output = vlev_u8m1(output, vl);\n\n    if (has_letter) {\n        // Process each character in parallel\n        vec_output = vreinterpret_v_u8m1(vmv_x_u64m1(\n            vadc_vx_u64m1(\n                vmseq_vx_u8m1(vec_input, 'a', vl),\n                vmsub_vx_u64m1(vec_input, 'Z', vl),\n                vl\n            )\n        ));\n    } else {\n        // Reverse the string if no letters are present\n        for (int i = 0; i < len / 2; ++i) {\n            std::swap(input[i], input[len - i - 1]);\n        }\n        memcpy(output, input, len);\n    }\n\n    // Convert back to string\n    return std::string(reinterpret_cast<char*>(output), len);\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result = l;\n    vint32m1_t vec_l = vloxei32(l.data(), vl);\n    \n    // Extract elements at indices divisible by 3\n    vint32m1_t vec_indices = vle32_v_i32((const int*)nullptr, vl); // Dummy load\n    for(int i=0; i<vl; i++) {\n        if(i % 3 == 0) {\n            vec_indices[i] = i;\n        }\n    }\n    vint32m1_t vec_selected = vlsseg3e32(vec_l, vec_indices, vl);\n\n    // Sort the selected elements\n    vint32m1_t vec_sorted = vmsnei_v_i32(vec_selected, 0, vl);\n    std::sort((int*)vec_sorted, (int*)vec_sorted + vlen_b / sizeof(int));\n\n    // Place sorted elements back into original vector\n    for(int i=0; i<vl; i++) {\n        if(i % 3 == 0) {\n            vse32_v_i32(&result[i], vec_sorted[i]);\n        }\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result = l;\n    vint32m1_t vec_result = vloxei32(result.data(), vl);\n    \n    // Extract indices divisible by three\n    vboolm1_t mask = vmsne_vx_i32(vec_result, 0, vl);\n    vint32m1_t indices_div_by_three;\n    size_t count = 0;\n    for(int i=0;i<vl;i++) {\n        if(i % 3 == 0) {\n            indices_div_by_three.v[i] = vec_result.v[i];\n            count++;\n        }\n    }\n    \n    // Sort the extracted elements\n    std::vector<int> sorted_indices(count);\n    for(int i=0;i<count;i++) {\n        sorted_indices[i] = indices_div_by_three.v[i];\n    }\n    std::sort(sorted_indices.begin(), sorted_indices.end());\n    \n    // Write back the sorted values\n    for(int i=0;i<count;i++) {\n        vec_result.v[i*3] = sorted_indices[i];\n    }\n    \n    vstxei32(result.data(), vl, vec_result);\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result = l;\n    vint32m1_t vec_result = vloxei32(result.data(), vl);\n    \n    // Extract indices divisible by three\n    vboolm1_t mask = vmsne_vim_bm(vec_result, 0, 3, vl);\n    vint32m1_t vec_indices_div_by_three = vmslt_vim_u(vmseq_vim_b(vec_result, 0, vl), 3, vl);\n    \n    // Gather elements at those indices\n    vint32m1_t vec_elements_div_by_three = vgather_vx_i32(vec_indices_div_by_three, vec_result, vl);\n    \n    // Sort the gathered elements\n    vint32m1_t sorted_elements = vmsort_v_i32(vec_elements_div_by_three, vl);\n    \n    // Scatter the sorted elements back into the original vector\n    vsegei32(sorted_elements, result.data(), vl);\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result = l;\n    vint32m1_t vec_l = vloxei32(l.data(), vl);\n    \n    // Extract elements at indices divisible by 3\n    vint32m1_t vec_indices = vle32_v_i32((int*)vec_l, vl);\n    vint32m1_t vec_mask = vmseq_v_i32(vec_indices, vici32(0), vl);\n    vint32m1_t vec_extracted = vmsne_v_i32(vec_l, vici32(0), vl);\n\n    // Sort the extracted elements\n    int sorted[3];\n    for(int i=0;i<3;i++) sorted[i] = vget_i32(vec_extracted, i);\n    std::sort(sorted, sorted+3);\n\n    // Replace the original elements with sorted ones\n    for(int i=0;i<3;i++) {\n        if(vmseq_v_i32(vec_mask, vici32(i), vl)) {\n            v\u52d2\u5165_i32(vec_l, sorted[i], i);\n        }\n    }\n\n    // Store back to result\n    vse32_v_i32(result.data(), vec_l, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_78_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<int> sort_third_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result = l;\n    vint32m1_t vec_result;\n    vint32m1_t vec_l;\n\n    for(int i=0; i<l.size(); i+=3){\n        if(i+3 <= l.size()){\n            vec_l = vle32_v_i32m1(&l[i]);\n            vint32m1_t sorted = vec_l;\n            vmsort2_vv_i32m1(sorted, sorted, vl);\n            vec_result = vle32_v_i32m1(&result[i]);\n            vec_result = vmseq_vx_i32m1(vec_result, 0, vl); // Clear if not set\n            vec_result = vor_vv_i32m1(vec_result, sorted, vl);\n            vse32_v_i32m1(&result[i], vec_result);\n        }\n        else{\n            // Handle remaining elements less than 3\n            std::vector<int> temp(l.begin()+i, l.end());\n            std::sort(temp.begin(), temp.end());\n            std::copy(temp.begin(), temp.end(), result.begin()+i);\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    float8mf8_t vec = vle32_v_f32m8(l.data(), vl);\n    float8mf8_t max_val = veor_vx_f32m8(vec, 0.0f, vl);\n    for(int i=1; i < l.size(); i*=2){\n        vl = vsetvl_e32m1(l.size()-i);\n        float8mf8_t vec2 = vle32_v_f32m8(l.data()+i, vl);\n        max_val = vmax_vv_f32m8(max_val, vec2, vl);\n    }\n    return vfredmax_vs_f32m8_f32m1(max_val, max_val, vl);\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    float8_m1_t vec = {0};\n    for(size_t i=0; i<l.size(); i+=vl){\n        float8_t temp;\n        vle32_v_f32(&temp, &l[i], vl);\n        if(i == 0){\n            vec = temp;\n        }\n        else{\n            vec = vmax_vv_f32(vec, temp, vl);\n        }\n    }\n    float result;\n    vse32_v_f32(&result, &vec, 1);\n    return result;\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    float8_m1_t vec = {0};\n    for(size_t i=0; i<l.size(); i+=vl){\n        float8_t temp;\n        vle32_v_f32(&temp, &l[i], vl);\n        if(i == 0){\n            vec = temp;\n        }\n        else{\n            vec = vmax_vf_f32(vec, temp, vl);\n        }\n    }\n    return vfmax_f32(vec);\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    float32xm1_t vec = vle32_v_f32m1(l.data(), vl);\n    float32xm1_t max_vec = vrgather_vx_f32m1(vfmul_vx_f32m1(vec, 0.0f, vl), vcreate_mask_f32m1(1, vl));\n    for(int i=1; i < l.size(); i *= 2){\n        vl = vsetvl_e32m1(i);\n        max_vec = vmax_vv_f32m1(max_vec, vrgather_vx_f32m1(vfmul_vx_f32m1(vec, 0.0f, vl), vcreate_mask_f32m1(1, vl)), vl);\n    }\n    return vfredmax_vs_f32m1_f32m1(max_vec, vfmul_vx_f32m1(vec, 0.0f, vl), vl);\n}\n```"}
{"task_id": "SimdBench_79_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nfloat max_element_simd(std::vector<float> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    float32xm1_t vec = vle32_v_f32m1(l.data(), vl);\n    float32xm1_t max_val = vlsge_vf32m1(vec, 0.0f, vl);\n    return vfmax_vf_f32m1(max_val, 0.0f, vl);\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\nint fizz_buzz_simd(int n){\n    int count = 0;\n    vint32m1_t mask = 0;\n    vint8m1_t seven = vmv_x_s_i8m1_t(7, LMUL_F1);\n    vbool4_t zero_flag = false;\n\n    for(int i=0; i<n; i+=16){\n        vint32m1_t nums;\n        if(i+16 <= n){\n            nums = vle32_v_i32m1((int32_t*)&i, LMUL_F1);\n        }\n        else{\n            nums = vle32_v_i32m1((int32_t*)&i, LMUL_F1, n-i);\n            zero_flag = true;\n        }\n\n        vint32m1_t div_11 = vmsle_v_i32m1(nums, vmseq_v_i32m1(vmodi_v_i32m1(nums, 11, LMUL_F1), 0, LMUL_F1), LMUL_F1);\n        vint32m1_t div_13 = vmsle_v_i32m1(nums, vmseq_v_i32m1(vmodi_v_i32m1(nums, 13, LMUL_F1), 0, LMUL_F1), LMUL_F1);\n\n        vbool4_t cond = vor_v_b4(div_11, div_13, LMUL_F1);\n\n        vint8m1_t digits;\n        vint8m1_t sevens;\n        \n        while(!zero_flag){\n            digits = vlsb_v_i8m1(nums, LMUL_F1);\n            sevens = vmseq_v_i8m1(digits, seven, LMUL_F1);\n            count += vpopc_v_i8m1(sevens, LMUL_F1);\n            nums = vslide1r_v_i32m1(nums, 1, LMUL_F1);\n        }\n\n        if(zero_flag){\n            digits = vlsb_v_i8m1(nums, LMUL_F1);\n            sevens = vmseq_v_i8m1(digits, seven, LMUL_F1);\n            count += vpopc_v_i8m1(sevens, LMUL_F1);\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\nint fizz_buzz_simd(int n){\n    int count = 0;\n    vint32m1_t vec_count = vle32_v_i32m1(&count, 1);\n    for(int i=0; i<n; i+=16){\n        vint32m1_t vec_i = vlev_i32m1(i, 1);\n        vbool4_t mask1 = vbge_vx_i32m1(vec_i, 11);\n        vbool4_t mask2 = vbge_vx_i32m1(vec_i, 13);\n        vbool4_t mask3 = vbge_vx_i32m1(vec_i, n);\n        vbool4_t mask = vor vv4_b4(mask1, mask2);\n        mask = vand vv4_b4(mask, vnot vv4_b4(mask3));\n        vint32m1_t vec_div11 = vcompress_i32m1(vseqz_v_i32m1(vmodi_vx_i32m1(vec_i, 11, 1)), mask);\n        vint32m1_t vec_div13 = vcompress_i32m1(vseqz_v_i32m1(vmodi_vx_i32m1(vec_i, 13, 1)), mask);\n        vbool4_t mask7 = vbge_vx_i32m1(vec_div11, 7);\n        vbool4_t mask7_2 = vbge_vx_i32m1(vec_div13, 7);\n        mask7 = vor vv4_b4(mask7, mask7_2);\n        vint32m1_t vec_count_update = vadd_vx_i32m1(vec_count, vpopc_i32m1(mask7));\n        vse32_v_i32m1(&count, vec_count_update, 1);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\nint fizz_buzz_simd(int n){\n    int count = 0;\n    vint32m1_t vec_count = vle32_v_i32m1(&count, 1);\n    for(int i=0; i<n; i+=16){\n        vint32m1_t vec_i = vlev_i32m1(i, 1);\n        vbool4_t mask11 = vbge_v_i32m1(vec_i, vsetvl_e32m1(11));\n        vbool4_t mask13 = vbge_v_i32m1(vec_i, vsetvl_e32m1(13));\n        vint32m1_t vec_mod11 = vremu_v_i32m1(vec_i, vsetvl_e32m1(11));\n        vint32m1_t vec_mod13 = vremu_v_i32m1(vec_i, vsetvl_e32m1(13));\n        vbool4_t cond11 = vmslt_v_i32m1(mask11, vec_mod11, vint32m1_t(0));\n        vbool4_t cond13 = vmslt_v_i32m1(mask13, vec_mod13, vint32m1_t(0));\n        vbool4_t cond = vor_v_i32m1(cond11, cond13);\n        vint32m1_t vec_digits = vlsr_v_i32m1(vec_i, vsetvl_e32m1(1));\n        vbool4_t cond_digit_7 = vmseq_v_i32m1(vec_digits, vint32m1_t(7));\n        vint32m1_t vec_add = vmseq_v_i32m1(cond, cond_digit_7);\n        vec_count = vadd_v_i32m1(vec_count, vec_add);\n    }\n    count = vse32_v_i32m1(&vec_count, 1);\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\nint fizz_buzz_simd(int n){\n    int count = 0;\n    vint32m1_t mask = 0;\n    vint8mf2_t selem = 7;\n    vbool16_t mask7;\n    \n    for(int i=0; i<n; i+=16){\n        vint32m1_t vec_i = vle32_v_i32m1(&i, LMUL_1);\n        vint32m1_t div11 = vmseq_v_i32m1_i32m1(vec_i, vsetvl_e32m1(11), LMUL_1);\n        vint32m1_t div13 = vmseq_v_i32m1_i32m1(vec_i, vsetvl_e32m1(13), LMUL_1);\n        vbool16_t mask_div = vor_v_b16(div11, div13, LMUL_1);\n        \n        vint8mf2_t digits = vcrep_i8mf2(1, LMUL_8);\n        vbool16_t mask_digit7 = vmslt_v_i8mf2_i8mf2(digits, selem, LMUL_8);\n        \n        mask = vmand_mm(mask, mask_div, mask_digit7, LMUL_1);\n        count += vpopc_b16(mask);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_80_RVV", "completion": "```c\nint fizz_buzz_simd(int n){\n    int count = 0;\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    vbool4_t mask = v\u52d20m4_t();\n    for(int i=0; i<n; i+=4){\n        vint32m1_t vec_i = v\u52d232m1_t(i);\n        vint32m1_t divisible_by_11 = vmseq_v_i32m1(vec_i, 11);\n        vint32m1_t divisible_by_13 = vmseq_v_i32m1(vec_i, 13);\n        vbool4_t or_mask = vor_v_b4(divisible_by_11, divisible_by_13);\n        vint32m1_t digits = v\u52d232m1_t((i/10)%10, (i%10));\n        vint32m1_t sevens = vmseq_v_i32m1(digits, 7);\n        vint32m1_t seven_count = vmand_mm(or_mask, sevens);\n        count += vadd_v_i32m1(seven_count);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t length = l.size();\n    size_t vl = vsetvl_e32m1(length);\n    vfloat32m1_t vec_in = vle32_v_f32m1(l.data(), vl);\n    vfloat32m1_t vec_out = vec_in;\n\n    // Extract even indices\n    vfloat32m1_t even_mask = vmslt_vx_u32m1(vget_indices_u32(vl), 0, vl);\n    vfloat32m1_t even_values = vmseq_vx_f32(vec_in, even_mask);\n\n    // Sort even indices\n    vfloat32m1_t sorted_even = even_values;\n    vsort_v_f32m1(&sorted_even, vl);\n\n    // Merge sorted even values back into original vector\n    vec_out = vmerge_vv_f32m1(vec_out, sorted_even, even_mask);\n\n    std::vector<float> result(length);\n    vse32_v_f32m1(result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t length = l.size();\n    size_t vl = vsetvl_e32m1(length);\n    std::vector<float> result(length);\n\n    // Load input vector\n    vfloat32m1_t vec_in = vle32_v_f32m1(l.data(), vl);\n\n    // Separate even and odd indices\n    vfloat32m1_t vec_even = vmsle_uintm1(vseqf_u32(0, vl), vec_in);\n    vfloat32m1_t vec_odd = vmsub_uintm1(vseqf_u32(1, vl), vec_in);\n\n    // Sort even indices\n    vfloat32m1_t vec_even_sorted;\n    {\n        float temp_even[16];\n        vse32_v_f32m1(temp_even, vec_even, vl);\n        std::sort(temp_even, temp_even + vl);\n        vec_even_sorted = vle32_v_f32m1(temp_even, vl);\n    }\n\n    // Merge sorted even and original odd indices\n    result.resize(length);\n    vse32_v_f32m1(result.data(), vec_even_sorted, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t length = l.size();\n    size_t vl = vsetvl_e32m1(length);\n    std::vector<float> result(length);\n\n    // Load input vector\n    vfloat32m1_t vec_in;\n    float* input_ptr = l.data();\n    vec_in = vle32_v_f32m1(input_ptr, vl);\n\n    // Separate even and odd indices\n    vfloat32m1_t vec_even = vmsne_vx_f32m1(vec_in, 0.0f, vl); // Mask for even indices\n    vfloat32m1_t vec_odd = vmsfe_vx_f32m1(vec_in, 0.0f, vl);  // Mask for odd indices\n\n    // Extract even-indexed elements\n    vfloat32m1_t vec_even_elements = vcompress_vx_f32m1(vec_even, vec_in, vl);\n\n    // Sort even-indexed elements\n    float* even_data = (float*)malloc(vlmul * sizeof(float));\n    vse32_v_f32m1(even_data, vec_even_elements, vlsse32(vcompress_vm(vec_even), 0, vl));\n    std::sort(even_data, even_data + vlsse32(vcompress_vm(vec_even), 0, vl));\n    vfloat32m1_t vec_sorted_even = vle32_v_f32m1(even_data, vl);\n\n    // Place sorted even-indexed elements back into result\n    result = vse32_v_f32m1(vec_sorted_even, vl);\n\n    // Copy odd-indexed elements directly\n    result = vmerge_vv_f32m1(result, vec_odd, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t length = l.size();\n    size_t vl = vsetvl_e32m1(length);\n    std::vector<float> result(length);\n\n    // Load input vector\n    vfloat32m1_t vec_in;\n    float* l_data = l.data();\n    vec_in = vle32_v_f32m1(l_data, vl);\n\n    // Separate even and odd indices\n    vfloat32m1_t vec_even, vec_odd;\n    vfloat32m1_t mask_even = vmsne_v_i32m1_id(0, vl, 2); // Mask for even indices\n    vfloat32m1_t mask_odd = vmsne_v_i32m1_id(1, vl, 2);  // Mask for odd indices\n\n    vec_even = vmseq_vf_f32m1(vec_in, 0, mask_even, vl); // Initialize with zeros\n    vec_odd = vmseq_vf_f32m1(vec_in, 0, mask_odd, vl);   // Initialize with zeros\n\n    // Extract even-indexed elements\n    vfloat32m1_t vec_even_elements;\n    vec_even_elements = vmslt_vf_f32m1(vec_in, 0, mask_even, vl);\n\n    // Sort even-indexed elements\n    float* even_data = (float*)malloc(vl * sizeof(float));\n    vse32_v_f32m1(even_data, vec_even_elements, vl);\n    std::sort(even_data, even_data + vl);\n    vec_even_elements = vle32_v_f32m1(even_data, vl);\n\n    // Place sorted even-indexed elements back into result\n    result = vmerge_vv_f32m1(vec_even_elements, vec_in, mask_even, vl);\n\n    // Copy odd-indexed elements directly\n    result = vmerge_vv_f32m1(vec_odd, result, mask_odd, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_81_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <algorithm>\n#include <vector>\n\nstd::vector<float> sort_even_simd(std::vector<float> l){\n    size_t len = l.size();\n    size_t vl = vsetvl_e32m1(len);\n    vfloat32m1_t vec_in = vle32_v_f32m1(l.data(), vl);\n    vfloat32m1_t vec_even;\n    vfloat32m1_t vec_odd;\n\n    // Split into even and odd indices\n    for(int i=0; i<len; i+=2){\n        vse32_v_f32m1(&vec_even, &l[i], 1);\n        vse32_v_f32m1(&vec_odd, &l[i+1], 1);\n    }\n\n    // Sort even indices\n    std::sort(vget_v_f32m1(vec_even), vget_v_f32m1(vec_even) + vget_nlanes_f32m1(vec_even));\n\n    // Merge back\n    for(int i=0; i<len; i+=2){\n        vse32_v_f32m1(&l[i], &vec_even, 1);\n        vse32_v_f32m1(&l[i+1], &vec_odd, 1);\n    }\n    \n    return l;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32m1(l.data(), vl);\n    \n    for(size_t i = 0; i < l.size(); ++i){\n        for(size_t j = i + 1; j < l.size(); ++j){\n            for(size_t k = j + 1; k < l.size(); ++k){\n                if(vfloat32m1_t sum = vfadd_vv_f32m1(vec[i], vec[j], vl);\n                   vfadd_vx_f32m1(sum, vec[k], vl) == 0.0f){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32m1(l.data(), vl);\n    \n    for (size_t i = 0; i < l.size(); ++i) {\n        for (size_t j = i + 1; j < l.size(); ++j) {\n            for (size_t k = j + 1; k < l.size(); ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32m1(l.data(), vl);\n    \n    for(size_t i = 0; i < l.size(); ++i){\n        for(size_t j = i + 1; j < l.size(); ++j){\n            for(size_t k = j + 1; k < l.size(); ++k){\n                if(vmsum_vs_i32m1_i32m1(vec[i], vec[j], vec[k], vl) == 0){\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstdint>\n#include <vector>\n\nbool triples_sum_to_zero_simd(std::vector<int> l) {\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32m1(l.data(), vl);\n    \n    for (size_t i = 0; i < l.size(); ++i) {\n        for (size_t j = i + 1; j < l.size(); ++j) {\n            for (size_t k = j + 1; k < l.size(); ++k) {\n                if (l[i] + l[j] + l[k] == 0) {\n                    return true;\n                }\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_82_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstdint>\n#include <bit>\n\nbool triples_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32m1(l.data(), vl);\n    \n    for(size_t i = 0; i < l.size(); ++i){\n        vint32m1_t other_elements = vmsne_vx_i32m1(vec, l[i], vl);\n        vint32m1_t pairs = vsub_vv_i32m1(other_elements, l[i]);\n        \n        size_t pair_len = vsetvl_e32m1(vl - 1);\n        vint32m1_t pair_vec = vsub_vx_i32m1(pairs, l[i], pair_len);\n        \n        for(size_t j = i + 1; j < l.size(); ++j){\n            vint32m1_t check = vmseq_vx_i32m1(pair_vec, -(l[i] + l[j]), pair_len);\n            if(vmsum_vx_i32m1(check, 1, pair_len) > 0){\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result(l.size());\n    vint32m1_t vec_in = vloxei32((const int32_t*)l.data(), vl);\n    vint32m1_t vec_out = vadd_vx_i32m1(vec_in, 1, vl);\n    vsexei32((int32_t*)result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result(l.size());\n    vint32m1_t vec_in = vloxei32((const int32_t*)l.data(), vl);\n    vint32m1_t vec_out = vadd_vx_i32m1(vec_in, 1, vl);\n    vsexei32((int32_t*)result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    std::vector<int> result(l.size());\n    vint32m1_t vec_in = vloxei32((const int32_t*)l.data(), vl);\n    vint32m1_t vec_out = vadd_vx_i32m1(vec_in, 1, vl);\n    vsexei32((int32_t*)result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec_in = vloxei32((const int32_t*)l.data(), vl);\n    vint32m1_t vec_out = vadd_vx(vec_in, 1, vl);\n    int32_t result[vl];\n    vsexei32(result, vec_out, vl);\n    return std::vector<int>(result, result + vl);\n}\n```"}
{"task_id": "SimdBench_83_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> incr_list_simd(std::vector<int> l){\n    const int vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec_in = vloxei32(l.data(), vl);\n    vint32m1_t vec_out = vadd_vx(vec_in, 1, vl);\n    std::vector<int> result(l.size());\n    vse32x1_v_i32(result.data(), vec_out, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    alignas(64) int data[l.size()];\n    memcpy(data, l.data(), l.size() * sizeof(int));\n    \n    vint32m1_t vec_data = vloxei32(data, 0, vl);\n    vint32m1_t neg_vec_data;\n    \n    for(size_t i = 0; i < l.size(); i += vl){\n        neg_vec_data = vneg_vx(vec_data, vl);\n        vboolm1_t mask = vmseq_vx(vec_data, neg_vec_data, vl);\n        \n        if(vmreduce_or(mask)){\n            return true;\n        }\n        \n        // Load next vector\n        vec_data = vloxei32(data, i + vl, vl);\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    alignas(64) int data[l.size()];\n    memcpy(data, l.data(), l.size() * sizeof(int));\n    vint32m1_t vec = vloxei32(data, 0, vl);\n    for(size_t i=0; i<l.size(); i+=vl){\n        vint32m1_t neg_vec = vneg_vx(vec);\n        vboolm1_t mask = vmseq_vx(vec, neg_vec, vl);\n        if(vmsum_mask_b1(mask)){\n            return true;\n        }\n        if(i+vl < l.size()){\n            vec = vloxei32(data, i+vl, vl);\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    alignas(64) int data[l.size()];\n    memcpy(data, l.data(), l.size() * sizeof(int));\n    \n    vint32m1_t vec_data = vloxei32(data, 0, vl);\n    vint32m1_t neg_vec_data;\n    \n    for(size_t i = 0; i < l.size(); i += vl){\n        neg_vec_data = vneg_vx(vec_data, vl);\n        for(size_t j = 0; j < l.size(); j += vl){\n            vint32m1_t other_vec_data = vloxei32(data, j, vl);\n            vboolm1_t mask = vmseq_vv(vec_data, other_vec_data, vl);\n            if(vmreduce_or(mask)){\n                return true;\n            }\n        }\n        vec_data = vadd_vx(vec_data, 1, vl);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    alignas(64) int data[l.size()];\n    memcpy(data, l.data(), l.size() * sizeof(int));\n    vint32m1_t vec = vloade32(data, vl);\n    vint32m1_t neg_vec;\n    for(size_t i=0; i<l.size(); i+=vl){\n        neg_vec = vneg_vx(vec, vl);\n        vint32m1_t mask = veq_vv(vec, neg_vec, vl);\n        for(int j=0; j<vl; j++){\n            if(vmrg_vx(mask, j)){\n                return true;\n            }\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_84_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool pairs_sum_to_zero_simd(std::vector<int> l){\n    size_t vl = vsetvl_e32m1(l.size());\n    alignas(64) int data[l.size()];\n    memcpy(data, l.data(), l.size() * sizeof(int));\n    vint32m1_t vec = vloade32(data, vl);\n    vint32m1_t neg_vec;\n    for(size_t i = 0; i < l.size(); i += vl){\n        neg_vec = vneg_vx(vec, vl);\n        vint32m1_t mask = vmseq_vx(vec, 0, vl);\n        if(vmsum_mask_m1(mask, vl)){\n            return true;\n        }\n        vec = vsub_vx(vec, 1);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <string.h>\n#include <stdint.h>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    const int vlen = vgetvl();\n    const int max_digits = 64; // Assuming a maximum of 64 digits for simplicity\n    int8_t digits[vlen];\n    uint8_t valid_mask[vlen];\n    \n    // Initialize vectors\n    vuint8m1_t mask = v\u52d20x01);\n    vint8m1_t zero = v\u52d20());\n    \n    // Convert each digit in parallel\n    int pos = 0;\n    do {\n        vint64m1_t vx = v\u52d2x);\n        vint8m1_t vb = v\u52d2base);\n        vint8m1_t rem = vmodu_vx_i8m1(vx, vb);\n        vint8m1_t div = vdivu_vx_i8m1(vx, vb);\n        \n        // Store remainder as digit\n        v\u52d2digits[pos] = rem;\n        \n        // Update position mask\n        valid_mask[pos] = 1;\n        pos += vlen;\n    } while (viseq_vx_i64m1(div, zero) == 0);\n    \n    // Reverse the digits\n    int8_t reversed_digits[max_digits];\n    for (int i = 0; i < max_digits; ++i) {\n        reversed_digits[i] = digits[max_digits - 1 - i];\n    }\n    \n    // Convert digits to string\n    char result_str[max_digits + 1];\n    for (int i = 0; i < max_digits; ++i) {\n        if (valid_mask[i]) {\n            result_str[i] = '0' + reversed_digits[i];\n        } else {\n            result_str[i] = '\\0';\n            break;\n        }\n    }\n    result_str[max_digits] = '\\0';\n    \n    return std::string(result_str);\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c\nstd::string change_base_simd(int64_t x, int8_t base){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c\nstd::string change_base_simd(int64_t x, int8_t base){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <string.h>\n#include <stdint.h>\n\nstd::string change_base_simd(int64_t x, int8_t base) {\n    const int vlen = vgetvl();\n    const int max_digits = 64; // Assuming maximum of 64 digits for simplicity\n    int8_t digits[vlen];\n    uint8_t valid_mask[vlen];\n    \n    // Initialize vectors\n    vuint64m1_t vx = vle64_v_u64m1(&x, 1);\n    vint8m1_t vbase = vle8_v_i8m1(&base, 1);\n    \n    // Vectorized base conversion logic\n    int i = 0;\n    while (vx.v[i] != 0) {\n        vdivuw_vx(vd, vx, vbase); // Compute quotient\n        vmul_vx(vmod, vx, vbase); // Compute remainder\n        vse8_v_i8m1(digits + i * vlen, vd); // Store quotient\n        vx = vd;\n        i++;\n    }\n    \n    // Reverse the digits\n    int8_t reversed_digits[max_digits];\n    for (int j = 0; j < i; j++) {\n        memcpy(reversed_digits + j * vlen, digits + (i - j - 1) * vlen, sizeof(int8_t) * vlen);\n    }\n    \n    // Convert digits to string\n    char result[max_digits];\n    for (int j = 0; j < i; j++) {\n        snprintf(result + j, sizeof(char) * vlen, \"%d\", reversed_digits[j]);\n    }\n    \n    return std::string(result);\n}\n```"}
{"task_id": "SimdBench_85_RVV", "completion": "```c\nstd::string change_base_simd(int64_t x, int8_t base){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_palindrome_simd(std::string text){\n    const size_t len = text.size();\n    if(len <= 1) return true;\n\n    size_t vl = vsetvl_e8m1(len);\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(text.c_str());\n\n    vuint8m1_t vec_left, vec_right;\n    for(size_t i=0; i < len/2; i+=vl){\n        vl = vsetvl_e8m1(len - i);\n        vec_left = vle8_v_u8m1(str + i, vl);\n        vec_right = vle8_v_u8m1(str + len - i - vl, vl);\n        if(vmsne_vx_u8m1(vec_left, vec_right, vl))\n            return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_palindrome_simd(std::string text){\n    const size_t len = text.size();\n    if(len <= 1) return true;\n\n    size_t vl = vsetvl_e8m1(len);\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(text.c_str());\n\n    vuint8m1_t vec_left, vec_right;\n    for(size_t i=0; i < len/2; i+=vl){\n        vl = vsetvl_e8m1(len - i);\n        vec_left = vle8_v_u8m1(str + i, vl);\n        vec_right = vle8_v_u8m1(str + len - i - vl, vl);\n        if(vmsne_vx_u8m1(vec_left, vec_right, vl))\n            return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_palindrome_simd(std::string text){\n    const size_t len = text.size();\n    if(len <= 1) return true;\n\n    size_t vl = vsetvl_e8m1(len);\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(text.c_str());\n\n    vuint8m1_t vec_left, vec_right;\n    for(size_t i=0; i < len/2; i+=vl){\n        vl = vsetvl_e8m1(len - i);\n        vec_left = vle8_v_u8m1(str + i, vl);\n        vec_right = vle8_v_u8m1(str + len - i - vl, vl);\n        if(vmsne_vx_u8m1(vec_left, vec_right, vl))\n            return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n\nbool is_palindrome_simd(std::string text){\n    size_t len = text.length();\n    if(len <= 1) return true;\n\n    size_t vl = vsetvl_e8m1(len);\n    const char* str = text.c_str();\n\n    vint8m1_t vec_left, vec_right;\n    for(size_t i=0; i < len/2; i+=vl){\n        vl = vsetvl_e8m1(len - i);\n        vec_left = vle8_v_i8m1(str + i, vl);\n        vec_right = vle8_v_i8m1(str + len - i - vl, vl);\n        if(vmsne_vx_i8m1(vec_left, vec_right, vl))\n            return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_86_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_palindrome_simd(std::string text){\n    const size_t len = text.size();\n    if(len <= 1) return true;\n\n    size_t vl = vsetvl_e8m1(len);\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(text.c_str());\n\n    vuint8m1_t vec_left, vec_right;\n    for(size_t i=0; i < len/2; i+=vl){\n        vl = vsetvl_e8m1(len - i);\n        vec_left = vle8_v_u8m1(str + i, vl);\n        vec_right = vle8_v_u8m1(str + len - i - vl, vl);\n        if(vmsne_vx_u8m1(vec_left, vec_right, vl))\n            return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\nstd::string decode_shift_simd(std::string s){\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* str = (uint82_t*)s.data();\n    uint8_t* out = (uint8_t*)_alloca(len);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(str + i, this_vl);\n        vuint8m1_t vec_out = vmseq_vx_u8m1(vec_in, 'e', this_vl); // Compare with 'e' (shifted 'a')\n        vec_out = vsub_vx_u8m1(vec_out, 5, this_vl); // Subtract 5\n        vse8_v_u8m1(out + i, vec_out, this_vl);\n    }\n\n    return std::string((char*)out, len);\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\nstd::string decode_shift_simd(std::string s){\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* str = (uint8_t*)s.data();\n    uint8_t* out = (uint8_t*)_alloca(len);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(str + i, this_vl);\n        vuint8m1_t vec_out = vmsub_vx_u8m1(vec_in, 5, this_vl);\n        vse8_v_u8m1(out + i, vec_out, this_vl);\n    }\n\n    return std::string((char*)out, len);\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\nstd::string decode_shift_simd(std::string s){\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* str = (uint8_t*)s.data();\n    uint8_t* out = (uint8_t*)_alloca(len);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(str + i, this_vl);\n        vuint8m1_t vec_out = vmseq_vx_u8m1(vec_in, 'e', this_vl); // 'e' corresponds to ('a' - 5)\n        vse8_v_u8m1(out + i, vec_out, this_vl);\n    }\n\n    return std::string((char*)out, len);\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\nstd::string decode_shift_simd(std::string s){\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* str = (uint8_t*)s.data();\n    uint8_t* out = (uint8_t*)_alloca(len);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(str + i, this_vl);\n        vuint8m1_t vec_out = vmseq_vx_u8m1(vec_in, 'e', this_vl); // 'e' corresponds to ('a' - 5)\n        vse8_v_u8m1(out + i, vec_out, this_vl);\n    }\n\n    return std::string((char*)out, len);\n}\n```"}
{"task_id": "SimdBench_87_RVV", "completion": "```cpp\nstd::string decode_shift_simd(std::string s){\n    size_t len = s.length();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t* str = (uint8_t*)s.data();\n    uint8_t* out = (uint8_t*)_alloca(len);\n\n    for(size_t i=0; i<len; i+=vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vuint8m1_t vec_in = vle8_v_u8m1(str + i, this_vl);\n        vuint8m1_t vec_out = vmsub_vx_u8m1(vec_in, 5, this_vl);\n        vse8_v_u8m1(out + i, vec_out, this_vl);\n    }\n\n    return std::string((char*)out, len);\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t vl = vsetvl_e32m1(l.size());\n    const int8_t* data = reinterpret_cast<const int8_t*>(l.data());\n    vint32m1_t vec = vle32_v_i32m1(data, vl);\n    vint32m1_t threshold = vmslt_vx_i32m1(vec, t, vl);\n    return vor_seg_v_i32m1(threshold, vl) == vl;\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t vl = vsetvl_e32m1(l.size());\n    const int32_t *input = l.data();\n    vint32m1_t vec = vle32_v_i32m1(input, vl);\n    vboolm1_t mask = vmseq_v_i32m1_i32(vec, t, vl);\n    return vmall_m_b1(mask);\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t vl = vsetvl_e32m1(l.size());\n    const int32_t *input = l.data();\n    vint32m1_t vec = vle32_v_i32m1(input, vl);\n    vboolm1_t mask = vmseq_v_i32m1_i32(vec, t, vl);\n    return vmall_m_b1(mask);\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t vl = vsetvl_e32m1(l.size());\n    vint32m1_t vec = vle32_v_i32(l.data(), vl);\n    vboolm1_t mask = vmseq_v_i32(vec, vdup_e32m1(t, vl), vl);\n    return vmall_m_b1(mask);\n}\n```"}
{"task_id": "SimdBench_88_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool below_threshold_simd(std::vector<int> l, int t) {\n    size_t vl = vsetvl_e32m1(l.size());\n    const int32_t *input = l.data();\n    vint32m1_t vec = vle32_v_i32m1(input, vl);\n    vboolm1_t mask = vmseq_v_i32m1_i32(vec, t, vl);\n    return vmall_m_b1(mask);\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t input[vlen / 8];\n    for(size_t i = 0; i < len; ++i){\n        input[i] = brackets[i] == '<' ? 1 : -1;\n    }\n    int8_t sum = 0;\n    for(size_t i = 0; i < len; i += vl){\n        size_t this_len = len - i > vl ? vl : len - i;\n        uint8_t vec_input[this_len];\n        for(size_t j = 0; j < this_len; ++j){\n            vec_input[j] = input[i + j];\n        }\n        uint8_t masked_vec_input[vlen / 8];\n        vmsltu_vx(masked_vec_input, vec_input, 0, this_len, v\u52d20);\n        sum += vadd_vx(masked_vec_input, 0, this_len, v\u52d20);\n    }\n    return sum == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t input[vlen / 8];\n    for(size_t i = 0; i < len; i++){\n        input[i] = brackets[i] == '<' ? 1 : -1;\n    }\n    int8_t sum = 0;\n    for(size_t i = 0; i < len; i += vl){\n        size_t this_vl = vsetvl_e8m1(len - i);\n        vint8_t vec = vle8_v_i8m1(input + i, this_vl);\n        vint8_t cumsum = vadd_sum_vs_i8m1_i8(vec, sum_v_i8m1(sum, this_vl), this_vl);\n        sum = vmv_x_s_i8m1_i8(cumsum);\n        if(sum < 0){\n            return false;\n        }\n    }\n    return sum == 0;\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    vbool4_t mask = 0;\n    vint8_t stack = 0;\n    const int8_t open_bracket = '<';\n    const int8_t close_bracket = '>';\n    \n    for(size_t i=0; i<len; i+=4){\n        vint8_t chars;\n        v\u52d2\u96f7\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    vbool16_t mask = 0;\n    vint8_t stack = 0;\n    const int8_t open_bracket = '<';\n    const int8_t close_bracket = '>';\n    \n    for(size_t i=0; i<len; i+=16){\n        size_t l = len - i;\n        vint8_t chars = vle8_v_i8m1((const int8_t*)(brackets.c_str()+i), l);\n        vbool16_t open_mask = vmslt_v_i8m1_i8m1(chars, open_bracket);\n        vbool16_t close_mask = vmslt_v_i8m1_i8m1(chars, close_bracket);\n        \n        stack = vsub_mask_i8m1_i8m1(stack, chars, open_mask);\n        stack = vadd_mask_i8m1_i8m1(stack, chars, close_mask);\n        \n        mask = vor_v_b16m1_b16m1(mask, open_mask);\n    }\n    \n    return vset_v_i8m1(stack) == 0 && !vany_v_b16m1(mask);\n}\n```"}
{"task_id": "SimdBench_89_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t input[vlen / 8];\n    for(size_t i = 0; i < len; ++i){\n        input[i] = brackets[i] == '<' ? 1 : -1;\n    }\n    uint8_t sum_seg[vlen / 8];\n    vuint8m1_t sum = vle8_v_u8m1(input, vl);\n    sum = vwadd_sumu_vx_u8m1(sum, 0, vl);\n    vse8_v_u8m1(sum_seg, sum, vl);\n    return sum_seg[0] == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    size_t len = brackets.size();\n    uint8_t v_mask[vlen / 8];\n    for (size_t i = 0; i < len; i += vlen / 8){\n        size_t chunk_size = (len - i >= vlen / 8) ? vlen / 8 : len % (vlen / 8);\n        vuint8m1_t open_brackets = vle8_v_u8m1((uint8_t*)&brackets[i], chunk_size);\n        vuint8m1_t close_brackets = vseqz_v_u8m1(chunk_size);\n\n        vint8m1_t diff = vsub_vx_i8m1(open_brackets, close_brackets);\n        vint8m1_t cum_diff = vadd_vx_i8m1(vsubvs_vx_i8m1(diff, 0, chunk_size), 0);\n\n        vmseq_vx_u8m1(v_mask, cum_diff, 0, chunk_size);\n        if (!vmall_m_u8m1(v_mask, chunk_size)) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    const char *str = brackets.c_str();\n\n    vint8m1_t open_mask = vluxei8_v_i8m1(str, 0, vl);\n    vint8m1_t close_mask = vluxei8_v_i8m1(str, 1, vl);\n\n    vint32m1_t balance = vsub_vx_i32m1(vluxei8_v_i32m1(open_mask, 0, vl), vl);\n    \n    balance = vadd_vx_i32m1(balance, vsegei8_v_i32m1(close_mask, 1, vl));\n\n    return vmsum_vs_i32m1_i32m1(balance, balance, 0, vl) == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstddef>\n#include <cstring>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t *bracket_vec = (uint8_t *)brackets.c_str();\n\n    vint8m1_t open_count = v\u52d20m1(0);\n    vint8m1_t close_count = v\u52d20m1(0);\n\n    for (size_t i = 0; i < len; i += vl) {\n        size_t this_step = (i + vl > len) ? len - i : vl;\n        vint8m1_t current = vle8_v_i8m1(&bracket_vec[i], this_step);\n        \n        vint8m1_t is_open = v\u52d2eq_v_i8m1(current, v\u52d21m1('('));\n        vint8m1_t is_close = v\u52d2eq_v_i8m1(current, v\u52d21m1(')'));\n\n        open_count = vadd_vx_i8m1(open_count, v\u52d2mul_vx_i8m1(is_open, v\u52d21m1(1)));\n        close_count = vadd_vx_i8m1(close_count, v\u52d2mul_vx_i8m1(is_close, v\u52d21m1(-1)));\n    }\n\n    int total_open = vse32_v_i8m1(vredsum_vs_i8m1_i8m1(open_count, v\u52d20m1(0), v\u52d20m1(1)));\n    int total_close = vse32_v_i8m1(vredsum_vs_i8m1_i8m1(close_count, v\u52d20m1(0), v\u52d20m1(1)));\n\n    return total_open == total_close && total_open == 0;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool correct_bracketing_simd(std::string brackets){\n    const size_t len = brackets.size();\n    uint8_t v_mask[vlen / 8];\n    for (size_t i = 0; i < len; i += vlen / 8){\n        size_t chunk_size = (len - i >= vlen / 8) ? vlen / 8 : len % (vlen / 8);\n        vuint8m1_t open_brackets = vle8_v_u8m1((uint8_t*)&brackets[i], chunk_size);\n        vuint8m1_t close_brackets = vseqz_v_u8m1(chunk_size);\n\n        vint8m1_t diff = vsub_vx_i8m1(open_brackets, close_brackets);\n        vint8m1_t cum_diff = vadd_vx_i8m1(vsubvs_vx_i8m1(diff, 0, chunk_size), 0);\n\n        vse8_v_u8m1(vle8_v_u8m1((uint8_t*)&brackets[i], chunk_size), chunk_size);\n        if (cum_diff != 0) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_90_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n\nbool correct_bracketing_simd(std::string brackets) {\n    size_t len = brackets.size();\n    size_t vl = vsetvl_e8m1(len);\n    uint8_t *bracket_vec = (uint8_t *)brackets.c_str();\n\n    vint8m1_t open_mask = vluxei8_v_i8m1(bracket_vec, 0, vl);\n    vint8m1_t close_mask = vluxei8_v_i8m1(bracket_vec, 1, vl);\n\n    vint32m1_t balance = vsub_vx_i32m1(vluxei32_v_i32m1((int32_t *)open_mask, 0, vl), \n                                      vluxei32_v_i32m1((int32_t *)close_mask, 0, vl), vl);\n\n    int32_t final_balance = vadd_vx_i32(balance, 0, vl);\n    \n    return final_balance == 0;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    const int n = xs.size();\n    if(n <= 1){\n        return std::vector<float>();\n    }\n    int vl = vsetvl_e32m1(n-1);\n    std::vector<float> result(n-1);\n    float* res_ptr = result.data();\n    const float* xs_ptr = xs.data() + 1;\n    vfloat32m1_t v_xs, v_res;\n    for(int i=0; i<n-1; i+=vl){\n        vl = vsetvl_e32m1(std::min(n-1-i, vl));\n        v_xs = vle32_v_f32m1(xs_ptr + i, vl);\n        v_res = vmul_vf_f32m1(vadd_vf_f32m1(v_xs, 0.0f, vl), static_cast<float>(vl), vl);\n        vse32_v_f32m1(res_ptr + i, v_res, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    const int n = xs.size();\n    if(n <= 1){\n        return std::vector<float>();\n    }\n    int vl = vsetvl_e32m1(n-1);\n    std::vector<float> result(n-1);\n    float* res_ptr = result.data();\n    const float* xs_ptr = xs.data() + 1;\n    vfloat32m1_t v_xs, v_res;\n    for(int i=0; i<n-1; i+=vl){\n        vl = vsetvl_e32m1(std::min(n-1-i, vl));\n        v_xs = vle32_v_f32m1(xs_ptr + i, vl);\n        v_res = vfwmul_vf_f32m1(v_xs, static_cast<float>(vl), vl);\n        vse32_v_f32m1(res_ptr + i, v_res, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    const int n = xs.size();\n    if(n <= 1){\n        return std::vector<float>();\n    }\n    \n    size_t vl = vsetvl_e32m1(n-1);\n    std::vector<float> result(n-1);\n    \n    float* res_ptr = result.data();\n    const float* xs_ptr = xs.data() + 1;\n    \n    vfloat32m1_t vec_xs, vec_res;\n    for(int i=0; i<n-1; i+=vl){\n        vl = vsetvl_e32m1(std::min(n-1-i, vl));\n        vec_xs = vle32_v_f32m1(xs_ptr + i, vl);\n        vec_res = vfwmul_vf_f32m1(vec_xs, static_cast<float>(vl), vl);\n        vse32_v_f32m1(res_ptr + i, vec_res, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    const int n = xs.size();\n    if(n <= 1){\n        return std::vector<float>();\n    }\n    \n    size_t vl = vsetvl_e32m1(n-1);\n    std::vector<float> result(n-1);\n    \n    float* res_ptr = result.data();\n    const float* xs_ptr = xs.data() + 1;\n    \n    vfloat32m1_t vec_xs, vec_res;\n    for(int i=0; i<n-1; i+=vl){\n        vl = vsetvl_e32m1(std::min(n-1-i, vl));\n        vec_xs = vle32_v_f32m1(xs_ptr + i, vl);\n        vec_res = vfwmul_vf_f32m1(vec_xs, static_cast<float>(vl), vl);\n        vse32_v_f32m1(res_ptr + i, vec_res, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_91_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<float> derivative_simd(std::vector<float> xs){\n    const int vl = vsetvl_e32m1(xs.size() - 1);\n    std::vector<float> result(vl, 0.0f);\n    float* res_ptr = result.data();\n    const float* xs_ptr = xs.data();\n\n    for(int i=0; i<vl; i++) {\n        res_ptr[i] = static_cast<float>(i+1) * xs_ptr[i+1];\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c\nint vowels_count_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.size());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8m1_t mask_a = vmsne_vx_u8m1(vec, 'a', vl);\n    vbool8m1_t mask_e = vmsne_vx_u8m1(vec, 'e', vl);\n    vbool8m1_t mask_i = vmsne_vx_u8m1(vec, 'i', vl);\n    vbool8m1_t mask_o = vmsne_vx_u8m1(vec, 'o', vl);\n    vbool8m1_t mask_u = vmsne_vx_u8m1(vec, 'u', vl);\n    vbool8m1_t mask_y = vmsne_vx_u8m1(vec, 'y', vl);\n    \n    vbool8m1_t mask_end_y = vmsne_vx_u8m1(vget_v_u8m1(vec, vl-1), 'y', 1);\n    \n    vbool8m1_t total_mask = vmseq_vx_u8m1(vec, 'a', vl) | vmseq_vx_u8m1(vec, 'e', vl) |\n                            vmseq_vx_u8m1(vec, 'i', vl) | vmseq_vx_u8m1(vec, 'o', vl) |\n                            vmseq_vx_u8m1(vec, 'u', vl);\n    \n    total_mask = vmerge_vb(total_mask, mask_y, mask_end_y);\n    \n    return vpopc_v_i32m1(vbext_q_te(total_mask));\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c\nint vowels_count_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.size());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8m1_t mask_a = vmsne_vx_u8m1(vec, 'a', vl);\n    vbool8m1_t mask_e = vmsne_vx_u8m1(vec, 'e', vl);\n    vbool8m1_t mask_i = vmsne_vx_u8m1(vec, 'i', vl);\n    vbool8m1_t mask_o = vmsne_vx_u8m1(vec, 'o', vl);\n    vbool8m1_t mask_u = vmsne_vx_u8m1(vec, 'u', vl);\n    vbool8m1_t mask_y = vmsne_vx_u8m1(vec, 'y', vl);\n    \n    vbool8m1_t mask_end_y = vmsne_vx_u8m1(vget_v_u8m1(vec, vl-1), 'y', 1);\n\n    uint8_t count = 0;\n    count += vpopc_m_u8m1(mask_a);\n    count += vpopc_m_u8m1(mask_e);\n    count += vpopc_m_u8m1(mask_i);\n    count += vpopc_m_u8m1(mask_o);\n    count += vpopc_m_u8m1(mask_u);\n    count += vpopc_m_u8m1(vmand_mm(mask_y, mask_end_y));\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c\nint vowels_count_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.size());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8m1_t mask_a = vmsne_vx_u8m1(vec, 'a', vl);\n    vbool8m1_t mask_e = vmsne_vx_u8m1(vec, 'e', vl);\n    vbool8m1_t mask_i = vmsne_vx_u8m1(vec, 'i', vl);\n    vbool8m1_t mask_o = vmsne_vx_u8m1(vec, 'o', vl);\n    vbool8m1_t mask_u = vmsne_vx_u8m1(vec, 'u', vl);\n    vbool8m1_t mask_y = vmsne_vx_u8m1(vec, 'y', vl);\n    \n    vbool8m1_t mask_end_y = vmsne_vx_u8m1(vget_v_u8m1(vec, vl-1), 'y', 1);\n\n    uint8_t count = 0;\n    count += vpopc_m_u8m1(mask_a);\n    count += vpopc_m_u8m1(mask_e);\n    count += vpopc_m_u8m1(mask_i);\n    count += vpopc_m_u8m1(mask_o);\n    count += vpopc_m_u8m1(mask_u);\n    count += vpopc_m_u8m1(vmand_mm(mask_y, mask_end_y));\n    \n    return count;\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c\nint vowels_count_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.size());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8m1_t mask_a = vmsne_vx_u8m1(vec, 'a', vl);\n    vbool8m1_t mask_e = vmsne_vx_u8m1(vec, 'e', vl);\n    vbool8m1_t mask_i = vmsne_vx_u8m1(vec, 'i', vl);\n    vbool8m1_t mask_o = vmsne_vx_u8m1(vec, 'o', vl);\n    vbool8m1_t mask_u = vmsne_vx_u8m1(vec, 'u', vl);\n    vbool8m1_t mask_y = vmsne_vx_u8m1(vec, 'y', vl);\n    vbool8m1_t mask_end_y = vmsge_vx_u8m1(vec, 'y', vl);\n\n    vbool8m1_t total_mask = vor vvbool8m1(mask_a, mask_e, vl);\n    total_mask = vor vvbool8m1(total_mask, mask_i, vl);\n    total_mask = vor vvbool8m1(total_mask, mask_o, vl);\n    total_mask = vor vvbool8m1(total_mask, mask_u, vl);\n    total_mask = vor vvbool8m1(total_mask, mask_y, vl);\n    total_mask = vand vvbool8m1(total_mask, mask_end_y, vl);\n\n    return vpopc_v_u8m1(total_mask);\n}\n```"}
{"task_id": "SimdBench_92_RVV", "completion": "```c\nint vowels_count_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.size());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8m1_t mask_a = vmsne_vx_u8m1(vec, 'a', vl);\n    vbool8m1_t mask_e = vmsne_vx_u8m1(vec, 'e', vl);\n    vbool8m1_t mask_i = vmsne_vx_u8m1(vec, 'i', vl);\n    vbool8m1_t mask_o = vmsne_vx_u8m1(vec, 'o', vl);\n    vbool8m1_t mask_u = vmsne_vx_u8m1(vec, 'u', vl);\n    vbool8m1_t mask_y = vmsne_vx_u8m1(vec, 'y', vl);\n    \n    vbool8m1_t mask_end_y = vmsne_vx_u8m1(vget_v_u8m1(vec, vl-1), 'y', 1);\n\n    uint8_t count = 0;\n    count += vpopc_m_u8m1(mask_a);\n    count += vpopc_m_u8m1(mask_e);\n    count += vpopc_m_u8m1(mask_i);\n    count += vpopc_m_u8m1(mask_o);\n    count += vpopc_m_u8m1(mask_u);\n    count += vpopc_m_u8m1(vmand_mm(mask_y, mask_end_y));\n    return count;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\nint digitSum_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.length());\n    const unsigned char* str = reinterpret_cast<const unsigned char*>(s.c_str());\n    vint8m1_t vec = vle8_v_i8m1(str, vl);\n    vbool8m1_t mask = vmsne_vx_i8m1(vec, 'A', vl);\n    vint8m1_t upper = vmseq_vx_i8m1(vec, 'A', vl);\n    for(int i=1;i<26;i++){\n        vint8m1_t temp = vmseq_vx_i8m1(vec, 'A' + i, vl);\n        upper = vor_b_m(vbmask_b(upper), vbmask_b(temp), vl);\n    }\n    vec = vmseq_b_m(vec, upper, vl);\n    return vse8_v_i8m1(vec);\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\nint digitSum_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.length());\n    const unsigned char* str = reinterpret_cast<const unsigned char*>(s.c_str());\n    vint8m1_t vec = vle8_v_i8m1(str, vl);\n    vbool8_t mask = vmseq_v_i8m1_i8(vec, 'A', vl) | vmseq_v_i8m1_i8(vec, 'Z', vl);\n    vint8m1_t upper = vmseq_v_i8m1_i8(vec, 'A', vl) ? vec - 'A' + 'a' : vec;\n    vint8m1_t ascii_sum = vadd_vx_i8m1(upper, 0, vl);\n    return vsum_v_i8m1(ascii_sum, vl);\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\nint digitSum_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.length());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec;\n    vint8m1_t upper_check;\n    vint32m1_t ascii_sum = vint32m1_zero(vsetvl_e32m1());\n\n    for(int i=0; i<s.length(); i+=vl){\n        vec = vle8_v_u8m1(str + i, vl);\n        upper_check = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vor_vv_i8m1(upper_check, upper_check);\n        vec = vmslt_vx_u8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmslt_vx_u8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmseq_v_i8m"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\nint digitSum_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.length());\n    const unsigned char* str = reinterpret_cast<const unsigned char*>(s.c_str());\n    vuint8m1_t vec = vle8_v_u8m1(str, vl);\n    vbool8 mask = vmsne_vx_u8(vec, 'A', vl);\n    vuint8m1_t upper = vmseq_vx_u8(vec, 'A', vl);\n    for(int i=1; i<26; i++){\n        vbool8 temp = vmseq_vx_u8(vec, 'A' + i, vl);\n        upper |= temp;\n    }\n    vint8m1_t ascii = vsub_vx_i8(vec, 'A', vl);\n    ascii = vmseq_vx_i8(ascii, 0, vl) ? 0 : ascii;\n    vint8m1_t sum = vmul_vx_i8(ascii, upper, vl);\n    int result = vsum_v_i8(sum, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_93_RVV", "completion": "```c\nint digitSum_simd(std::string s){\n    const int vl = vsetvl_e8m1(s.length());\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    vuint8m1_t vec;\n    vint8m1_t upper_check;\n    vint32m1_t ascii_sum = vint32m1_zero(vsetvl_e32m1());\n\n    for(int i=0; i<s.length(); i+=vl){\n        vec = vle8_v_u8m1(str + i, vl);\n        upper_check = vmseq_v_i8m1(vec, 'A');\n        upper_check = vmseq_v_i8m1(vec, 'Z');\n        upper_check = vor_vv_i8m1(upper_check, upper_check);\n        vec = vmslt_vx_u8m1(vec, 'A');\n        upper_check = vmand_mm(upper_check, upper_check);\n        vec = vmsub_vx_u8m1(vec, 'Z' - 'A' + 1);\n        vec = vmsub_vx_u8m1(vec, 'A');\n        vec = vmseq_vx_u8m1(vec, 0);\n        vec = vmand_mm(vec, upper_check);\n        ascii_sum = vadd_vx_i32m1(ascii_sum, vsmul_vx_i32m1(vec, vec, 'A'));\n    }\n    return vsum_s32m1(ascii_sum);\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    std::vector<int> result(2, -1);\n    vint32m1_t indices = vsub_vx_i32m1(vl, 0);\n    vboolm1_t mask = vbset_m1_i32m1(vl);\n\n    for(int i=0; i<arr.size(); i+=vl){\n        vint32m1_t values = vle32_v_i32m1(&arr[i], vl);\n        vboolm1_t even_mask = veq_vx_u32m1(vl, values, 0);\n        vint32m1_t even_values = vmseq_vx_i32m1(vl, values, 0, even_mask);\n        vint32m1_t min_even = vmin_vx_i32m1(vl, even_values, 0);\n        vint32m1_t min_indices = vmseq_vx_i32m1(vl, indices, 0, even_mask);\n        vint32m1_t min_index = vmin_vx_i32m1(vl, min_indices, 0);\n        vint32m1_t min_value = vlsge_vx_i32m1(vl, min_even, 0);\n        vint32m1_t valid_min = vmseq_vx_i32m1(vl, min_value, 0);\n        if(valid_min){\n            result[0] = vle32_v_i32m1(&min_value, 1)[0];\n            result[1] = vle32_v_i32m1(&min_index, 1)[0];\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    std::vector<int> result(2, -1);\n    vint32m1_t indices = vsub_vx_i32m1(vl, 0);\n    vboolm1_t mask = vbset_m1_i32m1(vl);\n\n    for(int i=0; i<arr.size(); i+=vl){\n        vint32m1_t values = vle32_v_i32m1(&arr[i], vl);\n        vboolm1_t even_mask = veq_vx_u32m1(vl, values, 0);\n        vint32m1_t even_values = vmseq_vx_i32m1(vl, values, 0, even_mask);\n        vint32m1_t min_even = vmin_vx_i32m1(vl, even_values, 0);\n        vint32m1_t min_indices = vmslt_vx_i32m1(vl, indices, 0);\n        vint32m1_t valid_min = vmseq_vx_i32m1(vl, even_values, min_even, min_indices);\n        vint32m1_t selected_indices = vselect_i32m1(valid_min, indices, vsub_vx_i32m1(vl, 0));\n        vint32m1_t selected_values = vselect_i32m1(valid_min, values, vsub_vx_i32m1(vl, 0));\n\n        result[0] = vget_vx_i32(selected_values);\n        result[1] = vget_vx_i32(selected_indices);\n        break;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    std::vector<int> result(2, -1);\n    vint32m1_t indices = vsub_vx_i32m1(vl, 0);\n    vboolm1_t mask = vbset_u32m1(vl);\n\n    for(int i=0; i<arr.size(); i+=vl){\n        vint32m1_t values = vle32_v_i32m1(&arr[i], vl);\n        vboolm1_t even_mask = veq_vx_u32m1(vl, values, 0);\n        vint32m1_t even_values = vmseq_vx_i32m1(vl, values, 0, even_mask);\n        vint32m1_t min_value = vmin_vx_i32m1(vl, even_values, 0);\n        vint32m1_t min_indices = vmslt_vx_i32m1(vl, indices, 0);\n        vint32m1_t selected_indices = vselect_i32m1(min_indices, indices, min_value);\n        vint32m1_t selected_values = vselect_i32m1(min_indices, values, min_value);\n        vse32_v_i32m1(&result[0], vl, selected_values);\n        vse32_v_i32m1(&result[1], vl, selected_indices);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    std::vector<int> result(2, -1);\n    vint32m1_t indices = vsub_vx_i32m1(vl, 0);\n    vboolm1_t mask = vbset_m1_i32m1(vl);\n\n    for(int i=0; i<arr.size(); i+=vl){\n        vint32m1_t values = vle32_v_i32m1(&arr[i], vl);\n        vboolm1_t even_mask = veq_vx_b8_i32m1(values, 0, vl);\n        vint32m1_t even_values = vmseq_vx_i32m1(values, 0, vl);\n        vint32m1_t min_even = vmin_vx_i32m1(even_values, vl);\n        vint32m1_t min_indices = vmslt_vx_i32m1(indices, vl, min_even);\n        vse32_v_i32m1(&result[0], min_even, vl);\n        vse32_v_i32m1(&result[1], min_indices, vl);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_94_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> pluck_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    std::vector<int> result(2, -1);\n    vint32m1_t indices = vseq_w(0, vl);\n    vboolm1_t mask = vbset_m1(false);\n\n    for(int i=0; i<arr.size(); i+=vl){\n        vint32m1_t values = vle32_v_i32(arr.data()+i, vl);\n        vboolm1_t even_mask = vor_m_bf(vmsne_vx_u32(vmseq_m_bf(mask, values, 0), 0), vl);\n        if(!vbtest_m_bf(mask, even_mask)){\n            continue;\n        }\n        vint32m1_t even_values = vmseq_vx_i32(values, 0, even_mask);\n        vint32m1_t min_index = vidmax_v_i32(even_values, even_mask);\n        vint32m1_t min_value = vlsge_vx_i32(values, vle32_v_i32(&arr[min_index], 1), even_mask);\n        if(vmslt_vx_i32(min_value, result[0], mask)){\n            result[0] = vle32_v_i32(&arr[min_index], 1);\n            result[1] = min_index;\n        }\n    }\n    if(result[0] == -1){\n        result.clear();\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\nint search_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vboolm1_t mask = v\u52d20m1(vl);\n    int freq[256] = {0};\n    \n    for(int i=0;i<lst.size();i+=vl){\n        vint32m1_t chunk = vle32_v_i32m1(&lst[i], vl);\n        vfloat32m1_t cmp = vfredusum_vs_f32m1_f32m1_mask(chunk, chunk, v\u52d20m1(vl), mask);\n        vint32m1_t cnt = vadd_v_i32m1(cnt, cmp, mask);\n    }\n    \n    int result = -1;\n    for(int i=1;i<=255;i++){\n        if(freq[i] >= i && i > result){\n            result = i;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\nint search_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vbool32m1_t mask = vbge_vx_i32m1(vec, 1);\n    vec = vmseq_vx_i32m1(vec, 0, mask);\n    int freq[32] = {0};\n    for(int i=0;i<32;i++) {\n        vint32m1_t mask_i = vmseq_vx_i32m1(vec, i, mask);\n        freq[i] = vpopc_m_b32m1(mask_i);\n    }\n    int result = -1;\n    for(int i=1;i<32;i++) {\n        if(freq[i] >= i && i > result){\n            result = i;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\nint search_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vbool32m1_t mask = vbge_vx_i32m1(vec, 1);\n    vec = vmseq_vx_i32m1(vec, 0, mask);\n    int freq[1024] __attribute__((aligned(64))) = {0};\n    for(int i=0;i<1024;i++) {\n        vint32m1_t val = vsetvl_e32m1(1);\n        val = vle32_v_i32m1(&i, val);\n        vbool32m1_t m = viseq_vx_i32m1(vec, val, vl);\n        freq[i] += vpopc_m_b32m1(m);\n    }\n    int result = -1;\n    for(int i=1;i<1024;i++) {\n        if(freq[i] >= i && i > result){\n            result = i;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\nint search_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec_indices = vseq_v_i32m1(vl, 0);\n    vbool16m1_t mask_all = vmsne_vx_i32m1(vec_indices, 0, vl);\n\n    // Count frequencies using a vectorized approach\n    vint32m1_t vec_values = vlsseg32_v_i32m1(lst.data(), vl);\n    vuint32m1_t vec_counts = vsub_vx_u32m1(vmv_x_v_u32m1(vtrue_m1_b16(vl)), vec_values, vl);\n\n    // Find the maximum valid value\n    int max_value = -1;\n    for(int i=0; i<lst.size(); i++){\n        if(lst[i] > 0 && vec_counts[i] >= lst[i]){\n            if(lst[i] > max_value){\n                max_value = lst[i];\n            }\n        }\n    }\n    return max_value;\n}\n```"}
{"task_id": "SimdBench_95_RVV", "completion": "```cpp\nint search_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vbool32m1_t mask = vbge_vx_u32m1(vec, 1);\n    vec = vmslt_vx_i32m1(vec, 1, mask);\n    vint32m1_t freq;\n    for(int i=1;i<=lst.size();i++){\n        vbool32m1_t count_mask = viseq_vx_i32m1(vec, i, vl);\n        int count = vpopc_m_b32m1(count_mask);\n        if(count >= i){\n            freq = vset_v_i32m1(i);\n            break;\n        }\n    }\n    int result = vamoadd_wx_i32m1(freq, -1, vl);\n    return (result > 0) ? result : -1;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t vl = vsetvl_e32m1(q.size());\n    vint32m1_t vec_q = vle32_v_i32m1(q.data(), vl);\n    \n    // Calculate the sum using vector reduction\n    vint32m1_t sum_vec = vredsum_vs_i32m1_i32m1(vec_q, vint32m1_t(0), vl);\n    int sum = vget_i32(sum_vec);\n\n    // Check if sum exceeds the maximum weight\n    if (sum > w) return false;\n\n    // Check if the vector is palindromic\n    vint32m1_t reversed_vec = vrev8_v_i32m1(vec_q);\n    bool is_palindromic = (vmsne_vx_i32m1(reversed_vec, vec_q, vl) == 0);\n\n    return is_palindromic;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t vl = vsetvl_e32m1(q.size());\n    vint32m1_t vec_q = vle32_v_i32m1(q.data(), vl);\n    \n    // Calculate the sum using vector reduction\n    vint32m1_t sum_vec = vredsum_vs_i32m1_i32m1(vec_q, vint32m1_t(0), vl);\n    int sum = vget_i32(sum_vec, 0);\n\n    // Check if sum exceeds the maximum possible weight\n    if (sum > w) return false;\n\n    // Check if the vector is palindromic\n    vboolm1_t is_palindrome = vtrue_m1_b(vl);\n    for (size_t i = 0; i < vl / 2; i++) {\n        vint32m1_t left = vle32_v_i32m1(&q[i], 1);\n        vint32m1_t right = vle32_v_i32m1(&q[vl - i - 1], 1);\n        is_palindrome = vmand_m1_b(is_palindrome, veq_vx_i32m1(left, right, 1));\n    }\n\n    return vany_true_m1_b(is_palindrome);\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t vl = vsetvl_e32m1(q.size());\n    vint32m1_t vec_q = vle32_v_i32m1(q.data(), vl);\n    \n    // Calculate the sum using vector reduction\n    vint32m1_t sum_vec = vredsum_vs_i32m1_i32m1(vec_q, vint32m1_t(0), vl);\n    int sum = vget_i32(sum_vec, 0);\n\n    // Check if sum exceeds the maximum possible weight\n    if (sum > w) return false;\n\n    // Check if the vector is palindromic\n    vboolm1_t is_palindrome = vtrue_m_b(vl);\n    for (size_t i = 0; i < vl / 2; i++) {\n        vint32m1_t left = vle32_v_i32m1(&q[i], 1);\n        vint32m1_t right = vle32_v_i32m1(&q[vl - i - 1], 1);\n        is_palindrome = vmand_mm(is_palindrome, veq_vx_i32m1(left, right, 1));\n    }\n\n    return vany_b(is_palindrome);\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t vl = vsetvl_e32m1(q.size());\n    vint32m1_t vec_q = vle32_v_i32m1(q.data(), vl);\n    \n    // Calculate the sum using vector reduction\n    vint32m1_t sum_vec = vadd_vx_i32m1(vec_q, 0, vl);\n    int sum = vsum_s32_i32m1(sum_vec, vl);\n    \n    // Check if sum exceeds the maximum weight\n    if (sum > w) return false;\n    \n    // Check if the vector is palindromic\n    vint32m1_t reversed_vec = vreverse_v_i32m1(vec_q, vl);\n    bool is_palindromic = veq_vx_i32m1(vec_q, reversed_vec, vl) == vl;\n    \n    return is_palindromic;\n}\n```"}
{"task_id": "SimdBench_96_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool will_it_fly_simd(std::vector<int> q, int w) {\n    size_t vl = vsetvl_e32m1(q.size());\n    vint32m1_t vec_q = vle32_v_i32m1(q.data(), vl);\n    \n    // Calculate the sum using vector reduction\n    vint32m1_t sum_vec = vredsum_vs_i32m1_i32m1(vec_q, vint32m1_t(0), vl);\n    int sum = vget_i32(sum_vec, 0);\n\n    // Check if sum exceeds the maximum possible weight\n    if (sum > w) return false;\n\n    // Check if the vector is palindromic\n    vboolm1_t is_palindrome = vtrue_m_b(vl);\n    for (size_t i = 0; i < vl / 2; i++) {\n        vint32m1_t left = vle32_v_i32m1(&q[i], 1);\n        vint32m1_t right = vle32_v_i32m1(&q[q.size() - i - 1], 1);\n        is_palindrome = vmseq_v_i32m1_b1(is_palindrome, left, right, vl);\n    }\n\n    return vall_m_b(is_palindrome);\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr){\n    size_t len = arr.size();\n    size_t vl = vsetvl_e32m1(len);\n    int* data = arr.data();\n    vint32m1_t vec_left, vec_right;\n    int changes = 0;\n\n    for(size_t i=0; i<len/2; i+=vl){\n        vl = vsetvl_e32m1(len - i);\n        vec_left = vle32_v_i32m1(data + i, vl);\n        vec_right = vle32_v_i32m1(data + len - i - 1, vl);\n        vint32m1_t diff = vmseq_v_i32m1(vec_left, vec_right);\n        changes += vpopc_v_i32m1(diff);\n    }\n\n    if(len % 2 != 0){\n        changes += (arr[len/2] != arr[len/2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr){\n    size_t len = arr.size();\n    size_t vl = vsetvl_e32m1(len);\n    int* data = arr.data();\n    vint32m1_t vec1, vec2;\n    int count = 0;\n\n    for(size_t i=0; i<len; i+=vl){\n        vl = vsetvl_e32m1(len - i);\n        vec1 = vle32_v_i32m1(data + i, vl);\n        vec2 = vle32_v_i32m1(data + len - i - 1, vl);\n        vint32m1_t diff = vmseq_v_i32m1(vec1, vec2, vl);\n        count += vl - vpopc_m_b32(diff, vl);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr){\n    size_t len = arr.size();\n    size_t vl = vsetvl_e32m1(len);\n    int* data = arr.data();\n    vint32m1_t vec_left, vec_right;\n    int changes = 0;\n\n    for(size_t i=0; i<len/2; i+=vl){\n        vl = vsetvl_e32m1(len - i);\n        vec_left = vle32_v_i32m1(data + i, vl);\n        vec_right = vle32_v_i32m1(data + len - i - 1, vl);\n        vint32m1_t diff = vmseq_v_i32m1(vec_left, vec_right);\n        changes += vpopc_v_i32m1(diff);\n    }\n\n    if(len % 2 != 0){\n        changes += (arr[len/2] != arr[len/2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr){\n    size_t n = arr.size();\n    size_t vl = vsetvl_e32m1(n);\n    vint32m1_t vec_arr = v\u52d2index>\n```"}
{"task_id": "SimdBench_97_RVV", "completion": "```cpp\nint smallest_change_simd(std::vector<int> arr){\n    size_t len = arr.size();\n    size_t vl = vsetvl_e32m1(len);\n    int* data = arr.data();\n    vint32m1_t vec_left, vec_right;\n    int changes = 0;\n\n    for(size_t i=0; i<len/2; i+=vl){\n        vl = vsetvl_e32m1(len - i);\n        vec_left = vle32_v_i32m1(data + i, vl);\n        vec_right = vle32_v_i32m1(data + len - i - 1, vl);\n        vint32m1_t diff = vmseq_v_i32m1(vec_left, vec_right);\n        changes += vpopc_v_i32m1(diff);\n    }\n\n    if(len % 2 != 0){\n        changes += (arr[len/2] != arr[len/2]);\n    }\n\n    return changes;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    size_t len1 = lst1.size();\n    size_t len2 = lst2.size();\n    \n    if(len1 == 0 && len2 == 0){\n        return {};\n    }\n    \n    size_t max_len = (len1 > len2) ? len1 : len2;\n    std::vector<int> lens1(max_len, 0);\n    std::vector<int> lens2(max_len, 0);\n\n    for(size_t i = 0; i < len1; i++){\n        lens1[i] = lst1[i].length();\n    }\n    for(size_t i = 0; i < len2; i++){\n        lens2[i] = lst2[i].length();\n    }\n\n    size_t vl = vsetvl_e32m1(max_len);\n    vint32m1_t vec_lens1 = v\u52d2\u6212e_int32m1(lens1.data(), vl);\n    vint32m1_t vec_lens2 = v\u52d2\u6212e_int32m1(lens2.data(), vl);\n\n    vboolm1_t mask = vreduce_sum_u32m1(vec_lens1) < vreduce_sum_u32m1(vec_lens2);\n\n    std::vector<std::string> result;\n    if(vmask_elem(mask)){\n        result = lst2;\n    }\n    else{\n        result = lst1;\n    }\n    \n    return result;\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```c\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    size_t len1 = 0;\n    size_t len2 = 0;\n\n    if (!lst1.empty()) {\n        len1 = vadd_vv_u32(vle_v_u32((uint32_t *)lst1.data(), lst1.size(), vl), vsub_vx_u32(vl, lst1.size()), vl);\n    }\n    if (!lst2.empty()) {\n        len2 = vadd_vv_u32(vle_v_u32((uint32_t *)lst2.data(), lst2.size(), vl), vsub_vx_u32(vl, lst2.size()), vl);\n    }\n\n    if (len1 < len2) {\n        return lst1;\n    } else if (len2 < len1) {\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    size_t len1 = lst1.size();\n    size_t len2 = lst2.size();\n    size_t max_len = len1 > len2 ? len1 : len2;\n    \n    std::vector<int> lens1(max_len, 0);\n    std::vector<int> lens2(max_len, 0);\n\n    for(size_t i = 0; i < len1; i++){\n        lens1[i] = lst1[i].length();\n    }\n    for(size_t i = 0; i < len2; i++){\n        lens2[i] = lst2[i].length();\n    }\n\n    size_t vl = vsetvl_e32m1(max_len);\n    vint32m1_t vec_lens1 = v\u52d2\u96f7\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <cstring>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    size_t len1 = lst1.size();\n    size_t len2 = lst2.size();\n    size_t max_len = len1 > len2 ? len1 : len2;\n    \n    // Initialize vectors for character counts\n    std::vector<int> lens1(max_len, 0);\n    std::vector<int> lens2(max_len, 0);\n\n    // Calculate lengths of strings in lst1\n    for(size_t i=0; i<len1; ++i){\n        lens1[i] = lst1[i].length();\n    }\n    for(size_t i=len1; i<max_len; ++i){\n        lens1[i] = 0;\n    }\n\n    // Calculate lengths of strings in lst2\n    for(size_t i=0; i<len2; ++i){\n        lens2[i] = lst2[i].length();\n    }\n    for(size_t i=len2; i<max_len; ++i){\n        lens2[i] = 0;\n    }\n\n    // Use RVV intrinsics to compute sums in parallel\n    size_t vl = vsetvl_e32m1(max_len);\n    vint32m1_t sum1 = v\u52d20;\n    vint32m1_t sum2 = v\u52d20;\n\n    for(size_t i=0; i<max_len; i+=vl){\n        vint32m1_t lens1_vec = v\u52d2((int32_t*)&lens1[i], vl);\n        vint32m1_t lens2_vec = v\u52d2((int32_t*)&lens2[i], vl);\n        sum1 = vadd_vx(sum1, v\u52d2_sum(lens1_vec));\n        sum2 = vadd_vx(sum2, v\u52d2_sum(lens2_vec));\n    }\n\n    int total1 = v\u52d2_sum(sum1);\n    int total2 = v\u52d2_sum(sum2);\n\n    // Compare totals and return appropriate vector\n    if(total1 < total2){\n        return lst1;\n    } else if(total2 < total1){\n        return lst2;\n    } else {\n        return lst1;\n    }\n}\n```"}
{"task_id": "SimdBench_98_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n#include <algorithm>\n\nstd::vector<std::string> total_match_simd(const std::vector<std::string> & lst1, const std::vector<std::string> & lst2){\n    size_t len1 = lst1.size();\n    size_t len2 = lst2.size();\n    size_t max_len = std::max(len1, len2);\n    std::vector<int> lens1(max_len, 0);\n    std::vector<int> lens2(max_len, 0);\n\n    for(size_t i = 0; i < len1; i++){\n        lens1[i] = lst1[i].length();\n    }\n    for(size_t i = 0; i < len2; i++){\n        lens2[i] = lst2[i].length();\n    }\n\n    size_t vl = vsetvl_e32m1(max_len);\n    vint32m1_t vec_lens1 = vseq_v_i32m1(lens1.data(), vl);\n    vint32m1_t vec_lens2 = vseq_v_i32m1(lens2.data(), vl);\n\n    vboolm1_t mask = vmadd_vx_bm1(vec_lens1, vec_lens2, vl, v\u52d20);\n    std::vector<std::string> result;\n    if(vmsum_vs_b_v(mask, vl)){\n        result = lst1;\n    }\n    else{\n        result = lst2;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    size_t vl = vsetvl_e64m1(1);\n    vuint64m1_t vec_x = {x};\n    vuint64m1_t vec_n = {n};\n    vbool1_t mask = v\u52d20m1(0);\n\n    uint64_t result = 1;\n    while (result < x) {\n        result *= n;\n        v\u52d21m1(mask, result == x);\n    }\n    return v\u52d21m1(mask);\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    size_t vl = vsetvl_e64m1(1);\n    uint64_t max_exp = 64;\n    vuint64m1_t vec_n = {n};\n    vbool1_t mask_all = true;\n\n    if(n == 1){\n        return x == 1;\n    }\n\n    vuint64m1_t vec_x = {x};\n    vbool1_t result = vmseq_vv_u64(mask_all, vec_x, vec_n);\n\n    if(vmsum_vs_u64_u64(mask_all, result, vec_n, vl) > 0){\n        return true;\n    }\n\n    vuint64m1_t vec_current = {n};\n    for(size_t i = 1; i < max_exp; i++){\n        vec_current = vmul_vv_u64(vec_current, vec_n, vl);\n        result = vmseq_vv_u64(mask_all, vec_current, vec_x);\n        if(vmsum_vs_u64_u64(mask_all, result, vec_n, vl) > 0){\n            return true;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    size_t vl = vsetvl_e64m1(1);\n    vuint64m1_t vec_x = {x};\n    vuint64m1_t vec_n = {n};\n    vbool1_t mask = v\u52d20m1(1);\n\n    vuint64m1_t result = vmseq_vx_u64(vec_x, vec_n, vl);\n    return vmsum_mask_b1_u64(result, mask);\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n) {\n    size_t vl = vsetvl_e64m1(1);\n    uint64_t max_val = (uint64_t)vle64_v_u64(vl, &x, vl);\n    uint64_t base = n;\n    int count = 0;\n\n    while (base <= max_val) {\n        if (base == x) {\n            return true;\n        }\n        base *= n;\n        count++;\n        if (count > 63) { // Prevent infinite loop for invalid cases\n            break;\n        }\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_99_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nbool is_simple_power_simd(uint64_t x, uint64_t n){\n    size_t vl = vsetvl_e64m1(1);\n    uint64_t base = n;\n    uint64_t result[1];\n    result[0] = 1;\n\n    while(vl > 0){\n        uint64_t temp = vle64_v_u64(result, vl);\n        temp = temp * base;\n        vse64_v_u64(result, &temp, vl);\n        if(result[0] == x){\n            return true;\n        }\n        vl = vsetvl_e64m1(vl - 1);\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```c\nint hex_key_simd(const std::string & num){\n    const uint8_t prime_mask[16] __attribute__((aligned(64))) = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0};\n    vuint8m1_t mask_vec;\n    vuint8m1_t char_vec;\n    vbool16_t mask;\n    int count = 0;\n    size_t i = 0;\n\n    while(i + 16 <= num.size()){\n        mask_vec = vle8_v_u8m1((const uint8_t*)(num.data() + i), VLMAX);\n        char_vec = vmseq_vx_u8m1(mask_vec, '0', VLMAX);\n        mask = vmslt_vx_u8m1(mask_vec, 'F' + 1, VLMAX);\n        mask = vmseq_vx_u8m1(mask_vec, '9' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'E' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'D' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'C' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'B' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'A' + 1, VLMAX) | mask;\n        mask = vmslt_vx_u8m1(mask_vec, '7' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '6' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '5' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '3' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '2' + 1, VLMAX) | mask;\n        mask = vmslt_vx_u8m1(mask_vec, '1' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '0' + 1, VLMAX) | mask;\n        count += vpopc_m_b16(mask);\n        i += 16;\n    }\n    for(; i < num.size(); ++i){\n        if(num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' ||\n           num[i] == 'B' || num[i] == 'D'){\n            count++;\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\nint hex_key_simd(const std::string & num){\n    const uint8_t v_mask[16] = {0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0};\n    size_t len = num.size();\n    int count = 0;\n    vbool16 v_mask_v = __rvv_vmsne_vx_u8(v_mask, 0, 16);\n    \n    for(size_t i=0; i<len; i+=16){\n        size_t chunk_len = (len - i >= 16) ? 16 : len % 16;\n        vuint8m1_t v_hex = __rvv_vle8_v_u8((const unsigned char*)(num.c_str() + i), chunk_len);\n        vbool16 v_mask_chunk = __rvv_vmsge_vx_u8(v_hex, '0', chunk_len);\n        vbool16 v_valid = __rvv_vmand vv_mask_v, v_mask_chunk;\n        vuint8m1_t v_primes = __rvv_vcompress_b_u8(v_valid, v_hex);\n        count += __rvv_vpopc_b16(v_valid);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\nint hex_key_simd(const std::string & num){\n    const int vl = vsetvl_e8m1(16);\n    const uint8_t primes[16] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0};\n    const vuint8m1_t prime_mask = vloadu_v_u8m1(primes, vl);\n\n    vuint8m1_t vec = vle8_v_u8m1(reinterpret_cast<const uint8_t*>(num.c_str()), vl);\n    vbool16_t mask = vmslt_vx_u8m1(vec, 'A', vl);\n    vec = vmseq_vx_u8m1(vec, 'A', vl);\n    vec = vmselect_b16(mask, vec, vle8_v_u8m1(reinterpret_cast<const uint8_t*>(num.c_str()) + 1, vl));\n\n    vbool16_t prime_check = vmsge_vx_u8m1(vec, 'A', vl);\n    vuint8m1_t digit_values = vec - ('A' - 10);\n    digit_values = vmseq_vx_u8m1(digit_values, 10, vl);\n    digit_values = vmseq_vx_u8m1(digit_values, 11, vl);\n    digit_values = vmseq_vx_u8m1(digit_values, 13, vl);\n\n    vbool16_t final_mask = vmseq_v_u8m1(vec, '2', vl) | vmseq_v_u8m1(vec, '3', vl) |\n                           vmseq_v_u8m1(vec, '5', vl) | vmseq_v_u8m1(vec, '7', vl) |\n                           prime_check;\n\n    return vpopc_v_i32m1(vmand_mm(final_mask, prime_mask, vl));\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```cpp\nint hex_key_simd(const std::string & num){\n    const uint8_t prime_mask[16] __attribute__((aligned(64))) = {0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0};\n    vuint8m1_t mask_vec;\n    vuint8m1_t char_vec;\n    vbool16_t mask;\n    int count = 0;\n    size_t i = 0;\n\n    while(i + 16 <= num.size()){\n        mask_vec = vle8_v_u8m1((const uint8_t*)(num.data() + i), VLMAX);\n        char_vec = vmseq_vx_u8m1(mask_vec, '0', VLMAX);\n        mask = vmslt_vx_u8m1(mask_vec, 'F' + 1, VLMAX);\n        mask = vmseq_vx_u8m1(mask_vec, '9' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'E' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'D' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'C' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'B' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, 'A' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '8' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '7' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '6' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '5' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '4' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '3' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '2' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '1' + 1, VLMAX) | mask;\n        mask = vmseq_vx_u8m1(mask_vec, '0' + 1, VLMAX) | mask;\n        count += vpopc_m_b16(mask);\n        i += 16;\n    }\n\n    for(; i < num.size(); ++i){\n        if(num[i] == '2' || num[i] == '3' || num[i] == '5' || num[i] == '7' ||\n           num[i] == 'B' || num[i] == 'D'){\n            count++;\n        }\n    }\n\n    return count;\n}\n```"}
{"task_id": "SimdBench_100_RVV", "completion": "```c\nint hex_key_simd(const std::string & num){\n    const int vl = vsetvl_e8m1(16);\n    const uint8_t primes[16] = {0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0};\n    const vuint8m1_t prime_mask = vloadu_v_u8m1(primes, vl);\n    vuint8m1_t vec;\n    int count = 0;\n    for(int i=0; i<num.size(); i+=vl){\n        vec = vle8_v_u8m1(num.data()+i, vl);\n        vuint8m1_t masked = vmseq_v_i8m1(vec, '2', vl);\n        masked = vmseq_v_i8m1(masked, '3', vl) | masked;\n        masked = vmseq_v_i8m1(masked, '5', vl) | masked;\n        masked = vmseq_v_i8m1(masked, '7', vl) | masked;\n        masked = vmseq_v_i8m1(masked, 'B', vl) | masked;\n        masked = vmseq_v_i8m1(masked, 'D', vl) | masked;\n        count += vpopc_m_b8m1(vmseq_v_u8m1(masked, prime_mask, vl));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\nbool is_happy_simd(const std::string & s){\n    const int vec_len = vsetvl_e8m1(8); // Vector length for uint8_t elements\n    const char *str = s.c_str();\n    size_t len = s.length();\n\n    if(len < 3){\n        return false;\n    }\n\n    vuint8m1_t vec_a, vec_b, vec_c;\n    for(size_t i = 0; i <= len - 3; i += vec_len){\n        size_t chunk_len = (len - i >= vec_len) ? vec_len : len - i;\n        vuint8m1_t vec_s = vle8_v_u8m1(str + i, vl);\n        \n        // Load three consecutive vectors with offset\n        vec_a = vsub_vx_u8m1(vec_s, 0, vl);\n        vec_b = vsub_vx_u8m1(vec_s, 1, vl);\n        vec_c = vsub_vx_u8m1(vec_s, 2, vl);\n\n        // Check if all elements in the three vectors are distinct\n        vboolm1_t mask_ab = vmsne_vx_u8m1(vec_a, vec_b, vl);\n        vboolm1_t mask_ac = vmsne_vx_u8m1(vec_a, vec_c, vl);\n        vboolm1_t mask_bc = vmsne_vx_u8m1(vec_b, vec_c, vl);\n\n        // If any pair is not distinct, return false\n        if(vfirst_b(mask_ab | mask_ac | mask_bc, vl)){\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\nbool is_happy_simd(const std::string & s){\n    const int vl = vsetvl_e8m1(3);\n    const uint8_t* str = reinterpret_cast<const uint8_t*>(s.c_str());\n    \n    if(s.length() < 3){\n        return false;\n    }\n    \n    vuint8m1_t vec_a, vec_b, vec_c;\n    \n    // Load first three characters\n    vec_a = vle8_v_u8m1(str, vl);\n    \n    for(int i=1; i <= static_cast<int>(s.length()) - 2; i += vl){\n        vec_b = vec_a;\n        vec_a = vle8_v_u8m1(str + i, vl);\n        \n        vec_c = vmseq_vv_u8m1(vec_a, vec_b, vl);\n        if(vmsum_vs_u8m1_u8m1(vec_c, vec_c, vl).v[0] > 0){\n            return false;\n        }\n        \n        if(i + vl < static_cast<int>(s.length())){\n            vec_c = vmseq_vx_u8m1(vec_a, str[i + vl], vl);\n            if(vec_c.v[0] != 0){\n                return false;\n            }\n        }\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\nbool is_happy_simd(const std::string & s){\n    const int vec_len = vsetvl_e8m1(8); // Use vector length of 8 for char\n    const char *str = s.c_str();\n    size_t len = s.length();\n\n    if(len < 3){\n        return false;\n    }\n\n    vint8m1_t vec_a, vec_b, vec_c;\n    for(size_t i = 0; i <= len - 3; i += vec_len){\n        size_t chunk_len = (len - i >= vec_len) ? vec_len : len - i;\n        vint8m1_t vec_s = vle8_v_i8m1(str + i, chunk_len);\n\n        // Load three consecutive vectors with offset\n        vec_a = vslide1up_vx_i8m1(vec_s, 0, chunk_len);\n        vec_b = vslide1down_vx_i8m1(vec_s, chunk_len);\n        vec_c = vec_s;\n\n        // Compare each element in the three vectors\n        vboolm1_t mask_ab = vmsne_vx_i8m1(vec_a, vec_b, chunk_len);\n        vboolm1_t mask_ac = vmsne_vx_i8m1(vec_a, vec_c, chunk_len);\n        vboolm1_t mask_bc = vmsne_vx_i8m1(vec_b, vec_c, chunk_len);\n\n        // Check if all pairs are unequal\n        vboolm1_t mask_all = vmand_mm(mask_ab, mask_ac, chunk_len);\n        mask_all = vmseq_mm(mask_all, mask_bc, chunk_len);\n\n        // If any part of the string fails, return false\n        if(vmsum_vs_b_m_i32m1(mask_all, mask_all, 0, chunk_len).ival != chunk_len){\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstddef>\n\nbool is_happy_simd(const std::string &s) {\n    const size_t len = s.size();\n    if (len < 3) return false;\n\n    size_t vl = vsetvl_e8m1(len);\n    const unsigned char *data = reinterpret_cast<const unsigned char *>(s.data());\n\n    vuint8m1_t vec_a, vec_b, vec_c;\n    for (size_t i = 0; i < len - 2; i += vl) {\n        vl = vsetvl_e8m1(std::min(len - i, vl));\n        vec_a = vle8_v_u8m1(data + i, vl);\n        vec_b = vle8_v_u8m1(data + i + 1, vl);\n        vec_c = vle8_v_u8m1(data + i + 2, vl);\n\n        vboolm1_t mask = vmseq_vv_u8m1(vec_a, vec_b, vl);\n        if (vmcloak(mask, vl)) return false;\n\n        mask = vmseq_vv_u8m1(vec_a, vec_c, vl);\n        if (vmcloak(mask, vl)) return false;\n\n        mask = vmseq_vv_u8m1(vec_b, vec_c, vl);\n        if (vmcloak(mask, vl)) return false;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_101_RVV", "completion": "```cpp\nbool is_happy_simd(const std::string & s){\n    const int vec_len = vsetvl_e8m1(8); // Use vector length of 8 for char\n    const char *str = s.c_str();\n    size_t len = s.length();\n\n    if(len < 3){\n        return false;\n    }\n\n    vint8m1_t vec_a, vec_b, vec_c;\n    for(size_t i = 0; i <= len - 3; i += vec_len){\n        size_t chunk_len = (len - i >= vec_len) ? vec_len : len - i;\n        vint8m1_t vec_s = vle8_v_i8m1(str + i, chunk_len);\n\n        // Load three consecutive vectors with offset\n        vec_a = vslide1up_vx_i8m1(vec_s, 0, chunk_len);\n        vec_b = vslide1down_vx_i8m1(vec_s, chunk_len);\n        vec_c = vec_s;\n\n        // Compare each element in the three vectors\n        vboolm1_t mask_ab = vmsne_vx_i8m1(vec_a, vec_b, chunk_len);\n        vboolm1_t mask_ac = vmsne_vx_i8m1(vec_a, vec_c, chunk_len);\n        vboolm1_t mask_bc = vmsne_vx_i8m1(vec_b, vec_c, chunk_len);\n\n        // Check if all pairs are unequal\n        vboolm1_t mask_all = vmand_mm(mask_ab, mask_ac, chunk_len);\n        mask_all = vmseq_mm(mask_all, mask_bc, chunk_len);\n\n        // If any part of the string fails, return false\n        if(vmsum_vs_b_m_i32m1(mask_all, vle32_v_i32m1(&i, 1), vle32_v_i32m1(&i, 0), chunk_len).data[0] > 0){\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c\nbool prime_length_simd(const std::string & str){\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t max_factor = static_cast<size_t>(std::sqrt(len));\n    vbool16_t mask = vsetvl_e32m1(max_factor);\n    vint32m1_t factors = vsub_vx_i32m1(mask, 1);\n\n    vbool16_t is_prime = vtrue_m1_b16(mask);\n    for(int i=2; i<=max_factor; i++){\n        vbool16_t local_mask = vseqge_vx_b16(mask, i);\n        vint32m1_t remainder = vrem_vx_i32m1(vsub_vx_i32m1(local_mask, 1), i);\n        vbool16_t divisible = vmseq_vx_b16(mask, remainder, 0);\n        is_prime = vand_mm_b16(is_prime, vnot_b16(divisible));\n    }\n    int result = vfirst_m_b16(is_prime);\n    return (result != -1);\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nbool prime_length_simd(const std::string & str){\n    size_t len = str.length();\n    if(len < 2) return false;\n\n    size_t max_factor = static_cast<size_t>(std::sqrt(len));\n    uint8_t mask[vlen / 8] __attribute__((aligned(64))) = {0};\n    \n    for(int i = 2; i <= max_factor; i++){\n        vint8m1_t vi = vset_v_i8m1(i);\n        vbool8_t vmask = vseq_v_i8m1(vi, len);\n        vmseq_vx(mask, vmask, 1, vlmax);\n    }\n    \n    for(int i = 2; i <= max_factor; i++){\n        vint8m1_t vi = vset_v_i8m1(i);\n        vbool8_t vmask = vseq_v_i8m1(vi, len);\n        if(vmsum_vs_b8m1_i32m1(mask, vmask, 0, vlmax) > 0){\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c\nbool prime_length_simd(const std::string & str){\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t max_factor = static_cast<size_t>(std::sqrt(len));\n    vbool_t mask = vsetvl_e32m1(max_factor);\n\n    for (size_t i = 2; i <= max_factor; i++) {\n        vuint32m1_t indices = vseq_w_b32m1(mask);\n        vuint32m1_t divisors = vadd_vx_u32(indices, i);\n        vboolm1_t is_divisible = veq_vx_u32(divisors, len);\n\n        if (vmulred_or_v_b32m1(is_divisible)) {\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c\nbool prime_length_simd(const std::string & str){\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t max_factor = static_cast<size_t>(std::sqrt(len));\n    vbool16_t mask = vsetvl_e32m1(max_factor);\n    vint32m1_t factors = vsub_vx_i32m1(mask, 1);\n\n    for(int i=2; i<=max_factor; i++){\n        vbool16_t cond = vmsltu_vx_i32m1(factors, i);\n        vint32m1_t mod_result = vremainder_vx_i32m1(vsub_vx_i32m1(factors, i), len);\n        if(vfirst_m_i32m1(cond, mod_result) != -1){\n            return false;\n        }\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_102_RVV", "completion": "```c\nbool prime_length_simd(const std::string & str){\n    size_t len = str.length();\n    if (len < 2) return false;\n\n    size_t max_factor = static_cast<size_t>(std::sqrt(len));\n    vbool16_t mask = vsetvl_e32m1(max_factor);\n    vint32m1_t factors = vsub_vx_i32m1(mask, 1);\n\n    vbool16_t is_prime = vtrue_m1_b16(mask);\n    for(int i=2; i<=max_factor; i++){\n        vbool16_t local_mask = vseqge_vx_b16(mask, i);\n        vbool16_t divisible = vremu_vx_i32m1(factors, i) == 0;\n        is_prime = vand_m1_b16(is_prime, vnot_b16(divisible));\n        if(!vany_b16(is_prime)) break;\n    }\n    return vany_b16(is_prime);\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    const int vec_len = vsetvl_e8u(1);\n    uint8_t data[vec_len];\n    std::memset(data, 0, vec_len);\n\n    int count = 0;\n    while (N > 0) {\n        data[count++] = N % 10;\n        N /= 10;\n        if (count == vec_len) {\n            uint8_t sum = 0;\n            for(int i=0; i<vec_len; i++) {\n                sum += data[i];\n            }\n            N += sum;\n            std::memset(data, 0, vec_len);\n            count = 0;\n        }\n    }\n\n    if(count > 0){\n        uint8_t sum = 0;\n        for(int i=0; i<count; i++) {\n            sum += data[i];\n        }\n        N += sum;\n    }\n\n    char buffer[64];\n    int pos = 0;\n    while(N > 0){\n        buffer[pos++] = '0' + (N % 10);\n        N /= 10;\n    }\n    std::reverse(buffer, buffer + pos);\n    return std::string(buffer, pos);\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    const int vl = vsetvl_e8u(8); // Vector length for uint8_t elements\n    uint8_t input[8] = {0};\n    int i = 7;\n    while (N > 0 && i >= 0){\n        input[i] = N % 10;\n        N /= 10;\n        i--;\n    }\n    uint8_t sum_vec[8] __attribute__((aligned(64)));\n    vuint8m1_t vec_input = vle8_v_u8m1(input + i + 1, vl);\n    vuint8m1_t vec_sum = vsub_vx_u8m1(vec_input, '0', vl);\n    vse8_v_u8m1(sum_vec, vec_sum, vl);\n    uint8_t sum = 0;\n    for(int j = 0; j < vl; j++){\n        sum += sum_vec[j];\n    }\n    char binary[64];\n    int index = 0;\n    while(sum > 0){\n        binary[index++] = (sum % 2) + '0';\n        sum /= 2;\n    }\n    std::string result(binary, index);\n    std::reverse(result.begin(), result.end());\n    return result;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    const int vl = vsetvl_e8u(8); // Vector length for 8 bytes\n    uint8_t input[8] __attribute__((aligned(64))) = {0};\n    uint8_t sum_vec[8] __attribute__((aligned(64))) = {0};\n    uint8_t sum = 0;\n\n    // Convert N to byte array\n    for(int i = 0; i < 8; i++) {\n        input[i] = (N >> (i * 8)) & 0xFF;\n    }\n\n    // Load data into vector registers\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n    vuint8m1_t vec_sum = vsub_vx_u8m1(vec_input, 0, vl);\n\n    // Sum the vector elements\n    for(int i = 1; i < vl; i *= 2){\n        vec_sum = vadd_vv_u8m1(vec_sum, vec_sum, vl / i);\n    }\n    sum = vget_v_i8m1(vec_sum, 0);\n\n    // Convert sum to binary string\n    std::string binary = \"\";\n    while(sum > 0){\n        binary = std::to_string(sum % 2) + binary;\n        sum /= 2;\n    }\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string>\n\nstd::string solve_simd(uint64_t N){\n    const int vl = vsetvl_e8u(8); // Set vector length for 8 elements\n    uint8_t input[8] = {0};\n    uint8_t sum_vec[8] = {0};\n    uint8_t sum = 0;\n\n    // Convert N to byte array\n    for(int i = 0; i < 8; i++) {\n        input[i] = N >> (i * 8) & 0xFF;\n    }\n\n    // Load data into vector registers\n    vuint8m1_t data = vle8_v_u8m1(input, vl);\n\n    // Compute sum using vector addition\n    vuint8m1_t sum_reg = vsub_vx_u8m1(data, 0, vl);\n    while(vl > 1){\n        sum_reg = vadd_vx_u8m1(sum_reg, 0, vl);\n        vl = vsetvl_e8u(vl / 2);\n    }\n    sum = vget_sum_u8m1(sum_reg);\n\n    // Convert sum to binary string\n    std::string binary = \"\";\n    while(sum > 0){\n        binary = std::to_string(sum % 2) + binary;\n        sum /= 2;\n    }\n    return binary.empty() ? \"0\" : binary;\n}\n```"}
{"task_id": "SimdBench_103_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string solve_simd(uint64_t N) {\n    const int vec_len = 8; // Assuming vector length of 8 bytes\n    uint8_t digits[vec_len];\n    std::memset(digits, 0, vec_len);\n\n    // Convert the number into bytes and store in the vector\n    for(int i = 0; i < vec_len && N > 0; ++i){\n        digits[i] = N % 10;\n        N /= 10;\n    }\n\n    // Use vector addition to compute the sum\n    vuint8m1_t vec_digits = vle8_v_u8m1(digits, vec_len);\n    vuint8m1_t sum_vec = vadd_vx_u8m1(vec_digits, 0, vec_len);\n\n    // Reduce the vector sum to a single value\n    uint8_t sum = 0;\n    for(int i = 0; i < vec_len; ++i){\n        sum += vget_v_i8m1(sum_vec, i);\n    }\n\n    // Convert the sum to binary string\n    char buffer[64];\n    snprintf(buffer, sizeof(buffer), \"%b\", sum);\n    return std::string(buffer);\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c\nint add_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec_indices = vseq_w(0, vl);\n    vboolm1_t mask_odd = vbmsel_m1(vec_indices, v\u52d201, v\u52d200);\n    vint32m1_t vec_lst = vle32_v_i32m1(lst.data(), vl);\n    vint32m1_t vec_even = vmseq_v_i32m1_i32(vec_lst, 0, vl);\n    vint32m1_t vec_selected = vmseq_v_i32m1_i32(vec_lst, 0, vl) & vmseq_v_i32m1_i32(vec_indices, 1, vl);\n    int sum = 0;\n    for(int i=0; i<vl; i++) {\n        if(vmreduce_or_m1(mask_odd, i)) {\n            sum += vec_lst[i];\n        }\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c\nint add_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vbool32m1_t mask = vbmsk_b32m1(vl);\n    vint32m1_t even_masked = vmseq_v_i32m1_i32(vec, 0, mask);\n    vint32m1_t odd_indices = vlsb_v_i32m1(vl);\n    vint32m1_t even_at_odd = vmand_mm(even_masked, odd_indices, mask);\n    vint32m1_t values_at_odd = vcompress_v_i32m1(vec, even_at_odd, mask);\n    int sum = 0;\n    for(int i=0; i<vl; i++) {\n        sum += vget_v_i32m1(values_at_odd, i);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c\nint add_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vboolm1_t mask = vbmsel_m_b1m1(vmsnei_v_i32m1(vec, 0, vl), \n                                   vmseq_v_i32m1(vec, 0, vl),\n                                   vmsltiu_v_i32m1(vec, 1, vl));\n    vint32m1_t even = vmseq_v_i32m1(vec, 0, vl);\n    vint32m1_t odd_index = vmsltiu_v_i32m1(vec, 1, vl);\n    vint32m1_t result_vec = vcompress_v_i32m1(vselect_b_i32m1(mask, even, odd_index), mask);\n    int result = vsum_v_i32m1(result_vec);\n    return result;\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c\nint add_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vboolm1_t mask = vbmsel_m_b1m1(vmsne_v_i32m1_i32(vec, 0, vl), \n                                   vmseq_v_i32m1_i32(vec, 1, vl));\n    vint32m1_t even_masked = vmslt_v_i32m1_i32(vec, 0, vl);\n    vint32m1_t odd_masked = vmslt_v_i32m1_i32(vec, 1, vl);\n    vint32m1_t even_at_odd = vmseq_v_i32m1_i32(even_masked, odd_masked, vl);\n    return vsum_v_i32m1(even_at_odd, vl);\n}\n```"}
{"task_id": "SimdBench_104_RVV", "completion": "```c\nint add_simd(std::vector<int> lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    vbool32m1_t mask = vbmsk_b32m1(vl);\n    vint32m1_t even_mask = vor_vv_i32m1(vec, vec, mask);\n    vint32m1_t odd_indices = vsub_vx_i32m1(even_mask, 1);\n    vint32m1_t result = vmslt_vx_i32m1(odd_indices, lst.size());\n    return vsum_v_i32m1(result);\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(32); // Set vector length for 32 characters\n    uint8_t input[32];\n    uint8_t output[32];\n\n    // Copy input string to uint8_t array\n    std::memcpy(input, s.c_str(), s.size());\n\n    // Encrypt each character using vector intrinsic\n    for (int i = 0; i < s.size(); i += vl) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vuint8m1_t vec_out = vmul_vx_u8m1(vec_in, 4, vl); // Multiply ASCII value by 4\n        vse8_v_u8m1(output + i, vec_out, vl);\n    }\n\n    // Convert back to string\n    return std::string((char *)output, s.size());\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    const int vec_len = 16; // Assuming vector length of 16 bytes\n    const char shift = 4;   // Two multiplied by two places shift\n    size_t len = s.size();\n    size_t i = 0;\n\n    // Allocate memory for the result\n    std::string result(len, ' ');\n    \n    // Process data in vectorized chunks\n    while (i + vec_len <= len) {\n        vuint8m1_t input_vec;\n        vuint8m1_t output_vec;\n\n        // Load input data into vector\n        for (int j = 0; j < vec_len; j++) {\n            ((unsigned char *)&input_vec)[j] = s[i + j];\n        }\n\n        // Perform encryption: shift characters by 'shift' positions\n        output_vec = vadd_vx_u8(input_vec, shift, vec_len);\n\n        // Wrap around if character exceeds 'z'\n        output_vec = vsub_vx_u8(output_vec, ('z' - 'a' + 1), vec_len);\n\n        // Store the result back to memory\n        for (int j = 0; j < vec_len; j++) {\n            result[i + j] = ((unsigned char *)&output_vec)[j];\n        }\n\n        i += vec_len;\n    }\n\n    // Handle remaining characters\n    while (i < len) {\n        result[i] = ((s[i] - 'a' + shift) % 26) + 'a';\n        i++;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(16); // Set vector length for 16 characters\n    uint8_t input[16] __attribute__((aligned(64)));\n    uint8_t output[16] __attribute__((aligned(64)));\n\n    // Copy input string to aligned buffer\n    std::memcpy(input, s.data(), s.size());\n    if (s.size() < 16) {\n        memset(input + s.size(), 0, 16 - s.size()); // Zero-pad if necessary\n    }\n\n    // Load data into vector registers\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n    vuint8m1_t vec_shift = vle8_v_u8m1((const uint8_t *)\"\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\", vl);\n\n    // Perform encryption: (x + 2*2) % 26\n    vuint8m1_t vec_base = vle8_v_u8m1((const uint8_t *)\"a\", vl);\n    vuint8m1_t vec_result = vmadd_vv_u8m1(vec_input, vec_shift, vec_base, vl);\n    vec_result = vmsub_vx_u8m1(vec_result, vec_base, vl);\n    vec_result = vmod_vx_u8m1(vec_result, 26, vl);\n\n    // Store result back to memory\n    vse8_v_u8m1(output, vec_result, vl);\n\n    // Extract the actual encrypted string\n    std::string result;\n    for (int i = 0; i < s.size(); i++) {\n        if (output[i] != 0) {\n            result += (char)(output[i] + 'a');\n        } else {\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    const int vec_len = 16; // Assuming vector length of 16 bytes\n    const char shift = 4;   // Two multiplied by two places shift\n    size_t len = s.size();\n    size_t i = 0;\n\n    // Allocate memory for the result\n    std::string result(len, ' ');\n    while (i < len) {\n        size_t chunk_size = std::min(vec_len, len - i);\n        size_t j;\n\n        // Load input characters into vector registers\n        vuint8m1_t input;\n        {\n            uint8_t input_bytes[vec_len];\n            for (j = 0; j < chunk_size; j++) {\n                input_bytes[j] = s[i + j];\n            }\n            input = vle8_v_u8m1(input_bytes, LMUL_1, vec_len);\n        }\n\n        // Perform encryption: add shift value\n        vuint8m1_t encrypted = vadd_vx_u8m1(input, shift, vec_len);\n\n        // Store encrypted characters back to memory\n        uint8_t output_bytes[vec_len];\n        vse8_v_u8m1(output_bytes, encrypted, LMUL_1, vec_len);\n        for (j = 0; j < chunk_size; j++) {\n            result[i + j] = output_bytes[j];\n        }\n\n        i += chunk_size;\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_105_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cstring>\n#include <string>\n\nstd::string encrypt_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(16); // Set vector length for 16 characters\n    uint8_t input[16] __attribute__((aligned(64)));\n    uint8_t output[16] __attribute__((aligned(64)));\n\n    // Copy input string to aligned buffer\n    std::memcpy(input, s.data(), s.size());\n    if (s.size() < 16) {\n        memset(input + s.size(), 0, 16 - s.size()); // Zero-pad if necessary\n    }\n\n    // Load data into vector registers\n    vuint8m1_t vec_input = vle8_v_u8m1(input, vl);\n    vuint8m1_t vec_shift = vle8_v_u8m1((const uint8_t *)\"\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\\x02\", vl);\n\n    // Perform encryption: (x + 2*2) % 26\n    vuint8m1_t vec_result = vadd_vv_u8m1(vec_input, vec_shift, vl);\n    vec_result = vmod_vx_u8m1(vec_result, 26, vl);\n\n    // Store result back to memory\n    vse8_v_u8m1(output, vec_result, vl);\n\n    // Extract the actual encrypted string from the output\n    std::string result;\n    for (int i = 0; i < s.size(); i++) {\n        if (output[i]) {\n            result += output[i];\n        } else {\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n#include <cctype>\n\nstd::string encode_simd(const std::string &message) {\n    const int vl = vsetvl_e8m1(32); // Vector length for 32 characters\n    uint8_t input[32];\n    uint8_t output[32];\n    std::memcpy(input, message.data(), message.size());\n\n    for(int i=0; i<message.size(); i+=vl) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vboolm1_t mask = vmsne_vx_u8m1(vec_in, 0, vl);\n\n        // Swap case\n        vuint8m1_t vec_upper = vmseq_vx_u8m1(vec_in, 'a', vl);\n        vuint8m1_t vec_lower = vmseq_vx_u8m1(vec_in, 'A', vl);\n        vuint8m1_t vec_swap_case = vor vv8m1_t(vec_upper, vec_lower, vl);\n        vuint8m1_t vec_swapped = vmsub_vx_u8m1(vec_in, 0x20, vec_swap_case);\n\n        // Replace vowels\n        vboolm1_t vowel_mask = vmsge_vx_u8m1(vec_swapped, 'a', vl) & vmsle_vx_u8m1(vec_swapped, 'z', vl);\n        vuint8m1_t vec_vowels = vmseq_vx_u8m1(vec_swapped, 'a', vl) | vmseq_vx_u8m1(vec_swapped, 'e', vl) |\n                                vmseq_vx_u8m1(vec_swapped, 'i', vl) | vmseq_vx_u8m1(vec_swapped, 'o', vl) |\n                                vmseq_vx_u8m1(vec_swapped, 'u', vl);\n        vuint8m1_t vec_replaced = vsub_vx_u8m1(vec_swapped, 0x6, vec_vowels);\n\n        // Store results\n        vse8_v_u8m1(output + i, vmslt_vx_u8m1(vec_replaced, 0, vl) ? vec_swapped : vec_replaced, mask);\n    }\n\n    return std::string((char *)output, message.size());\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n#include <cctype>\n\nstd::string encode_simd(const std::string &message) {\n    const int vl = vsetvl_e8m1(32); // Set vector length to process 32 bytes at a time\n    uint8_t input[32];\n    uint8_t output[32];\n    std::memcpy(input, message.data(), message.size());\n\n    for (int i = 0; i < message.size(); i += 32) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vuint8m1_t vec_out;\n\n        // Swap case\n        vbool8_t mask_upper = vmslt_u_u8m1(vec_in, v\u52d20_u8m1(65));\n        vbool8_t mask_lower = vmslt_u_u8m1(vec_in, v\u52d20_u8m1(97));\n        vec_out = vmseq_u_u8m1(vec_in, v\u52d20_u8m1(97), v\u52d20_u8m1(65)) | // 'a' -> 'A'\n                  vmseq_u_u8m1(vec_in, v\u52d20_u8m1(122), v\u52d20_u8m1(90)); // 'z' -> 'Z'\n\n        // Replace vowels\n        vbool8_t mask_a = vmseq_u_u8m1(vec_in, v\u52d20_u8m1('a'), v\u52d20_u8m1('e'));\n        vbool8_t mask_e = vmseq_u_u8m1(vec_in, v\u52d20_u8m1('e'), v\u52d20_u8m1('i'));\n        vbool8_t mask_i = vmseq_u_u8m1(vec_in, v\u52d20_u8m1('i'), v\u52d20_u8m1('o'));\n        vbool8_t mask_o = vmseq_u_u8m1(vec_in, v\u52d20_u8m1('o'), v\u52d20_u8m1('u'));\n        vbool8_t mask_u = vmseq_u_u8m1(vec_in, v\u52d20_u8m1('u'), v\u52d20_u8m1('a'));\n\n        vec_out = vmerge_vv_u8m1(vec_out, v\u52d20_u8m1('c'), mask_a);\n        vec_out = vmerge_vv_u8m1(vec_out, v\u52d20_u8m1('g'), mask_e);\n        vec_out = vmerge_vv_u8m1(vec_out, v\u52d20_u8m1('k'), mask_i);\n        vec_out = vmerge_vv_u8m1(vec_out, v\u52d20_u8m1('m'), mask_o);\n        vec_out = vmerge_vv_u8m1(vec_out, v\u52d20_u8m1('q'), mask_u);\n\n        vse8_v_u8m1(output + i, vec_out, vl);\n    }\n\n    return std::string((char *)output, message.size());\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n#include <cctype>\n\nstd::string encode_simd(const std::string &message) {\n    const int vl = vsetvl_e8m1(32); // Set vector length for 32 characters\n    uint8_t input[32];\n    uint8_t output[32];\n    std::memcpy(input, message.data(), message.size());\n\n    for(int i = 0; i < message.size(); i += vl) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vuint8m1_t vec_out;\n\n        // Swap case\n        vbool8_t mask_upper = vmslt_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"Z\", vl));\n        vbool8_t mask_lower = vmslt_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"a\", vl));\n        vec_out = vmseq_b8m1(mask_upper, vsub_vx_u8m1(vec_in, 'A', vl), vadd_vx_u8m1(vec_in, 'a' - 'A', vl));\n        vec_out = vmseq_b8m1(mask_lower, vadd_vx_u8m1(vec_in, 'A' - 'a', vl), vsub_vx_u8m1(vec_in, 'a', vl));\n\n        // Replace vowels\n        vbool8_t mask_a = vmseq_vx_u8m1(vec_in, 'a', vl);\n        vbool8_t mask_e = vmseq_vx_u8m1(vec_in, 'e', vl);\n        vbool8_t mask_i = vmseq_vx_u8m1(vec_in, 'i', vl);\n        vbool8_t mask_o = vmseq_vx_u8m1(vec_in, 'o', vl);\n        vbool8_t mask_u = vmseq_vx_u8m1(vec_in, 'u', vl);\n\n        vec_out = vmerge_vvm_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'c' - 'a', vl), mask_a);\n        vec_out = vmerge_vvm_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'g' - 'e', vl), mask_e);\n        vec_out = vmerge_vvm_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'k' - 'i', vl), mask_i);\n        vec_out = vmerge_vvm_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'm' - 'o', vl), mask_o);\n        vec_out = vmerge_vvm_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'w' - 'u', vl), mask_u);\n\n        vse8_v_u8m1(output + i, vec_out, vl);\n    }\n\n    return std::string((char *)output, message.size());\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n\nstd::string encode_simd(const std::string &message) {\n    const int vl = vsetvl_e8m1(32); // Set vector length for 32 characters\n    uint8_t input[32];\n    uint8_t output[32];\n    std::memcpy(input, message.c_str(), message.size());\n    input[message.size()] = 0;\n\n    for(int i = 0; i < message.size(); i += vl) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vuint8m1_t vec_out;\n\n        // Swap case\n        vbool8_t mask_upper = vmslt_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"A\", vl));\n        vbool8_t mask_lower = vmslt_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"a\", vl));\n        vec_out = vmseq_b8m1(mask_upper, vsub_vx_u8m1(vec_in, 'A', vl), vadd_vx_u8m1(vec_in, 'a' - 'A', vl));\n        vec_out = vmseq_b8m1(mask_lower, vsub_vx_u8m1(vec_in, 'a', vl), vadd_vx_u8m1(vec_in, 'A' - 'a', vl));\n\n        // Replace vowels\n        vbool8_t mask_a = vmsle_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"a\", vl));\n        vbool8_t mask_e = vmsle_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"e\", vl));\n        vbool8_t mask_i = vmsle_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"i\", vl));\n        vbool8_t mask_o = vmsle_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"o\", vl));\n        vbool8_t mask_u = vmsle_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t*) \"u\", vl));\n\n        vec_out = vmerge_vv_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'b' - 'a', vl), mask_a);\n        vec_out = vmerge_vv_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'f' - 'e', vl), mask_e);\n        vec_out = vmerge_vv_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'g' - 'i', vl), mask_i);\n        vec_out = vmerge_vv_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'h' - 'o', vl), mask_o);\n        vec_out = vmerge_vv_u8m1(vec_out, vadd_vx_u8m1(vec_in, 'j' - 'u', vl), mask_u);\n\n        vse8_v_u8m1(output + i, vec_out, vl);\n    }\n\n    return std::string((char *)output, message.size());\n}\n```"}
{"task_id": "SimdBench_106_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n\nstd::string encode_simd(const std::string &message) {\n    const int vl = vsetvl_e8m1(32); // Vector length for 32 characters\n    uint8_t input[32];\n    uint8_t output[32];\n    std::memcpy(input, message.data(), message.size());\n\n    for (int i = 0; i < message.size(); i += vl) {\n        vuint8m1_t vec_in = vle8_v_u8m1(input + i, vl);\n        vuint8m1_t vec_out;\n\n        // Swap case\n        vbool8_t mask = vmslt_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"Z\", vl));\n        vec_out = vmseq_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"AEIOUaeiou\", vl)) ? \n                  vadd_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"22222222\", vl)) : \n                  vmseq_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"a-z\", vl)) ?\n                  vsub_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"22222222\", vl)) :\n                  vmseq_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"A-Z\", vl)) ?\n                  vadd_u_u8m1(vec_in, vle8_v_u8m1((const uint8_t *)\"22222222\", vl)) :\n                  vec_in;\n\n        // Store result\n        vse8_v_u8m1(output + i, vec_out, vl);\n    }\n\n    return std::string((char *)output, message.size());\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string.h>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    size_t size = dict.size();\n    if(size == 0) return false;\n\n    bool all_upper = true;\n    bool all_lower = true;\n\n    const int vl = vsetvl_e8m1((size + 7) / 8);\n    uint8_t data[vl];\n    size_t i = 0;\n\n    for(const auto &pair : dict){\n        const std::string &key = pair.first;\n        memset(data, 0, vl * sizeof(uint8_t));\n        for(char c : key){\n            data[c - 'A'] |= 1;\n            data[c - 'a'] |= 2;\n        }\n        uint8_t sum = 0;\n        for(int j = 0; j < vl; j++) sum += data[j];\n        uint8_t res = vreduce_sum_u8((uint8_t*)data);\n        if(res != 255 && res != 0){\n            all_upper = false;\n            all_lower = false;\n            break;\n        }\n        if(res == 255) all_lower = false;\n        if(res == 0) all_upper = false;\n        i++;\n    }\n\n    return all_upper || all_lower;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string.h>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    size_t size = dict.size();\n    if(size == 0) return false;\n\n    bool all_upper = true;\n    bool all_lower = true;\n\n    size_t vec_len = vsetvl_e8m1(8); // Example vector length\n    uint8_t* keys_data = nullptr;\n    size_t keys_size = 0;\n    \n    // Extract keys data and size\n    for(const auto& pair : dict){\n        keys_data = reinterpret_cast<uint8_t*>(const_cast<char*>(pair.first.c_str()));\n        keys_size = pair.first.size();\n        if(keys_size == 0) continue;\n\n        uint8_t vstr[8];\n        for(size_t i=0; i<vec_len && i<keys_size; ++i){\n            vstr[i] = keys_data[i];\n        }\n        vuint8m1_t vstr_vec = vle8_v_u8m1(vstr, vec_len);\n        \n        // Check for uppercase\n        vboolm1_t vupper_mask = vmsne_vx_u8m1(vstr_vec, 'A', vec_len);\n        uint8_t vupper_res = vmv_x_s_u8m1_u8(vupper_mask);\n        if(vupper_res != 0){\n            all_upper = false;\n        }\n\n        // Check for lowercase\n        vboolm1_t vlower_mask = vmsne_vx_u8m1(vstr_vec, 'a', vec_len);\n        uint8_t vlower_res = vmv_x_s_u8m1_u8(vlower_mask);\n        if(vlower_res != 0){\n            all_lower = false;\n        }\n\n        if(!all_upper && !all_lower){\n            break;\n        }\n    }\n\n    return all_upper || all_lower;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string.h>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    size_t size = dict.size();\n    if(size == 0) return false;\n\n    bool all_upper = true;\n    bool all_lower = true;\n\n    size_t vec_len = vsetvl_e8m1(8); // Initialize vector length\n    uint8_t* keys_data = nullptr;\n    size_t keys_size = 0;\n    \n    for(auto& pair : dict){\n        keys_data = reinterpret_cast<uint8_t*>(const_cast<char*>(pair.first.c_str()));\n        keys_size = pair.first.size();\n\n        uint8_t lower_mask[8] __attribute__((aligned(64)));\n        uint8_t upper_mask[8] __attribute__((aligned(64)));\n\n        for(size_t i=0; i<keys_size; i+=vec_len){\n            size_t vl = vsetvl_e8m1(vec_len);\n            vuint8m1_t key_vec = vle8_v_u8m1(keys_data + i, vl);\n            \n            vuint8m1_t lower_check = vor_vv_u8m1(vlowercase_v_u8m1(key_vec), key_vec);\n            vse8_v_u8m1(lower_mask, lower_check, vl);\n\n            vuint8m1_t upper_check = vor_vv_u8m1(vuppercase_v_u8m1(key_vec), key_vec);\n            vse8_v_u8m1(upper_mask, upper_check, vl);\n\n            for(size_t j=0; j<vl; j++){\n                if(lower_mask[j] != 0) all_upper = false;\n                if(upper_mask[j] != 0) all_lower = false;\n            }\n        }\n\n        if(!all_upper && !all_lower) return false;\n    }\n\n    return all_upper || all_lower;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string.h>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    size_t size = dict.size();\n    if(size == 0) return false;\n\n    bool all_upper = true;\n    bool all_lower = true;\n\n    const int vl = vsetvl_e8m1((size + 7) / 8);\n    uint8_t data[vl];\n    size_t i = 0;\n\n    for(const auto &pair : dict){\n        const std::string &key = pair.first;\n        memset(data, 0, sizeof(data));\n        memcpy(data, key.data(), key.size() > vl ? vl : key.size());\n\n        uint8_t *vec = (uint8_t*)vle8_v_u8(data, vl);\n        \n        uint8_t upper_mask = vmsne_vx_u8(vec, 'A', vl);\n        uint8_t lower_mask = vmsne_vx_u8(vec, 'a', vl);\n\n        all_upper &= (vmsum_vs_u8_u8(all_upper ? 1 : 0, upper_mask, vl) == 0);\n        all_lower &= (vmsum_vs_u8_u8(all_lower ? 1 : 0, lower_mask, vl) == 0);\n\n        if(!all_upper && !all_lower) break;\n    }\n\n    return all_upper || all_lower;\n}\n```"}
{"task_id": "SimdBench_107_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <string.h>\n\nbool check_dict_case_simd(std::map<std::string, std::string> dict){\n    size_t size = dict.size();\n    if(size == 0) return false;\n\n    bool all_upper = true;\n    bool all_lower = true;\n\n    const int vec_len = vsetvl_e8m1(8); // Example vector length, adjust as needed\n    uint8_t* data = new uint8_t[vec_len];\n    size_t idx = 0;\n\n    for(const auto& pair : dict){\n        const std::string& key = pair.first;\n        if(key.length() > vec_len) return false; // Key too long for vector processing\n\n        memcpy(data, key.c_str(), key.length());\n        data[key.length()] = 0;\n\n        for(int i=0; i<key.length(); i+=vec_len){\n            uint8_t vl = vsetvl_e8m1(vec_len);\n            vuint8mf8_t vec = vle8_v_u8mf8(data + i, vl);\n            \n            vboolm8_t upper_mask = vreinterpretmb8_m8(vluxseg8mv_b8m8(vec, v\u52d2\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    if(n <= 2){\n        return std::vector<int>();\n    }\n    \n    int max_val = n;\n    int vlen = vsetvl_e32m1(max_val);\n    std::vector<int> primes;\n    std::vector<char> sieve(vlen, 1);\n    sieve[0] = sieve[1] = 0;\n\n    for(int i=2; i<n; i+=vlen){\n        int chunk_size = vsetvl_e32m1(i + vlen > n ? n - i : vlen);\n        vint32m1_t vi = vle32_v_i32m1(&i, chunk_size);\n        vboolm1_t mask = vmsltu_mask_i32m1(vi, n);\n        \n        for(int j=2; j*j<n; j+=vlen){\n            int step = j * j;\n            int end = n - step;\n            if(end <=0) break;\n            int step_chunk_size = vsetvl_e32m1(end > step + vlen ? vlen : end - step);\n            vint32m1_t vj = vle32_v_i32m1(&j, step_chunk_size);\n            vint32m1_t vstep = vle32_v_i32m1(&step, step_chunk_size);\n            vint32m1_t vidx = vmadd_vx_i32m1(vj, vstep, 0, step_chunk_size, mask);\n            \n            vsse32_v_i32m1(&sieve[0], vidx, 0, step_chunk_size, mask);\n        }\n\n        vint32m1_t vprimes = vcompress_v_i32m1(vi, sieve.data(), chunk_size, mask);\n        int* prime_ptr = (int*) &vprimes;\n        for(int k=0; k<chunk_size; k++){\n            if(prime_ptr[k]){\n                primes.push_back(prime_ptr[k]);\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    if(n <= 2){\n        return std::vector<int>();\n    }\n    \n    int max_val = n;\n    int num_bytes = sizeof(int) * ((max_val >> 5) + 1);\n    uint8_t *is_prime = (uint8_t*)malloc(num_bytes);\n    for(int i=0; i<num_bytes; i++) is_prime[i] = 0xFF;\n\n    is_prime[0] = 0x00;\n    if(n > 2) is_prime[1] = 0x00;\n\n    int vlenb = vsetvl_e8m1(8);\n    uint8_t mask = 0xFE;\n    for(int factor=3; factor*factor < n; factor+=2){\n        if(is_prime[factor>>3] & (mask >> (factor & 7))){\n            int start = factor * factor;\n            if(start % 2 == 0) start += factor;\n            for(int j=start; j<n; j+=factor*2){\n                is_prime[j>>3] &= ~(mask >> (j & 7));\n            }\n        }\n    }\n\n    std::vector<int> primes;\n    primes.reserve(n / 4); // Approximation\n\n    for(int i=3; i<n; i+=2){\n        if(is_prime[i>>3] & (mask >> (i & 7))){\n            primes.push_back(i);\n        }\n    }\n    if(n > 2) primes.insert(primes.begin(), 2);\n\n    free(is_prime);\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    if(n <= 2){\n        return std::vector<int>();\n    }\n    \n    int max_val = n;\n    int vlen = vgetvl_e32m1();\n    int num_elements = (max_val + vlen - 1) / vlen;\n    std::vector<int> primes;\n    primes.reserve(max_val); // Reserve space to avoid reallocations\n\n    // Initialize a vector to track prime candidates\n    std::vector<char> is_prime(max_val, 1);\n    is_prime[0] = is_prime[1] = 0;\n\n    for(int start = 2; start < max_val; start += vlen){\n        int end = std::min(start + vlen, max_val);\n        vint32m1_t vec_start = vsetivli(end - start, vsew8, vlmax_m1_b8());\n        \n        for(int i = start; i < end; i++){\n            if(is_prime[i]){\n                primes.push_back(i);\n                vint32m1_t mask = vle32_v_i32m1(&is_prime[i*i], vlen);\n                mask = vmseq_vx_i32m1(mask, i, vlmax_m1_b8());\n                vse32_v_i32m1(&is_prime[i*i], mask, vlmax_m1_b8());\n            }\n        }\n    }\n\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    if(n <= 2){\n        return std::vector<int>();\n    }\n    \n    int max_val = n;\n    int vlen = vsetvl_e32m1(max_val);\n    std::vector<int> primes;\n    std::vector<char> sieve(vlen, 1);\n    sieve[0] = sieve[1] = 0;\n\n    for(int i=2; i<n; i+=vlen){\n        int chunk_size = vlen;\n        if(i + vlen > n){\n            chunk_size = n - i;\n        }\n        vint32m1_t vi = vle32_v_i32m1(&i, vlmax());\n        vse32_v_i32m1(&sieve[i], vi, chunk_size);\n\n        vint32m1_t start = vsub_vx_i32m1(vi, 1, vlmax());\n        vint32m1_t step = vi;\n        vint32m1_t idx;\n        while(true){\n            idx = vadd_vx_i32m1(start, 0, vlmax());\n            if(vmslt_vx_u32m1(idx, i, vlmax())){\n                break;\n            }\n            vint32m1_t mask = vmseq_vx_u32m1(idx, 0, vlmax());\n            vint32m1_t indices = vsub_vx_i32m1(idx, i, vlmax());\n            vint32m1_t values = vle32_v_i32m1(&sieve[0], vlmax());\n            vint32m1_t masked_values = vmseq_mask_i32m1(values, mask, vlmax());\n            vse32_v_i32m1(&sieve[0], masked_values, vlmax());\n            start = vadd_vx_i32m1(start, i, vlmax());\n        }\n    }\n\n    for(int i=2; i<n; ++i){\n        if(sieve[i]){\n            primes.push_back(i);\n        }\n    }\n    return primes;\n}\n```"}
{"task_id": "SimdBench_108_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> count_up_to_simd(int n){\n    if(n <= 2){\n        return std::vector<int>();\n    }\n    \n    int max_val = n;\n    int vlen = vgetvl_e32m1();\n    int num_elements = vlen / sizeof(int);\n    std::vector<int> primes;\n    std::vector<int> candidates(num_elements, 0);\n    \n    for(int start = 2; start < n; start += num_elements){\n        int end = start + num_elements;\n        if(end > n){\n            end = n;\n        }\n        \n        for(int i = 0; i < num_elements && start + i < n; ++i){\n            candidates[i] = start + i;\n        }\n        \n        for(int j = 2; j*j < end; ++j){\n            vbool_t mask = v\u52d20_mask(candidates, j);\n            v\u52d20_masked(candidates, mask, j);\n        }\n        \n        for(int k = 0; k < num_elements && start + k < n; ++k){\n            if(candidates[k] != 0){\n                primes.push_back(candidates[k]);\n            }\n        }\n    }\n    \n    return primes;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c\nint count_upper_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(32);\n    const unsigned char upper_vowels[4] = {'A', 'E', 'I', 'O'};\n    vuint8m1_t mask = vloadu_v_u8m1(upper_vowels, vl);\n    vbool8_t vmask;\n    int count = 0;\n    for(int i=0; i < (int)s.size(); i+=32) {\n        vuint8m1_t vec = vle8_v_u8m1((const unsigned char*)s.c_str() + i, vl);\n        vmask = vmsne_v_i8m1_b8(vec, 0, vl);\n        vuint8m1_t filtered = vmseq_v_i8m1_u8m1(vec, mask, vl);\n        count += vpopc_v_i8m1(vmseq_v_i8m1_u8m1(filtered, vle8_v_u8m1((const unsigned char*)s.c_str() + i + 16, vl), vl), vl);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c\nint count_upper_simd(const std::string & s){\n    const int vl = vsetvl_e8m1(s.size());\n    const unsigned char upper_vowels[4] = {'A', 'E', 'I', 'O'};\n    vuint8m1_t vowel_vec = vloadu_v_u8m1(upper_vowels, vl);\n    vbool8_t mask;\n    int count = 0;\n    for(int i=0; i<s.size(); i+=vl){\n        vuint8m1_t str_vec = vle8_v_u8m1((unsigned char*)&s[i], vl);\n        mask = vmsne_vx_u8m1(str_vec, 0, vl);\n        vuint8m1_t filtered = vcompress_v_x_u8m1(str_vec, mask, vl);\n        vbool8_t vowel_mask = vmseq_vx_u8m1(filtered, vowel_vec, vl);\n        count += vpopc_v_u8m1(vmsne_vx_u8m1(filtered, 0, vl));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c\nint count_upper_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(32);\n    const unsigned char upper_vowels[4] = {'A', 'E', 'I', 'O'};\n    vuint8m1_t vowel_mask = vseqeq_b_m(vl, vle8_v_u8m1(upper_vowels, vl), vl, v\u52d2\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c\nint count_upper_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(32);\n    const unsigned char upper_vowels[4] = {'A', 'E', 'I', 'O'};\n    vuint8m1_t vowel_mask = vseqeq_b_m(vl, vle8_v_u8m1(upper_vowels, vl), vl, 4);\n\n    int count = 0;\n    for (size_t i = 0; i < s.size(); i += 32) {\n        vuint8m1_t chars = vle8_v_u8m1((const unsigned char*)s.c_str() + i, vl);\n        vboolm1_t even_mask = vmsne_vx_u8m1(chars, 0, vl);\n        vuint8m1_t filtered_chars = vmseq_vx_u8m1(chars, 0, vl);\n        vboolm1_t vowel_match = vmseq_b_m(vl, filtered_chars, vowel_mask, 4);\n        count += vpopc_v_u8m1(vmseq_b_m(vl, filtered_chars, vowel_match, 4));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_109_RVV", "completion": "```c\nint count_upper_simd(const std::string &s) {\n    const int vl = vsetvl_e8m1(32);\n    const unsigned char upper_vowels[4] = {'A', 'E', 'I', 'O'};\n    vuint8m1_t vowel_mask = vseqeq_b_m(vl, vle8_v_u8m1(upper_vowels, vl), vl, 4);\n    int count = 0;\n    for(int i=0; i<s.size(); i+=32){\n        vuint8m1_t chars = vle8_v_u8m1((const unsigned char*)&s[i], vl);\n        vboolm1_t even_mask = vmsne_vx_u8m1(chars, 0, vl);\n        vuint8m1_t even_chars = vmseq_vx_u8m1(chars, 0, even_mask, vl);\n        vboolm1_t vowel_even_mask = vmseq_vx_u8m1(even_chars, 0, vowel_mask, vl);\n        count += vpopc_m_u8m1(vmand_mm(vowel_even_mask, even_mask, vl));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    std::vector<int> result(n);\n    int8m8_t vec_n = vle8_v_i8m8(&n, 1);\n    int8m8_t ones = vsub_vx_i8m8(vadd_vx_i8m8(vec_n, 1, 8), 1, 8);\n    int8m8_t twos = vsub_vx_i8m8(vadd_vx_i8m8(vec_n, 2, 8), 2, 8);\n    int8m8_t odds = vadd_vx_i8m8(ones, 2, 8);\n    int8m8_t evens = vadd_vx_i8m8(twos, 2, 8);\n    int8m8_t result_vec = vselect_i8m8(vmsltu_vx_i8m8(vec_n, 0, 8), evens, odds);\n    vse8_v_i8m8(result.data(), result_vec, 8);\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int vl = vsetvl_e32m1(n);\n    std::vector<int> result(vl);\n    vint32m1_t vec_n = vle32_v_i32m1(&n, vl);\n    \n    vint32m1_t odd_mask = vmseq_v_i32m1(vec_n, vneg_v_i32m1(vec_n));\n    vint32m1_t next_odd = vmadd_v_i32m1(vec_n, odd_mask, vsub_v_i32m1(vec_n, odd_mask));\n    vint32m1_t next_even = vmadd_v_i32m1(vec_n, vnot_v_i32m1(odd_mask), vadd_v_i32m1(vec_n, vnot_v_i32m1(odd_mask)));\n    \n    vse32_v_i32m1(result.data(), vmseq_v_i32m1(vec_n, vsetvl_e32m1(1)) ? next_odd : next_even, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int vl = vsetvl_e32m1(n);\n    std::vector<int> result(vl);\n    vint32m1_t vec_n = vle32_v_i32m1(&n, 1);\n    \n    vint32m1_t odd_mask = vmseq_v_i32m1(vec_n, vnclip_w(1, vec_n, vl));\n    vint32m1_t next_odd = vadd_vx_i32m1(vec_n, 2, vl);\n    vint32m1_t next_even = vadd_vx_i32m1(vec_n, 1, vl);\n    \n    vint32m1_t next_numbers = vmsub_vv_i32m1(next_odd, odd_mask, next_even, vl);\n    \n    vse32_v_i32m1(result.data(), next_numbers, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int vl = vsetvl_e32m1(n);\n    std::vector<int> result(vl);\n    vint32m1_t vec_n = vle32_v_i32m1(&n, vl);\n    \n    vint32m1_t odd_mask = vmseq_v_i32m1(vec_n, vnclip_w_i32(vec_n, 1));\n    vint32m1_t next_odd = vnclip_w_i32(vec_n + 2, 1);\n    vint32m1_t next_even = vec_n + 2;\n    \n    vint32m1_t result_vec = vmsub_vv_i32m1(next_odd, odd_mask, next_even);\n    \n    vse32_v_i32m1(result.data(), result_vec, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_110_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> make_a_pile_simd(int n){\n    int vl = vsetvl_e32m1(n);\n    std::vector<int> result(vl);\n    vint32m1_t vec_n = vle32_v_i32m1(&n, vl);\n    \n    vint32m1_t odd_mask = vmseq_v_i32m1(vec_n, vnclip_w_i32m1(vec_n, 1));\n    vint32m1_t next_odd = vadd_vx_i32m1(vec_n, 2);\n    vint32m1_t next_even = vadd_vx_i32m1(vec_n, 1);\n    \n    vint32m1_t result_vec = vmsub_vv_i32m1(next_odd, odd_mask, next_even);\n    \n    vse32_v_i32m1(result.data(), result_vec, vl);\n    return result;\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64_t count = m - n + 1;\n    int64_t sum = 0;\n    \n    const int vl = vsetvl_e64m1(count);\n    int64_t vec_n[vl];\n    for(int i=0; i<vl; i++) {\n        vec_n[i] = n + i;\n    }\n    int64_t vec_sum[vl];\n    vint64m1_t vec_n_v = vloade64(vec_n, vl);\n    vint64m1_t vec_sum_v = vadd_vx_i64(vec_n_v, 0, vl);\n    vse64(vec_sum, vl, vec_sum_v);\n    \n    for(int i=0; i<vl; i++) {\n        sum += vec_sum[i];\n    }\n    \n    double avg = (double)sum / count;\n    int rounded_avg = std::floor(avg + 0.5);\n    \n    std::bitset<64> binary(rounded_avg);\n    return binary.to_string().substr(binary.to_string().length() - count, count);\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64_t length = m - n + 1;\n    int64_t sum = 0;\n\n    const int vl = vsetvl_e64m1(length);\n    int64_t vec_n[vl];\n    for(int i=0; i<length; i++) {\n        vec_n[i] = n + i;\n    }\n\n    vint64m1_t vec_n_v = vload_v_i64m1(vec_n, vl);\n    vint64m1_t vec_sum = vadd_vx_i64m1(vec_n_v, 0, vl);\n    sum = vsum_s_i64m1(vec_sum, vl);\n\n    int64_t avg = std::round(static_cast<double>(sum) / length);\n    std::bitset<64> binary(avg);\n    return binary.to_string().substr(binary.to_string().find('1'));\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64_t length = m - n + 1;\n    int64_t sum = 0;\n\n    const int vl = vsetvl_e64m1(length);\n    int64_t vec_n[vl];\n    for(int i=0; i<length; i++) {\n        vec_n[i] = n + i;\n    }\n    int64_t vec_sum[vl];\n    vint64m1_t vec_n_v = vloade64(vec_n, vl);\n    vint64m1_t vec_sum_v = vadd_vx(vec_n_v, 0, vl);\n    vse64(vec_sum, vl, vec_sum_v);\n\n    for(int i=0; i<vl; i++) {\n        sum += vec_sum[i];\n    }\n\n    int64_t average = round(static_cast<double>(sum) / length);\n    std::bitset<64> binary_avg(average);\n    return binary_avg.to_string().substr(binary_avg.to_string().find('1'));\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    int64_t length = m - n + 1;\n    int64_t sum = 0;\n    vint64_t vec_n = {n, n+1, n+2, n+3, n+4, n+5, n+6, n+7};\n    vint64_t vec_m = {m-7, m-6, m-5, m-4, m-3, m-2, m-1, m};\n    vint64_t vec_sum = vec_n + vec_m;\n    sum = vec_sum.reduce_sum();\n    if(length % 8 != 0){\n        int64_t remainder = m - (m % 8 + 1);\n        vint64_t vec_remain = {remainder+1, remainder+2, remainder+3, remainder+4, remainder+5, remainder+6, remainder+7, remainder+8};\n        vint64_t vec_remain_sum = vec_remain.reduce_sum();\n        sum += vec_remain_sum;\n    }\n    sum *= length / 8;\n    if(length % 8 != 0){\n        sum += (remainder + m) * (length % 8) / 2;\n    }\n    else{\n        sum /= 8;\n    }\n    int64_t avg = sum / length;\n    return std::bitset<64>(avg).to_string();\n}\n```"}
{"task_id": "SimdBench_111_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n#include <bitset>\n#include <string>\n\nstd::string rounded_avg_simd(int64_t n, int64_t m){\n    if(n > m){\n        return \"-1\";\n    }\n    \n    int64_t length = m - n + 1;\n    int64_t sum = 0;\n\n    const int vl = vsetvl_e64m1(length);\n    int64_t vec_n[vl];\n    for(int i=0; i<length; i++) {\n        vec_n[i] = n + i;\n    }\n    int64_t vec_sum[vl];\n    vint64m1_t vec_n_v = vloade64(vec_n, vl);\n    vint64m1_t vec_sum_v = vadd_vx(vec_n_v, 0, vl);\n    vse64(vec_sum, vl, vec_sum_v);\n\n    for(int i=0; i<vl; i++) {\n        sum += vec_sum[i];\n    }\n\n    int64_t avg = std::round(static_cast<double>(sum) / length);\n    std::bitset<64> binary(avg);\n    return binary.to_string().substr(64 - std::max(binary.count(), size_t(1)), 64);\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    int8mXf_t indices;\n    vint32mX_t fact_mod;\n    vint32mX_t sum;\n    vbool4_t mask;\n\n    // Initialize indices with values from 1 to n\n    indices = init_indices(n);\n\n    // Compute factorial mod 10000 for even indices\n    fact_mod = compute_factorial_mod(indices, 10000);\n\n    // Compute sum for odd indices\n    sum = compute_sum(indices);\n\n    // Combine results based on even/odd indices\n    result = combine_results(fact_mod, sum, indices);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    int8mXf_t indices;\n    vint32mX_t fact_mod;\n    vint32mX_t sum;\n    vbool4_t cond;\n\n    // Initialize indices with values from 1 to n\n    indices = vle32_v_i32mX(n, result.data(), 1);\n\n    // Compute factorial mod 10000 for even indices\n    fact_mod = vfsub_vx_i32mX(vfmul_vx_i32mX(vfsqrt_vx_i32mX(indices, 1), 1, 1), 10000, 1);\n\n    // Compute sum for odd indices\n    sum = vadd_vx_i32mX(indices, 1, 1);\n\n    // Select values based on condition (even or odd)\n    cond = vmslt_vx_u32mX(indices, 0, 1);\n    result = vmseq_vx_i32mX(fact_mod, sum, cond, 1);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    int8mXf_t indices;\n    vint32m1_t fact_mod, sum;\n    vbool4_t cond;\n\n    // Initialize indices\n    for(int i = 0; i < n; i++) {\n        indices[i] = i + 1;\n    }\n\n    // Compute factorial for even indices\n    fact_mod = vfadd_vx_vi(vfmul_vx(indices[0], indices[0], LMUL_1), 1, LMUL_1);\n\n    // Compute sum for odd indices\n    sum = vfadd_vx(indices[0], 1, LMUL_1);\n\n    // Combine results based on condition\n    for(int i = 0; i < n; i++) {\n        cond = vmslt_u_x_i(indices[i], 0, LMUL_1);\n        result[i] = vselect_i(fact_mod[i], sum[i], cond);\n    }\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    int8m1_t indices = vle8_v_i8m1(reinterpret_cast<const int8_t*>(result.data()), n);\n    int8m1_t evens = vmseq_v_i8m1(indices, 0, n);\n    int8m1_t odds = vmsne_v_i8m1(indices, 0, n);\n\n    // Factorial computation for even indices\n    int8m1_t fact_result = vsub_vx_i8m1(vsetvl_e8m1(n), 1);\n    int8m1_t fact_acc = vle8_v_i8m1(reinterpret_cast<const int8_t*>(&fact_result), n);\n    fact_acc = vset_v_i8m1(fact_acc, 1, 0);\n    for(int i=2; i<=n; i++){\n        fact_acc = vadd_vx_i8m1(fact_acc, i, n);\n        fact_acc = vse8_v_i8m1(reinterpret_cast<int8_t*>(&fact_result), fact_acc, n);\n    }\n    fact_result = vfredusum_vs_i8m1_i32(fact_result, fact_acc, 0, n);\n    fact_result = vmod_vx_i32(fact_result, 10000, n);\n\n    // Sum computation for odd indices\n    int8m1_t sum_result = vsub_vx_i8m1(vsetvl_e8m1(n), 1);\n    sum_result = vset_v_i8m1(sum_result, 0, 0);\n    for(int i=1; i<=n; i+=2){\n        sum_result = vadd_vx_i8m1(sum_result, i, n);\n    }\n    sum_result = vmod_vx_i32(sum_result, 10000, n);\n\n    // Combine results\n    int8m1_t final_result = vmux_vvv_i8m1(evens, fact_result, sum_result, n);\n    vse8_v_i8m1(reinterpret_cast<int8_t*>(result.data()), final_result, n);\n    return result;\n}\n```"}
{"task_id": "SimdBench_112_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> func_simd(int n){\n    std::vector<int> result(n);\n    int8mXf_t indices;\n    vint32mX_t fact_mod;\n    vint32mX_t sum;\n    vbool4_t mask;\n\n    // Initialize indices with values from 1 to n\n    indices = init_indices(n);\n\n    // Compute factorial mod 10000 for even indices\n    fact_mod = compute_factorial_mod(indices, 10000);\n\n    // Compute sum for odd indices\n    sum = compute_sum(indices);\n\n    // Combine results based on even/odd indices\n    result = combine_results(fact_mod, sum, indices);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    const int vl = vsetvl_e32m1(n);\n    int32_t evens[vl];\n    int32_t odds[vl];\n    vst1_v_i32(evens, vle32_v_i32((int32_t*)evens, vl), vl);\n    vst1_v_i32(odds, vle32_v_i32((int32_t*)odds, vl), vl);\n\n    for(int i=1; i<=n; i++){\n        int32_t num = i;\n        int32_t reversed = 0;\n        int32_t temp = num;\n        for(int d=0; d<10; d++){\n            reversed = reversed * 10 + (temp % 10);\n            temp /= 10;\n            if(temp == 0) break;\n        }\n        if(num == reversed){\n            vfloat32m1_t mask = vfloat32m1_t(v\u52d20);\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    const int vl = vsetvl_e32m1(n);\n    int32_t evens[vl];\n    int32_t odds[vl];\n    vst1_v_i32(evens, vle32_v_i32((int32_t*)evens, vl), vl);\n    vst1_v_i32(odds, vle32_v_i32((int32_t*)odds, vl), vl);\n\n    for(int i=1; i<=n; i++){\n        int32_t num = i;\n        int32_t reversed = 0;\n        int32_t temp = num;\n\n        for(int d=0; d<10; d++){\n            reversed = reversed * 10 + (temp % 10);\n            temp /= 10;\n            if(temp == 0) break;\n        }\n\n        if(num == reversed){\n            vfloat32m1_t mask = vseq_v_i32(vle32_v_i32((int32_t*)&i, vl), i, vl);\n            vint32m1_t index = vmseq_v_i32(mask, i, vl);\n            vint32m1_t even_mask = vand_v_i32(index, vintrin_even_parity(i), vl);\n            vint32m1_t odd_mask = vand_v_i32(index, vintrin_odd_parity(i), vl);\n\n            evens = veadd_v_i32(evens, even_mask, vl);\n            odds = veadd_v_i32(odds, odd_mask, vl);\n        }\n    }\n\n    int even_count = 0;\n    int odd_count = 0;\n    for(int j=0; j<vl; j++){\n        even_count += evens[j];\n        odd_count += odds[j];\n    }\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    const int vl = vsetvl_e32m1(n);\n    int32_t evens[vl];\n    int32_t odds[vl];\n    vst1_v_i32(evens, vle32_v_i32((int32_t*)evens, vl), vl);\n    vst1_v_i32(odds, vle32_v_i32((int32_t*)odds, vl), vl);\n\n    for(int i=1; i<=n; i++){\n        int32_t num = i;\n        int32_t reversed = 0;\n        int32_t temp = num;\n        for(int d=0; d<10; d++){\n            reversed = reversed * 10 + (temp % 10);\n            temp /= 10;\n            if(temp == 0) break;\n        }\n        if(num == reversed){\n            vfloat32m1_t mask = vseq_v_i32(vle32_v_i32(&i, vl), i, vl);\n            vint32m1_t index = vmseq_v_i32(mask, i, vl);\n            vint32m1_t even_check = vand_v_i32(index, vintrin_even_mask, vl);\n            vint32m1_t odd_check = vand_v_i32(index, vintrin_odd_mask, vl);\n            vse32_v_i32(evens, veadd_v_i32(vle32_v_i32(evens, vl), even_check, vl), vl);\n            vse32_v_i32(odds, veadd_v_i32(vle32_v_i32(odds, vl), odd_check, vl), vl);\n        }\n    }\n    int even_count = 0;\n    int odd_count = 0;\n    for(int j=0; j<vl; j++){\n        if(evens[j] > 0) even_count++;\n        if(odds[j] > 0) odd_count++;\n    }\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    const int vl = vsetvl_e32m1(n);\n    int32_t evens[vl];\n    int32_t odds[vl];\n    vmemset((uint8_t*)evens, 0, vl * sizeof(int32_t));\n    vmemset((uint8_t*)odds, 0, vl * sizeof(int32_t));\n\n    for(int i=1; i<=n; i++){\n        int32_t num = i;\n        int32_t reversed = 0;\n        int32_t temp = num;\n\n        // Reverse the digits of the number\n        while(temp != 0){\n            reversed = reversed * 10 + (temp % 10);\n            temp /= 10;\n        }\n\n        // Check if the number is a palindrome\n        if(num == reversed){\n            vfloat32m1_t mask = vseq_v_i32m1(reversed, i, vl);\n            vint32m1_t index = vmseq_v_i32m1(reversed, i, vl);\n            vint32m1_t even_mask = vand_v_i32m1(index, vle32_v_i32m1(&i, vl), vl);\n            vint32m1_t odd_mask = vor_v_i32m1(index, vle32_v_i32m1(&i, vl), vl);\n\n            vse32_v_i32m1(evens, veq_v_i32m1(even_mask, vle32_v_i32m1(&i, vl), vl), vl);\n            vse32_v_i32m1(odds, veq_v_i32m1(odd_mask, vle32_v_i32m1(&i, vl), vl), vl);\n        }\n    }\n\n    int even_count = vadd_v_i32m1(vle32_v_i32m1(evens, vl), vl);\n    int odd_count = vadd_v_i32m1(vle32_v_i32m1(odds, vl), vl);\n\n    return {even_count, odd_count};\n}\n```"}
{"task_id": "SimdBench_113_RVV", "completion": "```cpp\nstd::vector<int> even_odd_palindrome_simd(int n){\n    std::vector<int> result(2, 0);\n    vint32m1_t evens = vint32m1_zero();\n    vint32m1_t odds = vint32m1_zero();\n\n    for(int i = 1; i <= n; i++){\n        int num = i;\n        int original = num;\n        int reversed = 0;\n\n        // Reverse the number\n        while(num > 0){\n            reversed = reversed * 10 + (num % 10);\n            num /= 10;\n        }\n\n        // Check if it's a palindrome\n        if(original == reversed){\n            vint32m1_t temp = vint32m1_from_scalar(i);\n            vboolm1_t is_even = vmsltu_i32(temp, vint32m1_splat(2));\n            evens = vmerge_vxm(vint32m1_splat(1), evens, is_even);\n            odds = vmerge_vxm(vint32m1_splat(1), odds, vnot_b1(is_even));\n        }\n    }\n\n    result[0] = vsum_e32m1(evens);\n    result[1] = vsum_e32m1(odds);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\nint count_nums_simd(std::vector<int> n){\n    size_t vl = vsetvl_e32m1(n.size());\n    vint32m1_t nums = v\u52d2index>\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\nint count_nums_simd(std::vector<int> n){\n    size_t vl = vsetvl_e32m1(n.size());\n    vint32m1_t nums = v\u52d2\u6212(n.data(), vl, v\u52d2\u6212);\n    vboolm1_t mask = v\u52d2\u6212;\n    vint32m1_t sum_digits = v\u52d2\u6212;\n    for(int shift = 0; shift < 32; shift += 9){\n        vint32m1_t digits = v\u52d2\u6212(nums, shift, vl);\n        vboolm1_t positive = v\u52d2\u6212(digits, 0);\n        mask = v\u52d2\u6212(mask, positive);\n        sum_digits = v\u52d2\u6212(sum_digits, digits);\n    }\n    int result[1];\n    v\u52d2\u6212(sum_digits, result, vl);\n    return v\u52d2\u6212(result, mask, vl);\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\nint count_nums_simd(std::vector<int> n){\n    size_t vl = vsetvl_e32m1(n.size());\n    vint32m1_t nums = vfrom_int32m1(n.data(), vl);\n    vboolm1_t mask = v\u52d20m1(vle32(nums, vl));\n    vint32m1_t abs_nums = vabs_v_i32m1(nums);\n    vint32m1_t sum_digits;\n    v\u52d20m1(sum_digits);\n    for(int i=0;i<32;i++){\n        vboolm1_t mask_i = v\u52d20m1(vand_v_b8(vtob((1 << i)), mask));\n        if(!vmulred_b1(mask_i)) continue;\n        vint32m1_t digits = vlsr_v_i32m1(abs_nums, i);\n        digits = vor_v_i32m1(digits, vand_v_i32m1(abs_nums, vtob(0x0000000f)));\n        v\u52d20m1(sum_digits);\n        sum_digits = vadd_v_i32m1(sum_digits, digits);\n        mask_i = vmseq_v_i32m1_b1(sum_digits, vtob(0));\n        v\u52d20m1(sum_digits, mask_i);\n        mask = vmand_mm(mask, mask_i);\n    }\n    int count = 0;\n    for(int i=0;i<vl;i++) {\n        if(vmseq_v_i32m1_b1(vget_v_i32m1(sum_digits, i), vtob(0))) count++;\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\nint count_nums_simd(std::vector<int> n){\n    size_t vl = vsetvl_e32m1(n.size());\n    vint32m1_t nums = vfrom_int32m1(n.data(), vl);\n    vboolm1_t mask = v\u52d20m1(vle32(nums, vl));\n    vint32m1_t abs_nums = vabs_v_i32m1(nums);\n    vint32m1_t sum_digits;\n    v\u52d20m1(sum_digits);\n    for(int i=0;i<32;i++){\n        vboolm1_t mask_i = v\u52d20m1(vand_mask_i32m1(mask, vshr_v_i32m1(abs_nums, i, vl)));\n        vint32m1_t digits = vand_mask_i32m1(mask_i, vshr_v_i32m1(abs_nums, i, vl));\n        v\u52d2+=m1(sum_digits, digits);\n    }\n    vboolm1_t positive = v\u52d20m1(vgt_v_i32m1(sum_digits, v\u52d20m1(v\u52d20m1(v\u52d20m1(0, vl), vl), vl), vl));\n    return vpopc_m_b16m1(positive);\n}\n```"}
{"task_id": "SimdBench_114_RVV", "completion": "```c\nint count_nums_simd(std::vector<int> n){\n    size_t vl = vsetvl_e32m1(n.size());\n    vint32m1_t nums = v\u52d2\u6212(n.data(), vl, vl);\n    vboolm1_t mask = v\u52d2\u6212;\n    vint32m1_t sums = v\u52d2\u6212;\n    for(int shift = 0; shift < 32; shift += 4){\n        v\u52d2\u6212 = vshr_w_vx(nums, shift, vl);\n        v\u52d2\u6212 = vor_vv(mask, vand_vx(v\u52d2\u6212, 0xF), vl);\n        v\u52d2\u6212 = vmseq_vx(v\u52d2\u6212, 0, vl);\n        v\u52d2\u6212 = vsub_vx(v\u52d2\u6212, 0, vl);\n        sums = vadd_vv(sums, v\u52d2\u6212, vl);\n    }\n    vboolm1_t gt_zero = v\u52d2\u6212;\n    v\u52d2\u6212 = vmgt_vx(sums, 0, vl);\n    int count = v\u52d2\u6212;\n    return count;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    const int vl = vsetvl_e32m1(arr.size());\n    vint32m1_t vec = vloxei32(arr.data(), vl);\n    \n    // Find the maximum value in the vector\n    vint32m1_t max_val = vec;\n    for(int i=1; i<arr.size(); i++) {\n        vint32m1_t temp = vloxei32(arr.data() + i, vl);\n        max_val = vmax_vx(max_val, temp);\n    }\n    \n    // Check if the vector is already sorted\n    bool sorted = true;\n    for(int i=1; i<arr.size(); i++) {\n        if(vse32(vec[i]) > vse32(vec[i-1])) continue;\n        sorted = false;\n        break;\n    }\n    if(sorted) return true;\n    \n    // Check if there's exactly one point where the next element is smaller\n    int count = 0;\n    for(int i=1; i<arr.size(); i++) {\n        if(vse32(vec[i]) < vse32(vec[i-1])) {\n            count++;\n            if(count > 1) return false;\n        }\n    }\n    if(count == 0) return true;\n    \n    // Check if the last element is smaller than the first\n    if(vse32(vec[0]) > vse32(vec[arr.size()-1])) {\n        // Perform a right shift and check again\n        vint32m1_t shifted_vec = vslideup_vx(vec, vget_v_i32m1(vec[arr.size()-1]), vl);\n        bool shifted_sorted = true;\n        for(int i=1; i<arr.size(); i++) {\n            if(vse32(shifted_vec[i]) > vse32(shifted_vec[i-1])) continue;\n            shifted_sorted = false;\n            break;\n        }\n        if(shifted_sorted) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    const int vl = vsetvl_e32m1(arr.size());\n    vint32m1_t vec_arr = vloxei32(arr.data(), vl);\n    vint32m1_t sorted_vec = vec_arr;\n    vsort_v_i32m1(sorted_vec, vl);\n    \n    bool is_sorted = true;\n    for(int i = 0; i < vl; i++) {\n        if(vlse32(&sorted_vec, i*4) != vlsse32(arr.data(), i*4, vl)) {\n            is_sorted = false;\n            break;\n        }\n    }\n    \n    if(is_sorted) return true;\n    \n    for(int shift = 1; shift < arr.size(); shift++) {\n        vint32m1_t shifted_vec = vec_arr;\n        for(int i = 0; i < vl - 1; i++) {\n            vse32(&shifted_vec, i*4, vlsse32(vec_arr, (i+1)*4, vl));\n        }\n        vse32(&shifted_vec, (vl-1)*4, vlsse32(vec_arr, 0*4, vl));\n        \n        is_sorted = true;\n        for(int i = 0; i < vl; i++) {\n            if(vlse32(&shifted_vec, i*4) > vlsse32(shifted_vec, (i+1)*4, vl)) {\n                is_sorted = false;\n                break;\n            }\n        }\n        \n        if(is_sorted) return true;\n    }\n    \n    return false;\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    const int vl = vsetvl_e32m1(arr.size());\n    const int* data = arr.data();\n    vint32m1_t vec_arr = vloxei32(data, 0, vl);\n\n    // Find the pivot point where the array breaks the non-decreasing order\n    vboolm1_t break_point = vseqge_vv(vec_arr, vslideup_vx(vec_arr, 1, vl));\n    int count_breaks = vpopc_v_m(break_point, vl);\n\n    if (count_breaks <= 1) {\n        return true;\n    }\n\n    // Check if there's exactly one break and the array can be fixed with one shift\n    vint32m1_t shifted = vslide1ri_vx(vec_arr, -1, vl);\n    vboolm1_t is_sorted = viseq_vv(shifted, vslideup_vx(vec_arr, 1, vl));\n    return vall_m_b(is_sorted, vl);\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nbool move_one_ball_simd(std::vector<int> arr) {\n    const int vl = vsetvl_e32m1(arr.size());\n    vint32m1_t vec = vloxei32(arr.data(), vl);\n    \n    // Find the maximum value in the vector\n    vint32m1_t max_val = vec;\n    for(int i=1; i<arr.size(); i++) {\n        vint32m1_t temp = vloxei32(arr.data() + i, vl);\n        max_val = vmax_vx(max_val, temp);\n    }\n    \n    // Check if the vector is already sorted\n    vboolm1_t sorted = viseq_vx(vec, max_val);\n    if(vall_bm(sorted)) {\n        return true;\n    }\n    \n    // Check for exactly one break in the ascending order\n    vboolm1_t cond = vble_vx(vec, vslideup_vx(vec, 1, vl));\n    int breaks = vpopc_bm(cond);\n    \n    return (breaks == 1);\n}\n```"}
{"task_id": "SimdBench_115_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nbool move_one_ball_simd(std::vector<int> arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    vint32m1_t vec_arr = vloxei32(arr.data(), 0, vl);\n    \n    // Find the maximum value in the vector\n    vint32m1_t max_vec = vsub_vx(vec_arr, 1, vl); // Initialize with -1\n    vint32m1_t temp_vec = vec_arr;\n    for(int i=0; i<arr.size(); i++){\n        temp_vec = vsub_vx(temp_vec, 1, vl);\n        max_vec = vmax_vv(max_vec, temp_vec, vl);\n    }\n    int max_val = vget_v_i32(max_vec, 0);\n\n    // Check if the vector is already sorted\n    vint32m1_t sorted_check = vseqeq_vx(vec_arr, max_val, vl);\n    if(vmsum_uvm_b(sorted_check, 1, 0, vl)){\n        return true;\n    }\n\n    // Check for exactly one drop in sequence\n    vint32m1_t diff_vec = vsub_vv(vec_arr, vslideup_vx(vec_arr, 0, 1, vl), vl);\n    vint32m1_t drop_check = vmseq_vx(diff_vec, -1, vl);\n    int drop_count = vpopc_b_m(drop_check, vl);\n    if(drop_count == 1){\n        return true;\n    }\n\n    return false;\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    size_t len = lst1.size();\n    vint32m1_t vec1, vec2;\n    bool has_odd_in_lst1 = false;\n    bool has_even_in_lst2 = false;\n\n    for(size_t i=0; i<len; i+=16){\n        size_t chunk_size = (len - i >= 16) ? 16 : (len - i);\n        vbool16m1_t mask = v\u52d20000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    size_t len = lst1.size();\n    vint32m1_t vec1, vec2;\n    int count_odd = 0;\n\n    for(size_t i=0; i<len; i+=16){\n        size_t chunk_size = (len - i >= 16) ? 16 : (len - i);\n        vint32m1_t mask = vle32_v_i32m1(&lst1[i], chunk_size);\n        vec1 = mask;\n        mask = vle32_v_i32m1(&lst2[i], chunk_size);\n        vec2 = mask;\n\n        // Count odd numbers in lst1 and lst2\n        vboolm1_t odd_mask1 = vmslt_vx_i32m1(vec1, 0);\n        count_odd += vpopc_v_i32m1(odd_mask1);\n\n        vboolm1_t odd_mask2 = vmslt_vx_i32m1(vec2, 0);\n        count_odd -= vpopc_v_i32m1(odd_mask2);\n    }\n\n    return (count_odd <= 0) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    size_t len = lst1.size();\n    vint32m1_t vec1, vec2;\n    int count_odd1 = 0, count_odd2 = 0;\n\n    for(size_t i = 0; i < len; i += 8){\n        vint32m1_t mask1 = vle32_v_i32m1(lst1.data() + i, 8);\n        vint32m1_t mask2 = vle32_v_i32m1(lst2.data() + i, 8);\n\n        vec1 = vmseq_v_i32m1(mask1, 0, 8); // Check if elements are odd\n        vec2 = vmseq_v_i32m1(mask2, 0, 8);\n\n        count_odd1 += vpopc_v_i32m1(vec1);\n        count_odd2 += vpopc_v_i32m1(vec2);\n    }\n\n    if(count_odd1 <= count_odd2){\n        return \"YES\";\n    }\n    else{\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    size_t n = lst1.size();\n    vint32m1_t vec1, vec2;\n    int count_odd = 0;\n\n    for(size_t i=0; i<n; i+=16){\n        size_t len = (n - i >= 16) ? 16 : (n - i);\n        vint32m1_t mask = vle32_v_i32m1(&lst1[i], len);\n        vec1 = mask;\n        mask = vle32_v_i32m1(&lst2[i], len);\n        vec2 = mask;\n\n        // Check for odd numbers in lst1 and even numbers in lst2\n        vboolm1_t cond1 = vmslt_vx_i32m1(vec1, 0); // Odd numbers in lst1\n        vboolm1_t cond2 = vmsge_vx_i32m1(vec2, 0); // Even numbers in lst2\n\n        // Count how many such pairs exist\n        count_odd += vpopc_v_i32m1(vmand_mm(cond1, cond2));\n    }\n\n    return (count_odd >= __builtin_popcount((int)n)) ? \"YES\" : \"NO\";\n}\n```"}
{"task_id": "SimdBench_116_RVV", "completion": "```cpp\nstd::string myexchange_simd(const std::vector<int>& lst1, const std::vector<int>& lst2){\n    size_t n = lst1.size();\n    vint32m1_t vec1, vec2;\n    int count_odd1 = 0, count_odd2 = 0;\n\n    for(size_t i = 0; i < n; i += LMUL){\n        size_t lmul = get_vlmul();\n        size_t vl = vsetvl_e32m1(n - i);\n        vec1 = vle32_v_i32m1(&lst1[i], vl);\n        vec2 = vle32_v_i32m1(&lst2[i], vl);\n\n        vint32m1_t odd_mask1 = vmslt_vx_i32m1(vec1, 0, vl);\n        vint32m1_t odd_mask2 = vmslt_vx_i32m1(vec2, 0, vl);\n\n        count_odd1 += vpopc_m(vmsne_vx_i32m1(odd_mask1, 0, vl), vl);\n        count_odd2 += vpopc_m(vmsne_vx_i32m1(odd_mask2, 0, vl), vl);\n    }\n\n    if(count_odd1 <= count_odd2){\n        return \"YES\";\n    }\n    else{\n        return \"NO\";\n    }\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```c\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    const int vl = vsetvl_e8m1(lst.size());\n    uint8_t mask;\n    vuint8mf8x2_t odd_counts = vluxei8mf8x2((const char **)lst.data(), 0, vl);\n    vuint8mf8x2_t ones = vluxei8mf8x2((const char **)ones_data, 0, vl); // Assuming ones_data is preloaded with '1'\n    \n    vbool4_t cond;\n    vuint8mf8x2_t result = vluxei8mf8x2((const char **)result_data, 0, vl); // Assuming result_data is preloaded with template string\n    \n    for(int i=0; i<lst.size(); i+=vl){\n        vfredsum_vs_u8m1_u8m1(&odd_counts, &ones, &cond, vl);\n        vmseq_vx_u8m1(&cond, &odd_counts, 0, vl);\n        vse8mf8x2(result, &cond, vl);\n    }\n    \n    return result_data; // Assuming result_data is updated with final strings\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```c\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    const int vl = vsetvl_e8u(lst.size());\n    uint8_t input_lens[vl];\n    uint8_t odd_counts[vl];\n    \n    // Load input lengths\n    for(int i=0; i<lst.size(); i++) {\n        input_lens[i] = lst[i].size();\n    }\n    vuint8m1_t lens_vec = vload_v_u8m1(input_lens, vl);\n    \n    // Initialize odd counts\n    vuint8m1_t odd_vec = vsub_vx_u8m1(vuint8m1_t(), vl);\n    \n    for(int i=0; i<lst.size(); i++){\n        const std::string &s = lst[i];\n        for(char c : s){\n            if((c - '0') % 2 != 0){\n                odd_vec = vadd_vx_u8m1(odd_vec, 1);\n            }\n        }\n    }\n    \n    vse8_v_u8m1(odd_counts, odd_vec, vl);\n    \n    std::vector<std::string> result;\n    for(int i=0; i<lst.size(); i++){\n        char buf[64];\n        snprintf(buf, sizeof(buf), \"the number of odd elements %d in the string %d of the input.\", odd_counts[i], odd_counts[i]);\n        result.push_back(std::string(buf));\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    const int vl = vsetvl_e8u(lst.size());\n    uint8_t mask[vl];\n    for(int i=0; i<lst.size(); i++) {\n        mask[i] = 0;\n        for(char c : lst[i]) {\n            if((c - '0') % 2 != 0) {\n                mask[i]++;\n            }\n        }\n    }\n    std::vector<std::string> result(lst.size(), \"the number of odd elements _n the str_ng _ of the _nput.\");\n    for(int i=0; i<lst.size(); i++) {\n        char count_str[20];\n        snprintf(count_str, sizeof(count_str), \"%d\", mask[i]);\n        result[i][22] = count_str[0];\n        result[i][27] = count_str[0];\n        result[i][32] = count_str[0];\n        result[i][37] = count_str[0];\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n#include <string>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    const int vl = vsetvl_e8u(lst.size());\n    uint8_t v_mask[vl];\n    for(int i=0;i<vl;i++) v_mask[i] = (i < lst.size()) ? 1 : 0;\n    vuint8m1_t mask = vload_v_u8m1(v_mask, vl);\n    \n    vint8m1_t odd_counts = vsub_vx_i8m1(vmv_x_i8m1(0), vl);\n    \n    for(auto &s : lst){\n        vint8m1_t local_counts = vmv_x_i8m1(0);\n        for(char c : s){\n            int digit = c - '0';\n            vboolm1_t cond = (digit % 2 == 1);\n            local_counts = vadd_vv_i8m1(local_counts, vmsltu_vs_i8m1_i8m1(cond, digit, local_counts), mask);\n        }\n        odd_counts = vadd_vv_i8m1(odd_counts, local_counts, mask);\n    }\n    \n    std::vector<std::string> result(lst.size());\n    for(int i=0;i<lst.size();i++){\n        result[i] = \"the number of odd elements \" + std::to_string((int)vget_v_i8m1(odd_counts, i)) + \n                    \"n the str\" + std::to_string((int)vget_v_i8m1(odd_counts, i)) + \n                    \"ng \" + std::to_string((int)vget_v_i8m1(odd_counts, i)) + \n                    \" of the \" + std::to_string((int)vget_v_i8m1(odd_counts, i)) + \"nput.\";\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_117_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cstring>\n#include <cstdint>\n\nstd::vector<std::string> odd_count_simd(const std::vector<std::string> & lst){\n    size_t max_len = 0;\n    for(const auto & s : lst){\n        if(s.length() > max_len){\n            max_len = s.length();\n        }\n    }\n    const size_t vl = vsetvl_e8u(max_len);\n    uint8_t input[vl];\n    uint8_t mask[vl];\n    std::vector<std::string> result(lst.size());\n\n    for(size_t i = 0; i < lst.size(); i++){\n        memset(input, 0, sizeof(input));\n        memset(mask, 0, sizeof(mask));\n        const char * str = lst[i].c_str();\n        size_t len = lst[i].length();\n\n        for(size_t j = 0; j < len; j++){\n            input[j] = (str[j] - '0') % 2;\n        }\n\n        vuint8m1_t vec_input = vloade8u(input, vl);\n        vboolm1_t vec_mask = vmsne_vx_u8(vec_input, 0, vl);\n\n        uint8_t count = 0;\n        for(int k = 0; k < vl; k++){\n            if(vmask[k]){\n                count += vec_input[k];\n            }\n        }\n\n        char temp[64];\n        snprintf(temp, sizeof(temp), \"the number of odd elements %d in the string %d of the input.\", count, count);\n        result[i] = std::string(temp);\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    size_t vl = vsetvl_e64m1(nums.size());\n    vint64m1_t vec = v\u52d2\u5165_e64m1(nums.data(), vl);\n    int64_t min_sum = 0;\n    for(int i=0; i<nums.size(); i++){\n        vint64m1_t current = v\u52d2\u5165_e64m1(&nums[i], vl);\n        vint64m1_t sum = vadd_vx_e64m1(current, min_sum, vl);\n        min_sum = vmin_vx_e64m1(sum, min_sum, vl);\n    }\n    return min_sum;\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    size_t vl = vsetvl_e64m1(nums.size());\n    vint64m1_t vec_nums = v\u52d2index>\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    size_t vl = vsetvl_e64m1(nums.size());\n    vint64m1_t vec_nums = v\u52d2\u6212(nums.data(), vl);\n    vint64m1_t min_sum = v\u52d2\u6212(0);\n    for(int i=0; i<nums.size(); i+=vl){\n        vint64m1_t current = v\u52d2\u6212(&nums[i], vl);\n        vint64m1_t sums = vadd_vx(current, v\u52d2\u6212(0));\n        vint64m1_t temp_min = vmin_vx(sums, v\u52d2\u6212(0));\n        min_sum = vmin_vx(min_sum, temp_min);\n    }\n    return v\u52d2\u6212(min_sum);\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    size_t vl = vsetvl_e64m1(nums.size());\n    vint64m1_t vec = vle64_v_i64m1(nums.data(), vl);\n    vint64m1_t min_sum = vsub_vx_i64m1(vec, 0, vl);\n    \n    for(int i=1; i<nums.size(); ++i){\n        vint64m1_t current = vsub_vx_i64m1(vle64_v_i64m1(nums.data()+i, vl), 0, vl);\n        vint64m1_t temp = vmin_vv_i64m1(min_sum, current, vl);\n        min_sum = vmin_vx_i64m1(temp, vadd_vx_i64m1(min_sum, current, vl), vl);\n    }\n    \n    return vget_v_i64m1(min_sum, 0);\n}\n```"}
{"task_id": "SimdBench_118_RVV", "completion": "```c\nint64_t minSubArraySum_simd(const std::vector<int64_t>& nums){\n    size_t vl = vsetvl_e64m1(nums.size());\n    vint64m1_t vec = vle64_v_i64m1(nums.data(), vl);\n    vint64m1_t min_sum = vec;\n    for(int i=1; i<nums.size(); ++i){\n        vint64m1_t current = vsub_vx_i64m1(vec, i);\n        vint64m1_t temp = vmin_vv_i64m1(min_sum, current);\n        min_sum = vmin_vx_i64m1(temp, min_sum);\n    }\n    return vget_v_i64m1(min_sum, 0);\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```c\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity){\n    size_t rows = grid.size();\n    size_t cols = grid[0].size();\n    int total_trips = 0;\n    \n    for(size_t i=0; i<rows; i++){\n        const int* __restrict__ row = grid[i].data();\n        size_t j=0;\n        \n        while(j < cols){\n            size_t l = j;\n            size_t h = j + vlmax();\n            if(h > cols) h = cols;\n            \n            unsigned int vsegs[vlenb()/sizeof(unsigned int)];\n            vuint8m1_t v_row = vle8_v_u8m1(row+l, vlfrom(l));\n            \n            // Convert to sum of units\n            vuint8m1_t v_sum = vmseq_vx_u8m1(v_row, 1, vlfrom(l));\n            uint64_t sum = vmsum_u8m1_u64(v_sum, vsegs, vlfrom(l));\n            \n            int trips = (sum + capacity - 1) / capacity;\n            total_trips += trips;\n            \n            j = h;\n        }\n    }\n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```c\nint max_fill_simd(const std::vector<std::vector<int> > & grid,int capacity){\n    size_t rows = grid.size();\n    size_t cols = grid[0].size();\n    int total_trips = 0;\n    for(size_t i=0; i<rows; i++){\n        const int* __restrict__ row = grid[i].data();\n        size_t j=0;\n        while(j < cols){\n            size_t l = j;\n            size_t h = j + vlmax();\n            if(h > cols) h = cols;\n            uint8_t vmask[vlen/8];\n            for(int k=0; k<vlen/8; k++) vmask[k] = 0;\n            for(size_t k=l; k<h; k++) {\n                vmask[k-l] = (row[k] != 0);\n            }\n            size_t count = vpopc(vmask);\n            total_trips += ((count + capacity -1)/capacity);\n            j = h;\n        }\n    }\n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```c\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity) {\n    size_t rows = grid.size();\n    size_t cols = grid[0].size();\n    int total_trips = 0;\n\n    for (size_t i = 0; i < rows; i++) {\n        const int* __restrict__ row = grid[i].data();\n        size_t j = 0;\n        while (j < cols) {\n            size_t vl = vsetvl_e32m8(cols - j);\n            const int* restrict input = row + j;\n            vint32m8_t vec_in = vle32_v_i32m8(input, vl);\n            vint32m8_t vec_capacity = vfmv_s_x_i32m8(capacity, vl);\n            vbool4_t mask = vmseq_v_i32m8_i32(vec_in, vec_capacity, vl);\n            int count = vpopc_m_b4(mask);\n            total_trips += count;\n            j += vl;\n        }\n    }\n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```c\nint max_fill_simd(const std::vector<std::vector<int> > & grid,int capacity){\n    size_t rows = grid.size();\n    size_t cols = grid[0].size();\n    int total_trips = 0;\n    for(size_t i=0; i<rows; i++){\n        const int* __restrict__ row = grid[i].data();\n        size_t j=0;\n        while(j < cols){\n            size_t l = j;\n            size_t h = j + 8;\n            if(h > cols) h = cols;\n            uint8_t vmask[8] __attribute__((aligned(64)));\n            vbool8 mask = __rvv_vmsnevi_b8(vmask, 0, 0);\n            for(int k=0; k<8; k++) {\n                if(l+k >= cols) break;\n                mask = __rvv_vset_m_b8(mask, row[l+k], k+1);\n            }\n            size_t count;\n            __rvv_vfirst_m_b8(&count, mask);\n            total_trips += ((count + capacity -1)/capacity);\n            j += count;\n        }\n    }\n    return total_trips;\n}\n```"}
{"task_id": "SimdBench_119_RVV", "completion": "```c\nint max_fill_simd(const std::vector<std::vector<int> > & grid, int capacity){\n    size_t rows = grid.size();\n    size_t cols = grid[0].size();\n    int total_trips = 0;\n    for(size_t i=0; i<rows; i++){\n        const int* __restrict__ row = grid[i].data();\n        size_t j=0;\n        while(j < cols){\n            size_t l = j;\n            size_t h = j + 8;\n            if(h > cols) h = cols;\n            uint8_t vmask[8] __attribute__((aligned(64)));\n            vuint8mf8x2_t vec_mask;\n            vuint8mf8x2_t vec_row;\n            vbool16_t mask;\n            v\u52d2\u675f\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    size_t vl = vsetvl_e16m1(lst.size());\n    const int16_t* lst_data = lst.data();\n    vint16m1_t vec_lst = vle16_v_i16m1(lst_data, vl);\n    vbool16_t mask_even = vmsne_vx_i16m1(vec_lst, 0, vl);\n    vint16m1_t vec_odd = vmseq_vx_i16m1(vec_lst, 1, vl);\n    vbool16_t mask_odd_and_even = vmseq_vx_i16m1(vmslt_vx_i16m1(vec_lst, 0, vl), 0, vl);\n    vint16m1_t vec_filtered = vcompress_vx_i16m1(vec_odd, mask_odd_and_even, vl);\n    int16_t sum = 0;\n    for(int i=0; i<vl; i++) {\n        sum += vec_filtered[i];\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    size_t vl = vsetvl_e16m1(lst.size());\n    const int16_t* lst_data = lst.data();\n    vint16m1_t vec_lst = vle16_v_i16m1(lst_data, vl);\n    vbool16m1_t mask_odd = vbmsge_v_i16m1(vec_lst, vici16m1(1));\n    vbool16m1_t mask_even_idx = vbmsge_v_i16m1(vec_lst, vici16m1(0));\n    vbool16m1_t mask = vmseq_v_i16m1(mask_odd, mask_even_idx);\n    vint16m1_t vec_filtered = vcompress_v_i16m1(vec_lst, mask, vl);\n    vint16m1_t vec_odds = vmseq_v_i16m1(vec_filtered, vici16m1(1));\n    vint16m1_t vec_sum = vredsum_vs_i16m1_i16m1(vec_odds, vici16m1(0), vl);\n    return static_cast<int64_t>(vec_sum[0]);\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    size_t vl = vsetvl_e16m1(lst.size());\n    const int16_t* lst_data = lst.data();\n    vint16m1_t vec_lst = vle16_v_i16m1(lst_data, vl);\n    vbool16_t mask_even = vmsne_vx_i16m1(vec_lst, 0, vl);\n    vint16m1_t vec_even = vmseq_vx_i16m1(vec_lst, 0, vl);\n    vint16m1_t vec_odd = vmseq_vx_i16m1(vec_lst, 1, vl);\n    vint16m1_t vec_odd_in_even_pos = vmv_x_s_i16m1_m(mask_even, vec_odd, vl);\n    vint64m1_t vec_sum = vredsum_vs_i16m1_i64m1(vec_odd_in_even_pos, v\u52d20_i64m1(), vl);\n    return vget_v_i64m1(vec_sum, 0);\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    size_t vl = vsetvl_e16m1(lst.size());\n    const int16_t* lst_data = lst.data();\n    vint16m1_t vec_lst = vle16_v_i16m1(lst_data, vl);\n    vbool16_t mask_even = vbmsk_b16(1);\n    vint16m1_t vec_odd = vmseq_v_i16m1_i16(vec_lst, 1, mask_even);\n    vint16m1_t vec_filtered = vmslt_v_i16m1_i16(vec_odd, 0, mask_even);\n    vint16m1_t vec_sum = vredsum_vs_i16m1_i16m1(vec_filtered, vec_filtered, vl);\n    int64_t sum = vgetsum_s_i16m1(vec_sum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_120_RVV", "completion": "```c\nint64_t solution_simd(const std::vector<int16_t>& lst){\n    size_t vl = vsetvl_e16m1(lst.size());\n    const int16_t* lst_data = lst.data();\n    vint16m1_t vec_lst = vle16_v_i16m1(lst_data, vl);\n    vbool16m1_t mask_odd = vbmsge_v_i16m1(vec_lst, vici16m1(1));\n    vbool16m1_t mask_even_idx = vbmsge_v_i16m1(vec_lst, vici16m1(0));\n    vbool16m1_t mask = vmseq_v_i16m1(mask_odd, mask_even_idx);\n    vint16m1_t vec_filtered = vcompress_v_i16m1(vec_lst, mask, vl);\n    int16_t sum = 0;\n    for(int i=0; i<vl; i++){\n        sum += vec_filtered[i];\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\nint add_elements_simd(std::vector<int> arr, int k){\n    const int vl = vsetvl_e32m1(k);\n    const int thres = 100;\n    vint32m1_t vec_in = vle32_v_i32m1(arr.data(), vl);\n    vboolm1_t mask = vmseq_v_i32m1_i32(vmslt_v_i32m1_i32(vec_in, thres, vl), thres, vl);\n    vint32m1_t filtered = vcompress_v_b32(vec_in, mask, vl);\n    int sum = 0;\n    for(int i=0; i<vl; i++) {\n        if(vmvv_b32(mask, i)) {\n            sum += vfadd_s32m1_i32(filtered, i);\n        }\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\nint add_elements_simd(std::vector<int> arr, int k){\n    const int vl = vsetvl_e32m1(k);\n    const int16xm1_t mask = vmsne_vx_i16xm1(vluxei32_v_i16xm1(arr.data(), 0, vl), 100, vl);\n    const int16xm1_t values = vmseq_vx_i16xm1(vluxei32_v_i16xm1(arr.data(), 0, vl), 99, vl);\n    const int16xm1_t filtered = vmseq_vx_i16xm1(vmseq_vx_i16xm1(values, 10, vl), 9, vl);\n    const int16xm1_t masked_values = vmseq_vx_i16xm1(vmseq_vx_i16xm1(filtered, 1, vl), 0, vl);\n    const int16xm1_t masked_filtered = vmseq_vx_i16xm1(masked_values, 0, vl);\n    const int16xm1_t sum = vadd_vx_i16xm1(vmadd_vx_i16xm1(masked_filtered, 0, vl), 0, vl);\n    return vget_sum_i16xm1(sum);\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\nint add_elements_simd(std::vector<int> arr, int k){\n    const int vl = vsetvl_e32m1(k);\n    const int* data = arr.data();\n    vint32m1_t vec_sum = vint32m1_zero_m(vbool1_m(0));\n    vbool1_t mask = vbool1_m(vle1_v_i32m1(data, vl));\n\n    for(int i=0; i<k; i+=vl){\n        vint32m1_t vec_data = vle32_v_i32m1(data+i, vl);\n        vbool1_t mask_digits = vmseq_v_i32m1_i32(vec_data, 100);\n        vint32m1_t filtered = vmslt_v_i32m1_i32_mask(vec_data, 100, mask_digits);\n        vec_sum = vadd_v_i32m1(vec_sum, filtered);\n    }\n    return vsum_v_i32m1(vec_sum);\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```cpp\nint add_elements_simd(std::vector<int> arr, int k){\n    const int vl = vsetvl_e32m1(k);\n    const int* data = arr.data();\n    int sum = 0;\n    for(int i=0; i<k; i+=vl){\n        vint32m1_t vec = vle32_v_i32m1(data+i, vl);\n        vboolm1_t mask = vmseq_v_i32m1_i32(vmslt_v_i32m1_i32(vec, VSETVL_E32MH(100)), VSETVL_E32MH(-100));\n        vint32m1_t filtered = vcompress_v_b32(vec, mask, vl);\n        int local_sum = vsum_v_i32m1(filtered);\n        sum += local_sum;\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_121_RVV", "completion": "```c\nint add_elements_simd(std::vector<int> arr, int k){\n    const int vl = vsetvl_e32m1(k);\n    const int* data = arr.data();\n    int sum = 0;\n    vint32m1_t vec_sum = vint32m1_zero_m(vboolm1_t(), vl);\n\n    for(int i = 0; i < k; i += vl){\n        vint32m1_t vec = vle32_v_i32m1(data + i, vl);\n        vboolm1_t mask = vmseq_v_i32m1_i32(vmslt_v_i32m1_i32(vec, vint32m1_t(100)), vint32m1_t(-100), vl);\n        vec_sum = vadd_vv_i32m1(vec_sum, vec, vl);\n    }\n\n    sum = vorred_i32m1(vec_sum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t len = lst.size();\n    if (len <= 1) return true;\n\n    size_t vl = vsetvl_e32m1(len);\n    alignas(64) int data[32];\n    for (size_t i = 0; i < len; i++) {\n        data[i] = lst[i];\n    }\n\n    vint32m1_t vec = vle32_v_i32m1(data, vl);\n    vint32m1_t prev = vec;\n    vint32m1_t mask_eq = vseq_v_i32m1(vec, vsub_vx_i32m1(vec, 1), vl);\n    if (vmulred_x_u32(vmseq_v_i32m1(mask_eq, vl)) > 1) return false;\n\n    vint32m1_t mask_lt = vslt_v_i32m1(vec, vsub_vx_i32m1(vec, 1), vl);\n    if (!vmsumred_x_u32(mask_lt, vl)) {\n        vint32m1_t mask_gt = vsgt_v_i32m1(vec, vsub_vx_i32m1(vec, 1), vl);\n        return vmsumred_x_u32(mask_gt, vl) == vl - 1;\n    }\n    return false;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    alignas(64) int data[lst.size()];\n    memcpy(data, lst.data(), lst.size() * sizeof(int));\n    \n    vint32m1_t vec_data = vload_v_i32m1(data, vl);\n    vint32m1_t prev = vec_data;\n    vint32m1_t mask_dup = vseqeq_v_i32m1(prev, prev, vl);\n    if (vmulredsum_u32(mask_dup, vl) > 1) {\n        return false;\n    }\n    \n    vint32m1_t next = vslide1up_v_i32m1(vec_data, 0, vl);\n    vint32m1_t cmp = vmseq_v_i32m1(next, prev, vl);\n    if (vmulredsum_u32(cmp, vl)) {\n        return false;\n    }\n    \n    vint32m1_t gt = vmgt_v_i32m1(next, prev, vl);\n    if (vmulredsum_u32(gt, vl) != vl) {\n        return false;\n    }\n    \n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <stdalign.h>\n#include <cstdint>\n\nbool is_sorted_simd(const std::vector<int> &lst) {\n    const int vl = vsetvl_e32m1(lst.size());\n    alignas(64) int data[vl];\n    vint32m1_t vec = vle32_v_i32m1(lst.data(), vl);\n    \n    // Check for duplicates\n    vboolm1_t dup_mask = vmsne_vx_i32m1(vec, 0, vl);\n    for(int i=1; i<vl; i++) {\n        vboolm1_t eq_mask = vmseq_vx_i32m1(vget_v_i32m1(vec, i), vget_v_i32m1(vec, i-1), vl);\n        if(vmsum_vs_b_m1(dup_mask, eq_mask, dup_mask, vl)) {\n            return false;\n        }\n    }\n\n    // Check if sorted\n    vint32m1_t prev = vsub_vx_i32m1(vget_v_i32m1(vec, 0), 1);\n    for(int i=0; i<vl; i++) {\n        vint32m1_t curr = vget_v_i32m1(vec, i);\n        vboolm1_t gt_mask = vmgt_vx_i32m1(curr, prev, vl);\n        if(!vmsum_vs_b_m1(dup_mask, gt_mask, dup_mask, vl)) {\n            return false;\n        }\n        prev = curr;\n    }\n    return true;\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool is_sorted_simd(const std::vector<int> & lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    alignas(64) int data[lst.size()];\n    memcpy(data, lst.data(), lst.size() * sizeof(int));\n    \n    vint32m1_t vec_data = vloxei32(data, 0, vl);\n    vint32m1_t prev = vec_data;\n    vint32m1_t mask_dup = vseq_v_i32m1(vec_data, vle32_v_i32m1(&data[1], vl - 1), vl - 1);\n    \n    // Check duplicates\n    if (vmul_mask_i32m1(mask_dup, vl - 1)) {\n        return false;\n    }\n    \n    // Shift vector left by one\n    vint32m1_t shifted = vsrl_v_i32m1(vec_data, 1, vl);\n    \n    // Compare current with previous\n    vboolm1_t mask_order = vslt_v_i32m1(prev, shifted, vl);\n    \n    // Check if all elements are in order\n    return !vmul_mask_b8(mask_order, vl);\n}\n```"}
{"task_id": "SimdBench_122_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <stdalign.h>\n\nbool is_sorted_simd(const std::vector<int> & lst) {\n    size_t len = lst.size();\n    if (len <= 1) return true;\n\n    size_t vl = vsetvl_e32m1(len);\n    alignas(64) int data[32];\n    for (size_t i = 0; i < len; i++) {\n        data[i] = lst[i];\n    }\n\n    vint32m1_t vec = vle32_v_i32m1(data, vl);\n    vint32m1_t prev = vec;\n    vint32m1_t mask_eq = vor_segmv_i32m1(vec, prev, vl);\n\n    // Check duplicates\n    if (vmul_seg_v_i32m1(mask_eq, vl)) {\n        return false;\n    }\n\n    vint32m1_t mask_lt = vseqz_segmv_i32m1(vsub_seg_v_i32m1(vec, prev, vl), vl);\n    return vmul_seg_v_i32m1(mask_lt, vl);\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    size_t vl = vsetvl_e32m1(arr.size());\n    int32xm1_t vec_arr = vloxei32((const int32_t*)&arr[0], vl);\n    int32xm1_t signs = vsgnx_e32m1(vec_arr, 0);\n    int32xm1_t abs_vals = vfabs_vx(vec_arr, vl);\n    int32xm1_t sum_abs = vredsum_vs_e32m1(abs_vals, v\u52d2e32m1(0), vl);\n    int32xm1_t prod_sign = vredprod_vs_e32m1(signs, v\u52d2e32m1(1), vl);\n    \n    return vse32m1(sum_abs * prod_sign);\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    size_t len = arr.size();\n    int32xm1_t vec_arr;\n    int32xm1_t vec_signs;\n    int32xm1_t vec_mags;\n    int32xm1_t vec_sum = vsetvl_e32m1(0);\n    int32xm1_t vec_prod = vsetvl_e32m1(1);\n    \n    for(size_t i=0; i<len; i+=vsetvl_e32m1(len)){\n        size_t vl = vsetvl_e32m1(len - i);\n        vec_arr = vle32_v_i32m1(&arr[i], vl);\n        vec_signs = vmseq_vx_i32m1(vec_arr, 0, vl); // 1 if sign is zero\n        vec_signs = vmseq_vx_i32m1(vec_signs, -1, vl); // -1 if sign is negative\n        vec_signs = vmsub_vx_i32m1(vec_signs, 1, vl); // 1 if sign is positive\n        vec_mags = vmsltu_vx_i32m1(vec_arr, 0, vl); // Magnitude\n        vec_sum = vadd_vv_i32m1(vec_sum, vec_mags, vl);\n        vec_prod = vsmul_vx_i32m1(vec_prod, vec_signs, vl);\n    }\n    \n    int sum = vsum_v_i32m1(vec_sum);\n    int prod = vget_v_i32m1(vec_prod);\n    \n    return sum * prod;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    size_t len = arr.size();\n    int32xm1_t signs;\n    int32xm1_t magnitudes;\n    int32xm1_t ones = __riscv_vluxei32((const int32_t *)&arr[0], len, vl);\n    int32xm1_t mask = __riscv_vluxei32((const int32_t *)(&arr[0]), len, vl);\n    \n    signs = __riscv_vmsnevi_i32m1(ones, 0, vl);\n    magnitudes = __riscv_vmslevi_i32m1(ones, 0, vl);\n    \n    int32xm1_t sum_magnitudes = __riscv_vadd_sum_i32m1(magnitudes, vl);\n    int32xm1_t product_signs = __riscv_vreduce_sum_i32m1(signs, vl);\n    \n    return __riscv_vmv_x_i32m1(sum_magnitudes) * __riscv_vmv_x_i32m1(product_signs);\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    size_t vl = vsetvl_e32m1(arr.size());\n    int32xm1_t vec_arr = vloxei32((const int32_t*)&arr[0], arr.size(), vl);\n    int32xm1_t signs = vsgnx_e32m1(vec_arr, 31);\n    int32xm1_t abs_vals = vabsx_e32m1(vec_arr);\n    \n    int32xm1_t sign_product = vsetvl_e32m1(1);\n    sign_product = vmslx_vx_i32m1(sign_product, 1, vl);\n    \n    for(int i=0; i<vl; i++){\n        sign_product = vmslx_vx_i32m1(sign_product, vmsle_xm1_i32m1(signs, vget_v_i32m1(signs, i), vl), vl);\n    }\n    \n    int32xm1_t magnitude_sum = vfredusum_vs_e32m1_i32m1(abs_vals, vsetvl_e32m1(1), vl);\n    int sum = vget_v_i32(magnitude_sum) * vget_v_i32(sign_product);\n    \n    return sum;\n}\n```"}
{"task_id": "SimdBench_123_RVV", "completion": "```c\nint prod_signs_simd(const std::vector<int> & arr){\n    if(arr.empty()) return -32768;\n    \n    size_t vl = vsetvl_e32m1(arr.size());\n    int32xm1_t vec_arr = vloxei32((const int32_t*)&arr[0], vl);\n    int32xm1_t signs = vsgnx_e32m1(vec_arr, 0);\n    int32xm1_t abs_vals = vabsq_m_e32m1(signs, vec_arr);\n    int32xm1_t sum_mask = vmsne_vx_i32m1(signs, 0, vl);\n    int32xm1_t sum_vals = vmseq_vx_i32m1(signs, 1, vl);\n    int32xm1_t sum = vwmul_vv_i32m1(abs_vals, sum_vals, vl);\n    int result = vredsum_vs_i32m1_i32(sum, sum_mask, 0);\n    return result;\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_124_RVV", "completion": "```cpp\nstd::vector<int> minPath_simd(const std::vector<std::vector<int> > & grid, int k){\n    // Implementation using RVV intrinsics goes here\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n){\n    uint64_t mask = 0xAAAAAAAAAAAAAAAA; // Mask for even digits\n    vuint64m1_t vec_n;\n    vbool16_t mask_odd;\n    vuint64m1_t vec_product;\n    vuint64m1_t vec_masked;\n\n    // Load n into vector\n    vec_n = vle64_v_u64m1(&n, 1);\n\n    // Create a mask for odd digits using vector comparison\n    mask_odd = vmseq_v_i64m1(vec_n, vle64_v_i64m1((int64_t*)&mask, 1), vl);\n\n    // Apply mask to extract odd digits\n    vec_masked = vmslt_v_i64m1_i64m1(vec_n, vle64_v_i64m1((int64_t*)&mask, 1), vl);\n\n    // Compute product of odd digits using reduction\n    vec_product = vredsum_vs_u64m1_u64m1(vec_masked, vec_masked, v\u52d20m1_t(1), vl);\n\n    return vec_product;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n){\n    const uint64_t mask_even = 0xAAAAAAAAAAAAAAAA; // Mask for even digits\n    uint64_t prod = 1;\n    vbool16_t mask;\n    vuint64m1_t nums, evens;\n\n    // Convert the number to a vector of 64-bit elements\n    nums = vle64_v_u64((const uint64_t *)&n, 1);\n\n    // Check each digit for oddness and compute the product in parallel\n    for(int i = 0; i < 64; i += 8){\n        vmsne_vxm_b(mask, nums, 0, vlmax()); // Create a mask where digits are non-zero\n        evens = vmseq_vxm_u64(nums, mask_even, vlmax()); // Identify even digits\n        nums = vmand_vvm_u64(nums, vmsne_vxm_u64(evens, 0, vlmax()), vlmax()); // Keep only odd digits\n        prod *= vpopc_v_u64(nums, vlmax()); // Compute the product of odd digits\n    }\n\n    return prod;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n){\n    const uint64_t mask_even = 0xAAAAAAAAAAAAAAAA; // Mask for even digits\n    uint64_t mask_odd = ~mask_even;                // Mask for odd digits\n    uint64_t acc = 1;\n\n    vuint64m1_t vec_n;\n    vbool16_t mask;\n    vuint64m1_t vec_acc = vmv_x_v_u64m1(acc, LMUL_1);\n\n    while (n != 0) {\n        vec_n = vle64_v_u64m1((const uint64_t *)&n, LMUL_1);\n        mask = vmsne_vx_u64m1(vec_n, 0, LMUL_1); // Check non-zero elements\n        vec_acc = vmsltu_vx_u64m1(vec_acc, 0, LMUL_1); // Initialize with 1\n\n        vuint64m1_t vec_digits;\n        vec_digits = vand_vx_u64m1(vec_n, mask_odd, LMUL_1); // Extract odd digits\n\n        vbool16_t odd_mask = vor_seg_vx_u64m1(vec_digits, LMUL_1); // Create mask for odd digits\n        vec_acc = vwmul_vx_u64m1(vec_acc, vec_digits, LMUL_1); // Multiply odd digits\n\n        acc = vmv_x_v_u64m1(vec_acc, LMUL_1);\n        n = vcompress_vx_u64m1(vec_n, odd_mask, LMUL_1);\n    }\n\n    return acc;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t digits_simd(uint64_t n){\n    const uint64_t mask_even = 0xAAAAAAAAAAAAAAAA; // Mask for even digits\n    const uint64_t mask_odd  = 0x5555555555555555; // Mask for odd digits\n\n    vbool16_t mask;\n    vuint64m1_t nums;\n    vuint64m1_t odds;\n    vuint64m1_t evens;\n\n    nums = vle64_v_u64(&n, 1);\n    odds = vmseq_v_i64m1(nums, 1, vl1);\n    evens = vmseq_v_i64m1(vmslt_v_i64m1(nums, 0, vl1), 0, vl1);\n\n    vbool16_t odd_mask = vmand_vv_b16(odds, evens, vl1);\n    vint64m1_t prod = vmandnot_vv_i64m1(odds, evens, vl1);\n\n    while(vsetvl_e64m1(vl1)){\n        prod = vwmul_vx_i64m1(prod, prod, vl1);\n    }\n\n    uint64_t result;\n    vse64_v_u64(&result, prod, vl1);\n    return result;\n}\n```"}
{"task_id": "SimdBench_125_RVV", "completion": "```c\nuint64_t digits_simd(uint64_t n){\n    uint64_t mask = 0xAAAAAAAAAAAAAAAA; // Mask for even digits\n    vuint64m1_t vec_n;\n    vbool16_t mask_odd;\n    vuint64m1_t vec_product;\n    vuint64m1_t vec_masked;\n\n    // Load n into vector\n    vec_n = vle64_v_u64m1(&n, 1);\n\n    // Create a mask for odd digits\n    vec_masked = vmseq_v_i64m1(vec_n, 1, vl);\n\n    // Compute the product of odd digits\n    vec_product = vmsltu_v_i64m1(vec_n, 1, vl); // Initialize with 1s where odd\n    vec_product = vmseq_v_i64m1(vec_product, 1, vl); // Multiply by original values\n\n    // Reduce the vector to a single value\n    uint64_t product = vredsum_vs_u64m1_u64(vec_product, vec_product, 0, vl);\n\n    return product;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec_in = vle32_v_f32m1(lst.data(), vl);\n    float32xm1_t vec_rounded;\n    \n    // Perform ceiling operation\n    vec_rounded = vfrintx_m_f32m1(vec_in, v\u52d20m1(vtrue_m(vl)), vl);\n    \n    // Compute squares\n    float32xm1_t vec_squared = vmul_vf_f32m1(vec_rounded, vec_rounded, vl);\n    \n    // Reduce to sum\n    uint64xm1_t vec_sum = vredsum_vs_f32m1_u64m1(vec_squared, v\u52d20m1(0), vl);\n    \n    return vget_v_u64xm1(vec_sum, 0);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec_in;\n    float32xm1_t vec_rounded;\n    uint32xm1_t vec_squared;\n    uint64_t sum = 0;\n\n    for(size_t i = 0; i < lst.size(); i += vl){\n        vfloat32m1_load_mask(&vec_in, lst.data() + i, vl);\n        vec_rounded = vfrintx_r_asfloat32xm1(vec_in);\n        vec_squared = vmul_mask_u32(vec_rounded, vec_rounded, vl);\n        sum += vsumu_vec_u32xm1(vec_squared);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec = vle32_v_f32m1(lst.data(), vl);\n    float32xm1_t ceil_vec = vfrintx_m_f32m1(vec, v\u52d20m1(v\u52d2m1()), vl);\n    float32xm1_t sq_vec = vfmul_vf_f32m1(ceil_vec, 1.0f, vl);\n    uint64xm1_t sum_vec = vredsum_vs_u32m1_u32m1(v\u52d20m1(), sq_vec, vl);\n    return vget_v_u64m1(sum_vec, 0);\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec_in = vle32_v_f32m1(lst.data(), vl);\n    float32xm1_t vec_rounded;\n    \n    // Round up each element\n    vec_rounded = vfrintx_m_f32m1(vfrint_r_f32m1(vec_in), vec_in, vl);\n\n    // Compute squares\n    float32xm1_t vec_squared = vmul_vv_f32m1(vec_rounded, vec_rounded, vl);\n\n    // Sum all elements\n    uint64_t sum = vse32_v_u64m1(vmadd_sum_vf_f32m1(vec_squared, 0.0f, vl));\n\n    return sum;\n}\n```"}
{"task_id": "SimdBench_126_RVV", "completion": "```cpp\nuint64_t sum_squares_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec = vle32_v_f32m1(lst.data(), vl);\n    float32xm1_t rounded = vfrint_r_x_f32m1(vec, vl); // Round to upper int\n    float32xm1_t squared = vmul_vf_f32m1(rounded, rounded, vl);\n    uint64xm1_t sum = vredsum_vs_f32m1_u64m1(squared, v\u52d20m1_u64(0), vl);\n    return vget_v_u64xm1(sum, 0);\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c\nint can_arrange_simd(const std::vector<int> & arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    const int* arr_data = arr.data();\n    vint32m1_t vec_arr = vle32_v_i32m1(arr_data, vl);\n    vint32m1_t prev = vsub_vx_i32m1(vec_arr, 0, vl);\n    vbool32_t mask = vmseq_vx_i32m1(vec_arr, 0, vl);\n    int result = -1;\n    for(int i=1; i<arr.size(); i++){\n        vint32m1_t current = vle32_v_i32m1(arr_data + i, vl - i);\n        vint32m1_t cmp = vmge_vx_i32m1(current, prev, vl - i);\n        if(vmsum_vs_b32m1_i32m1(&mask, cmp, &mask, vl - i)){\n            result = i - 1;\n            break;\n        }\n        prev = current;\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c\nint can_arrange_simd(const std::vector<int> & arr){\n    size_t vl = vsetvl_e32m1(arr.size());\n    const int* arr_data = arr.data();\n    vint32m1_t vec_arr = vle32_v_i32m1(arr_data, vl);\n    \n    vbool32m1_t mask = vseqge_vv_b32m1(vec_arr, vec_arr, vl);\n    int result = -1;\n    \n    for(int i=1; i<arr.size(); i++){\n        if(!vmseq_vx_b32m1(mask, vec_arr, i, vl)){\n            result = i;\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c\nint can_arrange_simd(const std::vector<int> & arr){\n    size_t vl = vsetvl_e32m1(arr.size());\n    const int *arr_data = arr.data();\n    vint32m1_t vec_arr = vle32_v_i32m1(arr_data, vl);\n    vint32m1_t prev = vsub_vx_i32m1(vec_arr, 0, vl);\n    vbool32_t mask = vseq_v_i32m1_i32m1(vec_arr, prev, vl);\n    int result = -1;\n    for(int i=0; i<vl; i++){\n        if(vmseq_v_i32m1_b32(mask, i)){\n            result = i;\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c\nint can_arrange_simd(const std::vector<int> & arr){\n    const int vl = vsetvl_e32m1(arr.size());\n    const int* arr_data = arr.data();\n    vint32m1_t vec_arr = vle32_v_i32m1(arr_data, vl);\n    vint32m1_t prev = vsub_vx_i32m1(vec_arr, 0, vl);\n    vbool32_t mask = vslt_vv_i32m1(vec_arr, prev, vl);\n    int result = -1;\n    for(int i=0; i<vl; i++){\n        if(vmseq_vx_mask(mask, i)){\n            result = i;\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_127_RVV", "completion": "```c\nint can_arrange_simd(const std::vector<int> & arr){\n    size_t vl = vsetvl_e32m1(arr.size());\n    vint32m1_t vec = vle32_v_i32m1(arr.data(), vl);\n    vint32m1_t prev = vsub_vx_i32m1(vec, 0, vl);\n    vbool32m1_t mask = vslt_vx_i32m1(vec, prev, vl);\n    int result = -1;\n    for(int i=0; i<vl; i++){\n        if(vmseq_vx_mask(mask, i)){\n            result = i;\n            break;\n        }\n    }\n    return result;\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    const int8_t zero = 0;\n    vint32m1_t neg_max_vec = v\u52d2\u96f7\u59c632m1(0);\n    vint32m1_t pos_min_vec = v\u52d2\u96f7\u59c632m1(0);\n\n    for(int i=0;i<lst.size();i+=vl){\n        vint32m1_t input_vec = v\u52d2\u96f7\u59c632m1_from_ptr(&lst[i], vl);\n        vboolm1_t neg_mask = v\u52d2\u96f7\u59c632m1_lt(input_vec, zero);\n        vboolm1_t pos_mask = v\u52d2\u96f7\u59c632m1_ge(input_vec, zero);\n\n        vint32m1_t neg_candidates = vmseq_vim(neg_mask, input_vec, zero);\n        vint32m1_t pos_candidates = vmseq_vim(pos_mask, input_vec, zero);\n\n        neg_max_vec = v\u52d2\u96f7\u59c632m1_max(neg_max_vec, neg_candidates);\n        pos_min_vec = v\u52d2\u96f7\u59c632m1_min(pos_min_vec, pos_candidates);\n    }\n\n    int neg_max = v\u52d2\u96f7\u59c632m1_to_x(neg_max_vec);\n    int pos_min = v\u52d2\u96f7\u59c632m1_to_x(pos_min_vec);\n\n    return {neg_max, pos_min};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    const int8_t zero = 0;\n    vint32m1_t neg_max_vec = v\u52d200000000000000000000000000000000"}
{"task_id": "SimdBench_128_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    const int8_t zero = 0;\n    vint32m1_t neg_max_vec = v\u52d200000000000000000000000000000000"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    const int8_t zero = 0;\n    vint32m1_t neg_max_vec = v\u52d2\u96f7\u59c632m1(0);\n    vint32m1_t pos_min_vec = v\u52d2\u96f7\u59c632m1(0);\n\n    for(int i=0;i<lst.size();i+=vl){\n        vint32m1_t input_vec = v\u52d2\u96f7\u59c632m1_from_ptr(lst.data()+i);\n        vbool32_t mask_neg = v\u52d2\u96f7\u59c632m1_lt(input_vec, zero);\n        vbool32_t mask_pos = v\u52d2\u96f7\u59c632m1_ge(input_vec, zero);\n\n        vint32m1_t neg_candidates = vmseq_v_i32m1(input_vec, input_vec, mask_neg);\n        vint32m1_t pos_candidates = vmseq_v_i32m1(input_vec, input_vec, mask_pos);\n\n        neg_max_vec = v\u52d2\u96f7\u59c632m1_max(neg_max_vec, neg_candidates);\n        pos_min_vec = v\u52d2\u96f7\u59c632m1_min(pos_min_vec, pos_candidates);\n    }\n\n    int neg_max = v\u52d2\u96f7\u59c632m1_to_i32(neg_max_vec);\n    int pos_min = v\u52d2\u96f7\u59c632m1_to_i32(pos_min_vec);\n\n    if(neg_max == 0 && pos_min == 0){\n        return {0,0};\n    }\n    return {neg_max, pos_min};\n}\n```"}
{"task_id": "SimdBench_128_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> largest_smallest_integers_simd(const std::vector<int>& lst){\n    const int vl = vsetvl_e32m1(lst.size());\n    const int8_t zero = 0;\n    vint32m1_t neg_max_vec = v\u52d2\u96f7\u59c632m1(0);\n    vint32m1_t pos_min_vec = v\u52d2\u96f7\u59c632m1(0);\n\n    for(int i=0; i<lst.size(); i+=vl){\n        vint32m1_t input_vec = v\u52d2\u96f7\u59c632m1_from_ptr(&lst[i], vl);\n        vbool32m1_t neg_mask = v\u52d2\u96f7\u59c632m1_lt(input_vec, zero);\n        vbool32m1_t pos_mask = v\u52d2\u96f7\u59c632m1_ge(input_vec, zero);\n\n        vint32m1_t neg_candidates = vmseq_vim(neg_mask, input_vec, zero);\n        vint32m1_t pos_candidates = vmseq_vim(pos_mask, input_vec, zero);\n\n        neg_max_vec = v\u52d2\u96f7\u59c632m1_max(neg_max_vec, neg_candidates);\n        pos_min_vec = v\u52d2\u96f7\u59c632m1_min(pos_min_vec, pos_candidates);\n    }\n\n    int neg_max = v\u52d2\u96f7\u59c632m1_to_x(neg_max_vec);\n    int pos_min = v\u52d2\u96f7\u59c632m1_to_x(pos_min_vec);\n\n    return {neg_max, pos_min};\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n){\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vec_n = vle64_v_u64m1(&n, vl);\n    vuint64m1_t result = vsub_vx_u64m1(vec_n, 1, vl);\n    for(int i=0; i<n-1; i++){\n        result = vmul_vx_u64m1(result, result, vl);\n        result = vsub_vx_u64m1(result, 1, vl);\n    }\n    uint64_t final_result;\n    vse64_v_u64m1(&final_result, result, vl);\n    return final_result;\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n){\n    vint64m1_t vec_n = {n};\n    vint64m1_t vec_result = {1};\n    vbool16m1_t mask = __riscv_vsetvl_e64m1(1);\n\n    for(int i = n; i > 0; i--){\n        vint64m1_t vec_i = {i};\n        vint64m1_t vec_fact = {1};\n        vint64m1_t vec_temp = {1};\n\n        // Compute factorial in parallel\n        for(int j = i; j > 1; j--){\n            __riscv_vmadc_vim(vec_temp, vec_temp, j, mask);\n        }\n        vec_fact = vec_temp;\n\n        __riscv_vmadc_vim(vec_result, vec_result, vec_fact, mask);\n    }\n\n    return __riscv_vget_vx_u64(vec_result, 0);\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n){\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vec_n = vle64_v_u64m1(&n, vl);\n    vuint64m1_t result = vle64_v_u64m1((const uint64_t *) &n, vl);\n    \n    for(int i = 1; i < n; i++){\n        uint64_t current = i;\n        vuint64m1_t vec_current = vle64_v_u64m1(&current, vl);\n        result = vmul_vx_u64m1(result, current, vl);\n    }\n    \n    return vse64_v_u64m1(result, vl);\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n){\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vec_result = v\u52d20m1(0);\n    for(int i = 1; i <= n; i++){\n        vuint64m1_t vec_i = v\u52d20m1(i);\n        vuint64m1_t vec_fact = v\u52d20m1(1);\n        for(int j = 1; j <= i; j++){\n            vec_fact = v\u52d20m1(vec_fact * j);\n        }\n        vec_result = v\u52d20m1(vec_result * vec_fact);\n    }\n    return v\u52d20m1(vec_result);\n}\n```"}
{"task_id": "SimdBench_129_RVV", "completion": "```c\nuint64_t special_factorial_simd(uint64_t n){\n    size_t vl = vsetvl_e64m1(n);\n    vuint64m1_t vec_n = vle64_v_u64m1(&n, vl);\n    vuint64m1_t result = vmseq_vx_u64m1(vec_n, 1, vl);\n\n    for(int i = n-1; i >=1; i--){\n        uint64_t val = i;\n        vuint64m1_t vec_val = vle64_v_u64m1(&val, vl);\n        vuint64m1_t fact = vmul_vv_u64m1(result, vec_val, vl);\n        result = fact;\n    }\n\n    return vget_v_u64(result, 0);\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```c\nint sum_squares_simd(const std::vector<int> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const int* lst_data = lst.data();\n    int sum = 0;\n    vint32m1_t vec_sum = vint32m1_zero();\n\n    for(size_t i=0; i<lst.size(); i+=vl){\n        vint32m1_t vec_in = vle32_v_i32m1(&lst_data[i], vl);\n        vboolm1_t mask_mul3 = vmsltu_mask_i32(vle32_v_i32m1(&i, vl), vl, 3);\n        vboolm1_t mask_mul4 = vmsltu_mask_i32(vle32_v_i32m1(&i, vl), vl, 4);\n        vboolm1_t mask_mul3_and_not4 = vmseq_mask_i32(vmseq_mask_i32(mask_mul3, mask_mul4, vl), mask_mul4, vl);\n\n        // Square elements where index is a multiple of 3\n        vint32m1_t vec_squared = vmul_vx_i32(vec_in, vec_in, mask_mul3);\n        \n        // Cube elements where index is a multiple of 4 but not 3\n        vint32m1_t vec_cubed = vmul_vx_i32(vmuls_vx_i32(vec_in, vec_in, mask_mul3_and_not4), vec_in, mask_mul3_and_not4);\n        \n        // Add squared and cubed vectors\n        vec_sum = vadd_vx_i32(vec_sum, vec_squared, vl);\n        vec_sum = vadd_vx_i32(vec_sum, vec_cubed, vl);\n    }\n\n    sum = vsum_v_i32(vec_sum);\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```c\nint sum_squares_simd(const std::vector<int> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const int* lst_data = lst.data();\n    int sum = 0;\n    for(int i=0; i<lst.size(); i+=vl){\n        vint32m1_t vec = vle32_v_i32m1(lst_data + i, vl);\n        vboolm1_t mask3 = vmsne_vx_i32m1(vluxei32_v_i32m1(vec, i*4, vl), 0, vl);\n        vboolm1_t mask4 = vmsne_vx_i32m1(vluxxi32_v_i32m1(vec, i*4, vl), 0, vl);\n        vint32m1_t res3 = vmseq_vx_i32m1(vec, i*3, vl) ? vmsq_v_i32m1(vec) : vec;\n        vint32m1_t res4 = vmseq_vx_i32m1(vec, i*4, vl) ? vmpow_v_i32m1(vec, 3) : res3;\n        sum += vse32_v_i32m1(res4, vl);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```c\nint sum_squares_simd(const std::vector<int> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const int* lst_data = lst.data();\n    int sum = 0;\n    for(int i=0; i<lst.size(); i+=vl){\n        vint32m1_t vec = vle32_v_i32m1(lst_data + i, vl);\n        vboolm1_t mask1 = vmseq_v_i32m1_i32(vmsum_v_i32m1_i32(vec, vcreate_i32m1(3)), vcreate_i32m1(0));\n        vboolm1_t mask2 = vmseq_v_i32m1_i32(vmsum_v_i32m1_i32(vec, vcreate_i32m1(4)), vcreate_i32m1(0));\n        vint32m1_t res1 = vmseq_v_i32m1_i32(vmsum_v_i32m1_i32(vec, vcreate_i32m1(3)), vcreate_i32m1(0)) ? vsmul_vx_i32m1(vec, vec) : vec;\n        vint32m1_t res2 = vmseq_v_i32m1_i32(vmsum_v_i32m1_i32(vec, vcreate_i32m1(4)), vcreate_i32m1(0)) ? vsmul_vx_i32m1(vec, vsmul_vx_i32m1(vec, vec)) : res1;\n        sum += vse32_v_i32m1(res2, vl);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```c\nint sum_squares_simd(const std::vector<int> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const int* lst_data = lst.data();\n    int sum = 0;\n    for(int i=0; i<lst.size(); i+=vl){\n        vint32m1_t vec = vle32_v_i32m1(lst_data + i, vl);\n        vboolm1_t mask1 = vmsltu_vx_i32m1(vsub_vx_i32m1(vec, vcreate_i32m1(i)), 3);\n        vboolm1_t mask2 = vmsltu_vx_i32m1(vsub_vx_i32m1(vec, vcreate_i32m1(i)), 4);\n        vint32m1_t squared = vmul_vx_i32m1(vec, vec, mask1);\n        vint32m1_t cubed = vmul_vx_i32m1(vmuls_vx_i32m1(vec, vec, vec), vec, mask2 & !mask1);\n        sum += vse32_v_i32m1(squared, vl);\n        sum += vse32_v_i32m1(cubed, vl);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_130_RVV", "completion": "```cpp\nint sum_squares_simd(const std::vector<int> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const int* lst_data = lst.data();\n    int sum = 0;\n    for(int i=0; i<lst.size(); i+=vl){\n        vint32m1_t vec = vle32_v_i32m1(lst_data + i, vl);\n        vboolm1_t mask1 = vmsltu_vx_i32m1(vi32m1_from_idx(i), vl, 3);\n        vboolm1_t mask2 = vmsltu_vx_i32m1(vi32m1_from_idx(i), vl, 4);\n        vboolm1_t mask3 = vmseq_vx_i32m1(vi32m1_from_idx(i), vl, 3);\n        \n        // Square if index is multiple of 3\n        vint32m1_t squared = vmul_vx_i32m1(vec, vec, vmv_x_b32m1(mask1 & ~mask3));\n        \n        // Cube if index is multiple of 4 and not 3\n        vint32m1_t cubed = vmul_vx_i32m1(vec, vmul_vx_i32m1(vec, vec, vmv_x_b32m1(mask2 & ~mask1)), vmv_x_b32m1(mask2 & ~mask3));\n        \n        // Sum the results\n        sum += vse32_v_i32m1(squared + cubed, vl);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c\nint specialFilter_simd(const std::vector<int> & nums){\n    size_t vl = vsetvl_e32m1(nums.size());\n    const int *nums_ptr = nums.data();\n    int count = 0;\n    for(int i=0; i<nums.size(); i+=vl){\n        vint32m1_t vec_nums = vle32_v_i32m1(nums_ptr + i, vl);\n        vboolm1_t mask_gt_10 = vmgt_v_i32m1(vec_nums, vmslt_i32m1(10));\n        vint32m1_t vec_abs = vabs_v_i32m1(vec_nums);\n        vint32m1_t vec_first_digit = vfwmul_v_i32m1(vec_abs, vmslt_i32m1(0.1));\n        vint32m1_t vec_last_digit = vfredsum_vs_i32m1_i32m1(vec_abs, vmslt_i32m1(1), vl);\n        vboolm1_t mask_odd = vmseq_v_i32m1(vec_first_digit, vmslt_i32m1(1))\n                           | vmseq_v_i32m1(vec_first_digit, vmslt_i32m1(3))\n                           | vmseq_v_i32m1(vec_first_digit, vmslt_i32m1(5))\n                           | vmseq_v_i32m1(vec_first_digit, vmslt_i32m1(7))\n                           | vmseq_v_i32m1(vec_first_digit, vmslt_i32m1(9));\n        vboolm1_t final_mask = vmseq_v_i32m1(vec_last_digit, vmslt_i32m1(1))\n                             | vmseq_v_i32m1(vec_last_digit, vmslt_i32m1(3))\n                             | vmseq_v_i32m1(vec_last_digit, vmslt_i32m1(5))\n                             | vmseq_v_i32m1(vec_last_digit, vmslt_i32m1(7))\n                             | vmseq_v_i32m1(vec_last_digit, vmslt_i32m1(9));\n        count += vpopc_v_i32m1(vmand_mm(mask_gt_10, vmand_mm(mask_odd, final_mask)));\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c\nint specialFilter_simd(const std::vector<int> & nums){\n    size_t vl = vsetvl_e32m1(nums.size());\n    const int *nums_ptr = nums.data();\n    int count = 0;\n    for(int i=0; i<nums.size(); i+=vl){\n        vint32m1_t vec_nums = vle32_v_i32m1(nums_ptr + i, vl);\n        vboolm1_t mask_gt10 = vgts_v_i32m1(vec_nums, vint32m1_t(10));\n        vint32m1_t vec_abs = vabs_v_i32m1(vec_nums);\n        vint32m1_t vec_first_digit = vfwmul_v_i32m1(vec_abs, vint32m1_t(0.1f), vl);\n        vint32m1_t vec_last_digit = vfredsum_vs_i32m1_i32m1(vec_abs, vint32m1_t(1), vl);\n        vboolm1_t mask_odd = vor_vv_b_m(vbge_v_i32m1(vec_first_digit, vint32m1_t(1)),\n                                        vbge_v_i32m1(vec_first_digit, vint32m1_t(9)), vl);\n        mask_odd = vor_vv_b_m(mask_odd,\n                              vor_vv_b_m(vbge_v_i32m1(vec_last_digit, vint32m1_t(1)),\n                                         vbge_v_i32m1(vec_last_digit, vint32m1_t(9)), vl), vl);\n        vboolm1_t final_mask = vmand_mm(mask_gt10, mask_odd, vl);\n        count += vpopc_v_i32m1(final_mask);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c\nint specialFilter_simd(const std::vector<int> & nums){\n    size_t vl = vsetvl_e32m1(nums.size());\n    const int16_t *nums_ptr = reinterpret_cast<const int16_t*>(nums.data());\n    vint16m1_t vec_nums = vle16_v_i16m1(nums_ptr, vl);\n    \n    vbool16_t mask_gt10 = vreinterpret_v_b16m1(vluxei16_v_i16m1(vec_nums, 0, vl, v\u52d216m1));\n    vint16m1_t vec_gt10 = vmseq_v_i16m1_i16(vec_nums, 10, vl);\n    \n    return 0;\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c\nint specialFilter_simd(const std::vector<int> & nums){\n    size_t vl = vsetvl_e32m1(nums.size());\n    const int16_t *nums_ptr = reinterpret_cast<const int16_t*>(nums.data());\n    vint16m1_t vec_nums = vle16_v_i16m1(nums_ptr, vl);\n    \n    vbool16_t mask_gt10 = vreinterpret_v_b16m1(vluxei16_v_i16m1(vec_nums, 0, vl, v\u52d216m1));\n    vint16m1_t vec_abs = vabs_v_i16m1(vec_nums);\n    \n    // Extract first digit\n    vint16m1_t first_digit = vfadd_vx_i16m1(vec_abs, 0, vl);\n    first_digit = vand_vx_i16m1(first_digit, 0xF, vl);\n    \n    // Extract last digit\n    vint16m1_t last_digit = vfsub_vx_i16m1(vec_abs, 0, vl);\n    last_digit = vand_vx_i16m1(last_digit, 0xF, vl);\n    \n    vbool16_t mask_first_odd = vmslt_vx_b16m1(first_digit, 5, vl);\n    vbool16_t mask_last_odd = vmslt_vx_b16m1(last_digit, 5, vl);\n    \n    vbool16_t mask_all = vmseq_vx_b16m1(vec_abs, 10, vl);\n    mask_all = vmseq_vx_b16m1(mask_all, 1, vl);\n    \n    vbool16_t final_mask = vmseq_vx_b16m1(vec_abs, 10, vl);\n    final_mask = vmseq_vx_b16m1(final_mask, 1, vl);\n    \n    return vpopc_b16m1(final_mask);\n}\n```"}
{"task_id": "SimdBench_131_RVV", "completion": "```c\nint specialFilter_simd(const std::vector<int> & nums){\n    size_t vl = vsetvl_e32m1(nums.size());\n    const int16_t *nums_ptr = reinterpret_cast<const int16_t*>(nums.data());\n    vint16m1_t vec_nums = vle16_v_i16m1(nums_ptr, vl);\n    \n    vbool16_t mask_gt10 = vreinterpret_v_b16m1(vluxei16_v_i16m1(vec_nums, 0, vl, v\u52d216m1));\n    vint16m1_t vec_gt10 = vmseq_v_i16m1_i16(vec_nums, 10, vl);\n    \n    return 0;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    vint32m1_t indices = vsetvl_e32m1(n);\n    vint32m1_t values = vle32_v_i32m1(a, indices);\n    vint32m1_t mod_values = vsub_vx_i32m1(vadd_vx_i32m1(values, 1), 1);\n    mod_values = vrem_vx_i32m1(mod_values, 3);\n\n    for(int i=0; i<n-2; i++){\n        vboolm1_t mask = vmslt_vx_i32m1(mod_values, mod_values[i]);\n        vint32m1_t triplet_sums = vadd_vx_i32m1(vadd_vx_i32m1(mod_values[i], mod_values), 1);\n        vboolm1_t cond = vmseq_vx_i32m1(triplet_sums, 0);\n        count += vpopc_m_b32m1(cond & mask);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    vint32m1_t indices = vsetvl_e32m1(n);\n    vint32m1_t values = vle32_v_i32m1(a, indices);\n    vint32m1_t mod_values = vsub_vx_i32m1(vadd_vx_i32m1(values, 1), 1);\n    mod_values = vrem_vx_i32m1(mod_values, 3);\n\n    for(int i=0; i<n-2; i++){\n        vboolm1_t mask = vmslt_vx_i32m1(mod_values, mod_values[i]);\n        vint32m1_t triplet_sums = vadd_vx_i32m1(vadd_vx_i32m1(mod_values[i], mod_values), 1);\n        vboolm1_t cond = vmseq_vx_i32m1(triplet_sums, 0);\n        count += vpopc_m_b32m1(cond & mask);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    vint32m1_t indices = vsetvl_e32m1(n);\n    vint32m1_t values = vsub_vx_vi32(vmul_vx_vi32(vadd_vx_vi32(vindex_i32(indices), 1), 1), 1, indices);\n    vint32m1_t mod_values = vrem_vx_i32(values, 3, indices);\n\n    for(int i=0; i<n-2; i+=vl){\n        for(int j=i+1; j<n-1; j+=vl){\n            for(int k=j+1; k<n; k+=vl){\n                vboolm1_t mask = vmslt_vx_i32(k, n, vl);\n                vint32m1_t sum = vadd_vv_i32(vadd_vx_i32(mod_values[i], mod_values[j], vl), mod_values[k], vl);\n                vboolm1_t cond = vmseq_vx_i32(sum, 0, vl);\n                count += vpopc_b_m(cond, mask);\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    vint32m1_t indices = vsetvl_e32m1(n);\n    vint32m1_t values = vsub_vx_vi32(vmul_vx_vi32(vadd_vx_vi32(vindex_i32(indices), 1), 1), 1, indices);\n    vint32m1_t mod_values = vrem_vx_i32(values, 3, indices);\n    for(int i=0; i<n-2; i+=vl){\n        for(int j=i+1; j<n-1; j+=vl){\n            for(int k=j+1; k<n; k+=vl){\n                vboolm1_t mask = vmslt_vx_i32(k, n, vl);\n                vint32m1_t sum = vadd_vv_i32(vadd_vx_i32(mod_values[i], mod_values[j], vl), mod_values[k], vl);\n                vboolm1_t cond = vmseq_vx_i32(sum, 0, vl);\n                count += vpopc_b_m(cond, mask);\n            }\n        }\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_132_RVV", "completion": "```c\n#include <riscv_vector.h>\n\nuint64_t get_max_triples_simd(uint64_t n){\n    uint64_t count = 0;\n    vint32m1_t indices = vsetvl_e32m1(n);\n    vint32m1_t values = vsub_vx_vi32(vmul_vx_vi32(vadd_vx_vi32(vindex_i32(indices), 1), indices), indices, 1, indices);\n    vint32m1_t mod_values = vrem_vx_i32(values, 3, indices);\n    for(int i=0; i<n-2; i+=32){\n        vboolm1_t mask = vmsltu_vx_i32(mod_values, 3, indices);\n        vint32m1_t comb1 = vsub_vx_vi32(values, vget_vx_i32(values, i, indices), indices);\n        vint32m1_t comb2 = vsub_vx_vi32(comb1, vget_vx_i32(values, i+1, indices), indices);\n        vint32m1_t mod_comb = vrem_vx_i32(comb2, 3, indices);\n        vboolm1_t valid_mask = vmseq_vx_i32(mod_comb, 0, indices);\n        count += vpopc_b_m(valid_mask, mask, indices);\n    }\n    return count;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    vint32_t vn = {n};\n    vbool32_t vb;\n    vint32_t vx = {x};\n    vint32_t vy = {y};\n    vint32_t vresult;\n\n    // Assuming vector length of 1 for simplicity in this example\n    if (vn > 1 && vsetvl_e32m1(1) > 0) {\n        vb = vmsle_vx_i32m1(vn, 1); // Check if n <= 1\n        vresult = vternary_vvm_i32m1(vb, vy, vx);\n    }\n    return vresult[0];\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    vint32_t vec_n = {n};\n    vbool32_t mask;\n    vint32_t vec_x = {x};\n    vint32_t vec_y = {y};\n\n    // Check if n is prime using vectorized approach\n    if(n <= 1){\n        return y;\n    }\n    else if(n <= 3){\n        return x;\n    }\n    else if(n % 2 == 0 || n % 3 == 0){\n        return y;\n    }\n\n    int sqrt_n = (int)(sqrt((double)n));\n    vint32_t vec_sqrt_n = {sqrt_n};\n    vint32_t vec_i = {5};\n    \n    while(vmseq_v_i32m1(mask, vec_i, vec_sqrt_n)){\n        if(vmsle_v_i32m1(mask, vec_n, vec_i * vec_i)){\n            return y;\n        }\n        if(vmsle_v_i32m1(mask, vec_n, vec_i + 2)){\n            return y;\n        }\n        vec_i += 6;\n    }\n\n    return x;\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    vint32m1_t vec_n = {n};\n    vbool16_t mask;\n    int result[1];\n    \n    // Check if n is prime using vector operations\n    if (n <= 1) {\n        mask = !vmsltu_vx_mask(vec_n, 2, vl);\n    } else {\n        vint32m1_t vec_i = {2};\n        vint32m1_t vec_limit = vfwredsum_vs_x(vec_n, vec_n, vl, vl);\n        mask = true;\n        while (vec_i < vec_limit) {\n            if (vfwnmulsu_vx(vec_n, vec_i, vl) == 0) {\n                mask = false;\n                break;\n            }\n            vec_i += 1;\n        }\n    }\n    \n    // Select x if prime, else y\n    vint32m1_t vec_result = vmseq_vx_mask(mask, x, y, vl);\n    result[0] = vec_result[0];\n    return result[0];\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    vint32m1_t vec_n = {n};\n    vbool16_t mask;\n    int result[1];\n    \n    // Check if n is prime using vector operations\n    if (n <= 1) {\n        mask = !vmsltu_vx_mask(vec_n, 2, vlmax());\n    } else {\n        vint32m1_t vec_i = {2};\n        vint32m1_t vec_limit = vfredmin_vs(vec_n, vsetvl_e32m1(n-1), vlmax());\n        vint32m1_t vec_mod = vremu_vx(vec_n, vec_i, vlmax());\n        mask = vmand_mm(mask, vmsleu_vx(vec_mod, 1, vlmax()), vlmax());\n        while (vec_i < vec_limit) {\n            vec_i = vaddu_vx(vec_i, 1, vlmax());\n            vec_mod = vremu_vx(vec_n, vec_i, vlmax());\n            mask = vmand_mm(mask, vmsleu_vx(vec_mod, 1, vlmax()), vlmax());\n        }\n    }\n    \n    // Select x if prime, else y\n    vint32m1_t vec_result = vmseq_vx_mask(vec_n, x, y, mask, vlmax());\n    result[0] = vle32_v_i32m1(vec_result, 1);\n    return result[0];\n}\n```"}
{"task_id": "SimdBench_133_RVV", "completion": "```c\nint x_or_y_simd(int n, int x, int y){\n    vint32_t vn = {n};\n    vbool32_t vb;\n    vint32_t vx = {x};\n    vint32_t vy = {y};\n    vint32_t vresult;\n\n    // Check if n is prime using vectorized approach\n    if(n <= 1){\n        vresult = vy;\n    }\n    else{\n        vint32_t vtemp = {2};\n        vb = vmsltu_vx(vn, vtemp);\n        if(vb){\n            vresult = vx;\n        }\n        else{\n            vint32_t vlimit = vmsub_vx(vn, 1);\n            vint32_t vi = {2};\n            while(vi < vlimit){\n                vb = vmsltu_vx(vn, vi);\n                if(vb){\n                    vresult = vy;\n                    break;\n                }\n                vi = vadd_vx(vi, 1);\n            }\n            if(!vb){\n                vresult = vx;\n            }\n        }\n    }\n    return vfirst_v_i32(vresult);\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec = vle32_v_f32m1(lst.data(), vl);\n    uint32xm1_t mask_sign = vmseq_vf_u32m1(vluxei32_v_i32m1(vec, 0, vl), 0.0f, vl);\n    uint32xm1_t mask_int = vmsle_vf_u32m1(vec, 0.5f, vl);\n    uint32xm1_t mask_odd = vmseq_vf_u32m1(vnclip_wx_v_i32m1(vec, 0, vl), 1.0f, vl);\n    uint32xm1_t mask_valid = vmseq_vff_u32m1(vmseq_vff_u32m1(mask_sign, mask_int, vl), mask_odd, vl);\n    float32xm1_t vec_squared = vfmul_vf_f32m1(vec, vec, vl);\n    uint64_t sum = 0;\n    for(int i=0; i<vl; i++) {\n        if(vmvvx_u32m1(mask_valid, i)) {\n            sum += (uint64_t)vfloat32_to_uint64(vget_v_f32m1(vec_squared, i));\n        }\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const float *data = lst.data();\n    uint64_t sum = 0;\n\n    for(size_t i=0; i<lst.size(); i+=vl){\n        vfloat32m1_t vec = vle32_v_f32m1(data + i, vl);\n        vboolm1_t mask = vmslt_vf_f32m1_f32(0.0f, vec, vl); // Mask for negative values\n        vfloat32m1_t pos_vec = vmseq_vf_f32m1_f32(vec, vfnmadd_f32_f32_f32(vec, 2.0f, 1.0f), vl); // Mask for non-integer values\n        vint32m1_t int_vec = vfcvt_x_f_w_f32m1(pos_vec, vl); // Convert to integer\n        vboolm1_t odd_mask = vmslt_vf_i32m1_i32(int_vec, vsub_vx_i32m1_i32(int_vec, 1, vl), vl); // Mask for odd values\n        vint32m1_t odd_int_vec = vmand_mm_int32m1(mask, odd_mask, vl); // Combine masks\n        vint32m1_t squared = vmul_vx_i32m1_i32(odd_int_vec, odd_int_vec, vl); // Square the values\n        sum += vsmul_vx_u32m1(sum, squared, vl); // Accumulate the sum\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    float32xm1_t vec = vle32_v_f32m1(lst.data(), vl);\n    uint32xm1_t mask_sign = vmseq_vf_u32m1(vluxei32_v_i32m1(vec, 0, vl), 0.0f, vl);\n    uint32xm1_t mask_int = vfredusum_vs_u32m1_u32m1(vmseq_vf_u32m1(vfmseq_vf_u32m1(vec, 0.5f, vl), 0.0f, vl), mask_sign, vl);\n    uint32xm1_t mask_odd = vmseq_vf_u32m1(vfredusum_vs_u32m1_u32m1(vmseq_vf_u32m1(vfmseq_vf_u32m1(vec, 0.5f, vl), 0.0f, vl), mask_int, vl), 1.0f, vl);\n    float32xm1_t vec_squared = vfmul_vf_f32m1(vec, vec, vl);\n    uint64xm1_t result = vfredusum_vs_f32m1_u64m1(vec_squared, mask_odd, vl);\n    return vget_v_u64m1(result, 0);\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const float *data = lst.data();\n    uint64_t sum = 0;\n\n    for(size_t i=0; i<lst.size(); i+=vl){\n        size_t n = std::min(vl, lst.size() - i);\n        vfloat32m1_t vec = vle32_v_f32m1(data + i, n);\n        vboolm1_t mask = vmslt_vf_f32m1_f32(0.0f, vec, n); // Mask for negative values\n        vfloat32m1_t pos_vec = vmseq_vf_f32m1_f32(vec, 0.0f, n); // Mask for integer values\n        vint32m1_t int_vec = vfcvt_x_f_v_i32m1(vec, n);\n        vint32m1_t odd_vec = vmsub_vx_i32m1(int_vec, 1, n, mask); // Odd check\n        vint32m1_t valid_vec = vbmslt_vx_i32m1(odd_vec, 0, n, mask);\n        vfloat32m1_t square_vec = vfmul_vx_f32m1(int_vec, int_vec, n);\n        vfloat32m1_t filtered_square_vec = vfmacc_vx_f32m1(square_vec, 0.0f, valid_vec, n);\n        sum += vsmul_vx_f32m1(filtered_square_vec, 1.0f, n);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_134_RVV", "completion": "```c\n#include <riscv_vector.h>\n#include <cmath>\n\nuint64_t double_the_difference_simd(const std::vector<float> & lst){\n    size_t vl = vsetvl_e32m1(lst.size());\n    const float *data = lst.data();\n    uint64_t sum = 0;\n\n    for(size_t i = 0; i < lst.size(); i += vl){\n        size_t n = std::min(vl, lst.size() - i);\n        vfloat32m1_t vec = vle32_v_f32m1(data + i, n);\n        vboolm1_t mask = vmslt_vf_f32m1_f32m1(vec, 0.0f, n); // Mask for negative values\n        vfloat32m1_t int_vec = vfcvt_x_f_v_f32m1(vec, n); // Convert to integer\n        vboolm1_t int_mask = vfredusum_vs_b_f32m1(mask, n); // Check if all integers\n        vfloat32m1_t odd_vec = vfmseq_vf_f32m1(int_vec, 2.0f, n); // Mask for odd numbers\n\n        vfloat32m1_t square_vec = vmul_vf_f32m1(int_vec, int_vec, n);\n        vfloat32m1_t filtered_square_vec = vmsle_vb_f32m1_f32m1(odd_vec, square_vec, n);\n\n        sum += vfredusum_vs_f_f32m1(filtered_square_vec, n);\n    }\n    return sum;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int vl = vsetvl_e32m1(game.size());\n    std::vector<int> result(game.size(), 0);\n    int* res_ptr = result.data();\n\n    const int* game_ptr = game.data();\n    const int* guess_ptr = guess.data();\n\n    int32xm1_t game_vec = vle32_v_i32xm1(game_ptr, vl);\n    int32xm1_t guess_vec = vle32_v_i32xm1(guess_ptr, vl);\n\n    int32xm1_t diff_vec = vsub_vv_i32xm1(game_vec, guess_vec, vl);\n    int32xm1_t abs_diff_vec = vabs_vx_i32xm1(diff_vec, 0, vl);\n\n    int32xm1_t zero_vec = vlmul_v_i32xm1(0, vl);\n    \n    vse32_v_i32xm1(res_ptr, vmseq_vx_i32xm1(abs_diff_vec, zero_vec, vl), vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int vl = vsetvl_e32m1(game.size());\n    std::vector<int> result(game.size(), 0);\n    int* res_ptr = result.data();\n\n    const int* game_ptr = game.data();\n    const int* guess_ptr = guess.data();\n\n    int32xm1_t game_vec = vle32_v_i32xm1(game_ptr, vl);\n    int32xm1_t guess_vec = vle32_v_i32xm1(guess_ptr, vl);\n\n    int32xm1_t diff_vec = vsub_vv_i32xm1(game_vec, guess_vec, vl);\n    int32xm1_t abs_diff_vec = vabs_vx_i32xm1(diff_vec, 0, vl);\n\n    int32xm1_t zero_vec = v\u52d2\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int vl = vsetvl_e32m1(game.size());\n    std::vector<int> result(game.size(), 0);\n    int* res_ptr = result.data();\n\n    const int* game_ptr = game.data();\n    const int* guess_ptr = guess.data();\n\n    int32xm1_t game_vec = vle32_v_i32xm1(game_ptr, vl);\n    int32xm1_t guess_vec = vle32_v_i32xm1(guess_ptr, vl);\n\n    int32xm1_t diff_vec = vsub_vv_i32xm1(game_vec, guess_vec, vl);\n    int32xm1_t abs_diff_vec = vabs_vx_i32xm1(diff_vec, 0, vl);\n\n    int32xm1_t zero_vec = vlmul_v_i32xm1(0, vl);\n    \n    vse32_v_i32xm1(res_ptr, vmsltu_vx_i32xm1(abs_diff_vec, zero_vec, vl), vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int vl = vsetvl_e32m1(game.size());\n    std::vector<int> result(game.size(), 0);\n    int* res_ptr = result.data();\n\n    const int* game_ptr = game.data();\n    const int* guess_ptr = guess.data();\n\n    int32xm1_t game_vec = vle32_v_i32xm1(game_ptr, vl);\n    int32xm1_t guess_vec = vle32_v_i32xm1(guess_ptr, vl);\n\n    int32xm1_t diff_vec = vsub_vv_i32xm1(game_vec, guess_vec, vl);\n    int32xm1_t abs_diff_vec = vabs_vx_i32xm1(diff_vec, 0, vl);\n\n    int32xm1_t zero_vec = v\u52d20_v_i32xm1(lmul=1, vl);\n    int32xm1_t mask = vseqz_v_i32xm1(diff_vec, vl);\n\n    int32xm1_t final_vec = vmsub_vs_i32xm1(abs_diff_vec, zero_vec, mask, vl);\n\n    vse32_v_i32xm1(res_ptr, final_vec, vl);\n\n    return result;\n}\n```"}
{"task_id": "SimdBench_135_RVV", "completion": "```cpp\n#include <riscv_vector.h>\n#include <vector>\n\nstd::vector<int> compare_simd(const std::vector<int>& game, const std::vector<int>& guess){\n    const int vl = vsetvl_e32m1(game.size());\n    std::vector<int> result(game.size(), 0);\n    int* res_ptr = result.data();\n\n    const int* game_ptr = game.data();\n    const int* guess_ptr = guess.data();\n\n    vint32m1_t game_vec = vle32_v_i32m1(game_ptr, vl);\n    vint32m1_t guess_vec = vle32_v_i32m1(guess_ptr, vl);\n\n    vint32m1_t diff_vec = vsub_vx_i32m1(game_vec, 0, vl); // game - 0\n    vint32m1_t guess_abs = vabs_vx_i32m1(guess_vec, vl);   // |guess|\n\n    vint32m1_t cmp_result = vseq_vx_i32m1(diff_vec, 0, vl); // diff == 0\n\n    vint32m1_t abs_diff_vec = vmseq_vx_i32m1(cmp_result, 0, vl) ? vsub_vx_i32m1(diff_vec, 0, vl) : vsub_vx_i32m1(guess_abs, diff_vec, vl);\n\n    vse32_v_i32m1(res_ptr, abs_diff_vec, vl);\n\n    return result;\n}\n```"}
